{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "3 Class Classifier Multilingual.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bryan6aero/Chinese-BERT-Classifier/blob/main/3_Class_Classifier_Multilingual.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# Classifying Wikipedia Comments with BERT\n",
        "\n",
        "By Chris McCormick & Nick Ryan\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8uEW4O7f8XS"
      },
      "source": [
        "This Notebook will show you how to fine-tune BERT for **multi-label text classification** tasks, meaning that each sample in the dataset can belong to more than one category (or no category!). \n",
        "\n",
        "We'll be using the *Wikipedia Toxic Comments Challenge* dataset, which contains a large number of user-written comments, and where each comment can be tagged with multiple labels. \n",
        "\n",
        "The dataset has **6** different labels corresponding to different types of awfulness (\"toxic\", \"obscene\", \"insult\", ...), and each comment can be tagged with one or more labels, or no labels at all. \n",
        "\n",
        "This is a slightly different task than \"multiclass\" classification, where there are multiple categories, but each sample only belongs to one category.\n",
        "\n",
        "> *Side Note: Going off of the Wikipedia article titles, the correct spelling for these two terms are \"[Multiclass](https://en.wikipedia.org/wiki/Multiclass_classification)\" and \"[Multi-label](https://en.wikipedia.org/wiki/Multi-label_classification)\", so I'll do my best to stick to those spellings :)*\n",
        "\n",
        "The huggingface `transformers` library has built-in support for multiclass, but not multi-label, so we'll be defining a custom class here to do it! (Note that we'll still be relying heavily on the `transformers` library).\n",
        "\n",
        "> Note that Kaushal Trivedi has previously created and shared this same example [here](https://medium.com/huggingface/multi-label-text-classification-using-bert-the-mighty-transformer-69714fa3fb3d) back in 2019--modifying PyTorch transformers to apply it to the toxic comments challenge. His example code isn’t well documented, though, so we didn’t use it as the basis for our example here, other than to help confirm the small changes we needed to make to the model. That said, his code may be a source of additional insight if you are interested. For instance, he appears to use a more complex learning rate scheduler than the linear one that we have been using in our examples.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQgKKHtnPCkD"
      },
      "source": [
        "## Overview\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxtkgZR3P1R8"
      },
      "source": [
        "\n",
        "This Notebook is divided into six sections.\n",
        "\n",
        "* Section 1 - We'll look at the differences in a multi-label vs. multi-class architecture, and we'll define our custom multi-label model, using `transformers` and PyTorch.\n",
        "* Section 2 - We'll retrieve the toxic comments dataset and explore it a bit.\n",
        "* Section 3 - We'll tokenize the dataset so that it's ready to be fed into BERT.\n",
        "* Section 4 - We'll implement and run our training loop to fine-tune BERT on this dataset.\n",
        "* Section 5 - We'll apply our fine-tuned model to the test set of the toxic comments challenge and see how well we score!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlANiaJ4zZdx"
      },
      "source": [
        "## S1. Defining our Multi-Label Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O88xsdq90Fmf"
      },
      "source": [
        "In all of our examples, we have been using the `transformers` library by Huggingface, because it defines models for us for several different NLP tasks. Here are the most significant ones: \n",
        "\n",
        "* `BertForSequenceClassification` - Binary and Multiclass Text Classification.\n",
        "* `BertForTokenClassification` - Token-level classification, such as for Named Entity Recognition (NER)\n",
        "* `BertForQuestionAnswering` - Identify a span of text within a passage which answers the posed question.\n",
        "\n",
        "Each of these classes places a different final layer on top of the BERT model depending on the task.\n",
        "\n",
        "The `BertForSequenceClassification` class is the closest to what we are looking for; for some reason, though, it does not support multi-label classification, and so we'll need to define our own model: **BertForMultiLabelSequenceClassification**.\n",
        "\n",
        "Fortunately, we'll see that it's a pretty small change from the existing `BertForSequenceClassification`. To understand the change, let's look at the difference in architectures.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jInRJRYIpntp"
      },
      "source": [
        "### 1.1. Multiclass vs. Multi-Label Architectures\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2EViVcQ6pnX"
      },
      "source": [
        "At the most basic level, in *multiclass* our target is a one-hot vector that must have one and only one positive class. For multi-label our target is a one-hot vector that can have a) no positive classes, b) one positive class, or c) multiple positive classes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoKs4cFprOPY"
      },
      "source": [
        "\n",
        "![One Hot Vectors](https://drive.google.com/uc?id=1cPFTlbBVT9I2wx06M1MkuAToXfpXruuS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B14QKhW7rQRf"
      },
      "source": [
        "\n",
        "In both cases, the embedding for the `[CLS]` token, after being \"enhanced\" by all 12 of BERT's encoder layers, is fed into a classifier which makes our predictions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxrxIc5NrRv-"
      },
      "source": [
        "\n",
        "![Illustration of CLS token purpose](https://drive.google.com/uc?export=view&id=1ck4mvGkznVJfW3hv6GUqcdGepVTOx7HE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjp4AmVzrToN"
      },
      "source": [
        "\n",
        "The difference between how we handle multilabel vs multiclass tasks is just in the classifier at the very end! \n",
        "\n",
        "In both cases, we use a simple linear classifier, which has a `[768 x 6]` weight matrix. We multiply the `[CLS]` embedding (length 768) against this matrix to produce 6 logit values (one for each class).\n",
        "\n",
        "The difference between multiclass and multi-label is what we do with those 6 logits--we use a different *activation function* and *loss function*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RLjj_2r63fD"
      },
      "source": [
        "\n",
        "#### Multiclass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJFjYBEu64ua"
      },
      "source": [
        "For multiclass, we use the **SoftMax activation** function with **Cross-Entropy Loss**. You'll sometimes see this classifier referred to as a \"SoftMax Regression\" classifier (the use of the term 'regression' to name a classifier is confusing, I know!).\n",
        "\n",
        "The below illustration shows how the final `[CLS]` token embedding is multiplied by the classifier weights to produce the logits, then sent through the SoftMax activation function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJvjz0WRCmRY"
      },
      "source": [
        "\n",
        "![Multiclass Classifier with SoftMax](https://drive.google.com/uc?id=1X4hGAlKoTkoQlbLx3w2Iye3QaOIOuecQ)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY1eahVGCyeh"
      },
      "source": [
        "The result is a distribution of scores across the classes that will always add up to 1.0. \n",
        "\n",
        "Using softmax, the probability of one class affects the probability of the other classes in a big way. This works out well because there is only one correct answer, so if one score is very likely we want to make the other scores very unlikely. \n",
        "\n",
        "When we want to predict the label for a new piece of input text, we simply assign it the highest scoring class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wToJFJcp6tzU"
      },
      "source": [
        "\n",
        "#### Multi-Label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ3Lvojz6vJG"
      },
      "source": [
        "For multi-label, this presents a problem. Since an example can belong to multiple classes, we don't want the high probability that our example is one class to negatively affect the probability that it could be in the other classes. \n",
        "\n",
        "For multilabel, we will use the **sigmoid activation** function with **Binary Cross-Entropy Loss**. \n",
        "\n",
        "Here is the same illustration, this time with sigmoid activation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKvRr4SIHN2k"
      },
      "source": [
        "\n",
        "![Multilabel Classifier with sigmoid](https://drive.google.com/uc?id=1XAJfd9pVAIqIX43Ih13X4d4DjWEe7tys)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2xqcDhEHPxz"
      },
      "source": [
        "When we want to predict the labels for a new piece of input text, we just assign all labels whose scores are greater than some threshold. The sigmoid function always outputs values in the range 0 - 1.0, so 0.5 is a reasonable choice for our threshold.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRLVzVuH6xn8"
      },
      "source": [
        "\n",
        "#### Summing Up\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3CxbdFI6yeR"
      },
      "source": [
        "**Multiclass = SoftMax + Cross-Entropy**\n",
        "\n",
        "**Multi-Label = Sigmoid + Binary Cross-Entropy**\n",
        "\n",
        "**SoftMax** = Squish the outputs into a probability distribution of scores that add up to 1.\n",
        "\n",
        "**Sigmoid** = Squish each output into a score between 0 and 1. \n",
        "\n",
        "**Cross-Entropy Loss** = Punishes bad predictions at log scale.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ElsnSNUridI"
      },
      "source": [
        "### 1.2. Install the Hugging Face Library\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_N2UDLevYWn"
      },
      "source": [
        "With the theory out of the way, now we can define our new architecture in code.\n",
        "\n",
        "We will still be relying heavily on the `transformers` library, so we'll need to install it before we can define our model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NmMdkZO8R6q",
        "outputId": "054c0a99-62c9-4060-fcb2-38004944de13"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "### 1.3. BertForMultiLabelSequenceClassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXYitPoE-cjH"
      },
      "source": [
        "Now it's time to implement our custom model!\n",
        "\n",
        "> *If you're not interested in the details of implementing models in PyTorch, feel free to skip this section--you can always return to it later.*\n",
        "\n",
        "We can get most of what we need for our model definition by simplying copying the source code for `BertForSequenceClassification` from `modeling_bert.py` [here](https://github.com/huggingface/transformers/blob/0735def8e1200ed45a2c33a075bc1595b12ef56a/src/transformers/modeling_bert.py#L1267).\n",
        "\n",
        "`BertForSequenceClassification` calls down to an instance of `BertModel`, which implements all of BERT's non-task-specific architecture. We just need to define a `forward` function which calls down to `BertModel`, and then adds on our final multi-label classification step.\n",
        "\n",
        "I've commented our \"BertFor**MultiLabel**SequenceClassification\" class in detail below, but here is the outline of what happens in the call to `forward`:\n",
        "\n",
        "1. The inputs are passed through an instance of `BertModel`, which returns the final `[CLS]` token embedding that we need for classificaiton.\n",
        "2. The `[CLS]` embedding is multiplied by a `[768 x 6]` weight matrix (our classifier weights), which produces our 6 output \"logits\".\n",
        "3. During **evaluation**, that's it! We return the logits as our predictions.\n",
        "4. During **training**, we feed the logits through an instance of `BCEWithLogitsLoss` from PyTorch, which:\n",
        "    1. Applies the sigmoid activation function to each of the 6 logit values.\n",
        "    2. Sends these final activations, along with the correct labels, through the Binary Cross-Entropy Loss function to calculate the \"loss\" (how well / poorly the model is predicting the correct labels).\n",
        "\n",
        "And that's it! \n",
        "\n",
        "Finally, note that we'll be using a batch size of 16 in this Notebook, so I use that as an example value in some of the comments below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBdW3DKgIalH"
      },
      "source": [
        "***Aside: What about implementing backprop?***\n",
        "\n",
        "PyTorch handles gradient calculation for us--it constructs a \"compute graph\" as we execute the forward pass, attaching the graph to the tensors we use, and is able to automatically calculate our gradients from that graph when we call `loss.backward()` in our training loop.\n",
        "\n",
        "The actual weight updates are performed in the training loop later in the Notebook when we call `optimizer.step()`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9kg0ojhpaDv"
      },
      "source": [
        "BertFor**MultiLabel**SequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SomcsvX5bi1U"
      },
      "source": [
        "from torch import nn\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from transformers import BertPreTrainedModel, BertModel\n",
        "\n",
        "class BertForMultiLabelSequenceClassification(BertPreTrainedModel):\n",
        "    '''\n",
        "    This custom class closely resembles BertForSequenceClassification, which\n",
        "    supports multiclass classification, but not multi-label.\n",
        "    This modified version supports data points with multiple labels.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, config):\n",
        "        '''\n",
        "        Class initializer, called when we create a new instance of this class.\n",
        "        '''\n",
        "\n",
        "        # Call the init function of the parent class (BertPreTrainedModel)        \n",
        "        super().__init__(config)\n",
        "       \n",
        "        # Store the number of labels.\n",
        "        self.num_labels = config.num_labels\n",
        "        \n",
        "        # Create a `BertModel`--this implements all of BERT except for the final\n",
        "        # task-specific output layer (which is what we'll do here in `forward`). \n",
        "        self.bert = BertModel(config)\n",
        "\n",
        "        # Setup dropout object (note: I'm not familiar enough to speak to this).\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # Create a [768 x 6] weight matrix to use as our classifier.\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "\n",
        "        # Initialize model weights (inherited function).\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "    ):\n",
        "        '''\n",
        "        This function defines what happens on a forward pass of our model, both\n",
        "        for training and evaluation. For example, when we call \n",
        "            `model(b_input_ids, ...)`\n",
        "        during our training loop, it results in a call to this `forward`\n",
        "        function.\n",
        "        '''\n",
        "\n",
        "        # ====================\n",
        "        #   Run Through BERT\n",
        "        # ====================\n",
        "\n",
        "        # All of BERT's (non-task-specific) architecture is implemented by the\n",
        "        # BertModel class. Here we pass all of the inputs through our BertModel\n",
        "        # instance. \n",
        "        outputs = self.bert(\n",
        "            input_ids,                      # The input sequence\n",
        "            attention_mask=attention_mask,  # Mask out any [PAD] tokens.\n",
        "            token_type_ids=token_type_ids,  # Identify segment A vs. B\n",
        "            position_ids=position_ids,      # TODO...\n",
        "            head_mask=head_mask,            # TODO...\n",
        "            inputs_embeds=inputs_embeds,    # Presumably the initial embeddings\n",
        "                                            # for the tokens in our sequence.\n",
        "            output_attentions=output_attentions, # Boolean, whether to return\n",
        "                                                 # all of the attention scores.\n",
        "            output_hidden_states=output_hidden_states, # Whether to return\n",
        "                                                       # embeddings from all 12\n",
        "                                                       # layers.\n",
        "        )\n",
        "\n",
        "        # Side note: It confused me to see us *invoking* an instance of a class\n",
        "        # (calling self.bert(...)) as if it were a function! I learned that in \n",
        "        # Python, an instance of a class can be callable if the class defines a \n",
        "        # `__call__` method! \n",
        "        # BertModel ultimately inherits from torch.nn.Module, which I imagine \n",
        "        # implements a `__call__` method that allows PyTorch to work its magic.\n",
        "\n",
        "        # The forward pass of 'BertModel' (the call to `self.bert`) returns two\n",
        "        # items.\n",
        "\n",
        "        # The first output is the final embeddings taken from the output of \n",
        "        # the final BERT encoder layer.\n",
        "        #\n",
        "        # `final_embeddings` has dimensions:\n",
        "        #    [ batch size  x  sequence length  x  768]\n",
        "        #      (768 is the length of the embeddings in BERT-base)\n",
        "        #\n",
        "        # I've included this here for informational purposes, but we won't \n",
        "        # actually use the `final_embeddings` anywhere here!\n",
        "        final_embeddings = outputs[0]\n",
        "\n",
        "        # ===========================\n",
        "        #   Apply Output Classifier\n",
        "        # ===========================\n",
        "\n",
        "        # The second output is the activated form of the final [CLS] embedding. \n",
        "        # This comes from the so-called \"pooling layer\" that BERT has on its \n",
        "        # output which is only applied to the [CLS] token and none of the\n",
        "        # others.\n",
        "        #\n",
        "        # You can see the definition of BertPooler.forward here:\n",
        "        # https://github.com/huggingface/transformers/blob/0735def8e1200ed45a2c33a075bc1595b12ef56a/src/transformers/modeling_bert.py#L506\n",
        "        #\n",
        "        # It takes the final embedding for the [CLS] token (and *only* that\n",
        "        # token), multiplies it with a [768 x 768] weight matrix, and then\n",
        "        # applies tanh activation to each of the 768 features in the embedding.\n",
        "        activated_cls = outputs[1]\n",
        "\n",
        "        # Apply dropout (note: I'm not familiar enough with dropout to speak to\n",
        "        # it, but I believe it is applied during training only, and is turned \n",
        "        # off during evaluation mode when we call `model.eval()`).\n",
        "        activated_cls = self.dropout(activated_cls)\n",
        "        \n",
        "        # Send it through our linear \"classifier\". The \"classifier\" is actually\n",
        "        # just a [768 x 6] weight matrix, with *no activation function*. \n",
        "        # Multiplying the activated CLS embedding with this matrix results in\n",
        "        # a vector with 6 values, which are the scores for each of our classes.\n",
        "        # Because we have not applied the activation function, these output \n",
        "        # values are referred to as \"logits\". \n",
        "        # When performing evaluation (not training), the logits are adequate for\n",
        "        # making a classification, since the activation function does not change\n",
        "        # the ranking of the results.\n",
        "        # So, in evaluation mode, we are done here!\n",
        "        logits = self.classifier(activated_cls)\n",
        "        \n",
        "        # ===================\n",
        "        #   Training Mode\n",
        "        # ===================\n",
        "\n",
        "        # If labels for the inputs have been provided, we take that to mean that\n",
        "        # we are in training mode, and we need to calculate the loss function.\n",
        "        if labels is not None:\n",
        "            \n",
        "            # The Binary Cross-Entropy Loss function is defined for us in \n",
        "            # PyTorch by the `BCEWithLogitsLoss` class.\n",
        "            #\n",
        "            # This loss function will:\n",
        "            #   1. Apply the sigmoid activation to each of our 6 logit values.\n",
        "            #   2. Feed those outputs, along with the correct labels, through \n",
        "            #      the binary cross entropy loss function to calculate a \n",
        "            #      (single?) loss value for the sample.\n",
        "            loss_fct = BCEWithLogitsLoss()\n",
        "\n",
        "            # Call the loss function, giving it the `logits` and the correct\n",
        "            # `labels`.\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), # The logits\n",
        "                            labels.view(-1, self.num_labels)) # The labels\n",
        "\n",
        "            # What's view(-1, ...)?\n",
        "            # The `view` function is used to reshape tensors. `-1` tells PyTorch\n",
        "            # to infer that dimension by dividing the total number of elements\n",
        "            # by the other dimensions.\n",
        "            # For batched input, this call to view is not necessary. Both\n",
        "            # `logits` and `labels` are already [16 x 6] here.\n",
        "            # Perhaps it's there to re-shape the tensors if you're only\n",
        "            # evaluating on a single input instead of a batch?\n",
        "\n",
        "            # Output is (loss, logits, <bonus returns>)\n",
        "            # The 'bonus return' values are the attentions and the hidden states\n",
        "            # from all 12 layers, but these are only returned by `BertModel` if\n",
        "            # the appropriate flags are set. \n",
        "            return ((loss, logits) + outputs[2:])\n",
        "\n",
        "        # ===================\n",
        "        #   Evaluation Mode\n",
        "        # ===================\n",
        "\n",
        "        # Otherwise, in evaluation mode...\n",
        "        else:\n",
        "        \n",
        "            # Output is (logits, <bonus returns>)\n",
        "            # Again, the logits are adequate for classification, so we don't\n",
        "            # bother applying the (sigmoid) activation function here.\n",
        "            return ((logits,) + outputs[2:])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt3HTo7LLMtj"
      },
      "source": [
        "## S2. Retrieve & Inspect Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMx3Wd3K3B2q"
      },
      "source": [
        "The Toxic Comments Challenge on Kaggle (TODO) tasks competitors with classifying user-written comments (from Wikipedia edit pages) as containing depending on whether they \n",
        "toxic             15294\n",
        "severe_toxic       1595\n",
        "obscene            8449\n",
        "threat              478\n",
        "insult             7877\n",
        "identity_hate      1405"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAjyraFG4Abp"
      },
      "source": [
        "### 2.1. Download\n",
        "--------------------------------------\n",
        "Download the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-LF9NXd4Abp",
        "outputId": "d4d70ed8-d59c-459c-a09a-6675555361f7"
      },
      "source": [
        "import gdown\n",
        "import os\n",
        "\n",
        "# Model files and their Google Drive IDs.\n",
        "# These are tuples of the form (local_file_name, drive_id).\n",
        "\n",
        "files = [\n",
        "\n",
        "\n",
        "     ('./data/train.csv',     '170MpjGO_Rm4nElLqr5MQUm7daSHvOaMC'), \n",
        "     ('./data/test.csv',     '1yzfIBRcKdCQgsWWaJUlgnvTCGtAd0DNK'),    \n",
        "     ('./data/sample_submission.csv', '1mncwmJa9sJ7cMPxYA9vNH-L2lv7QC5la'),\n",
        "     ('./data/test_labels.csv', '1Xemv4f_xpF-ZumrC3DdRJ1Y8JYvlH_69'),\n",
        "]\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "Longer\n",
        "https://drive.google.com/file/d/170MpjGO_Rm4nElLqr5MQUm7daSHvOaMC/view?usp=sharing train no blanks\n",
        "https://drive.google.com/file/d/14F_DBk8fgEk0y3sLj3NhwNrgYvyi3SK5/view?usp=sharing train !!! too long\n",
        "https://drive.google.com/file/d/1YHeGASctVT5dT8u7JKAQqtCsvweleFLu/view?usp=sharing train max 500\n",
        "https://drive.google.com/file/d/1lb51GOGuu1vtxQzYzO6Ufh1jrc-eYpNG/view?usp=sharing train max 300\n",
        "https://drive.google.com/file/d/1hofWwNXbh-4ms61wwVV0LuiEl6s2QuyR/view?usp=sharing title train\n",
        "https://drive.google.com/file/d/1yzfIBRcKdCQgsWWaJUlgnvTCGtAd0DNK/view?usp=sharing test\n",
        "https://drive.google.com/file/d/1mncwmJa9sJ7cMPxYA9vNH-L2lv7QC5la/view?usp=sharing Sample Submission\n",
        "https://drive.google.com/file/d/1Xemv4f_xpF-ZumrC3DdRJ1Y8JYvlH_69/view?usp=sharing Test Labels\n",
        "\n",
        "'''\n",
        "\n",
        "# Make the '/data/' subdirectory.\n",
        "if not os.path.exists('./data/'):\n",
        "    os.mkdir('./data/')\n",
        "\n",
        "print('Downloading dataset files...')\n",
        "\n",
        "# For each of the files...\n",
        "for pair in files:\n",
        "    # Get the local filename.\n",
        "    output = pair[0]\n",
        "    \n",
        "    # Get the ID of the file on Google Drive.\n",
        "    file_id = pair[1]\n",
        "    \n",
        "    # Download the file.\n",
        "    gdown.download('https://drive.google.com/uc?id=' + file_id, output, \n",
        "                   quiet=False)\n",
        "    \n",
        "print('DONE.')"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=170MpjGO_Rm4nElLqr5MQUm7daSHvOaMC\n",
            "To: /content/data/train.csv\n",
            "100%|██████████| 14.9M/14.9M [00:00<00:00, 172MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yzfIBRcKdCQgsWWaJUlgnvTCGtAd0DNK\n",
            "To: /content/data/test.csv\n",
            "100%|██████████| 974k/974k [00:00<00:00, 84.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1mncwmJa9sJ7cMPxYA9vNH-L2lv7QC5la\n",
            "To: /content/data/sample_submission.csv\n",
            "100%|██████████| 16.9k/16.9k [00:00<00:00, 27.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Xemv4f_xpF-ZumrC3DdRJ1Y8JYvlH_69\n",
            "To: /content/data/test_labels.csv\n",
            "100%|██████████| 10.9k/10.9k [00:00<00:00, 5.04MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02NmUilP4Abs"
      },
      "source": [
        "### 2.2. Parse & Inspect\n",
        "-------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pOXoBTILCfr"
      },
      "source": [
        "\n",
        "We'll use `pandas` just to help us parse the comma-separated `.csv` file. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYvXA4_3FcbY"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('./data/train.csv')\n",
        "test = pd.read_csv('./data/test.csv')\n",
        "sample = pd.read_csv('./data/sample_submission.csv')\n",
        "test_label = pd.read_csv('./data/test_labels.csv')"
      ],
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdyFwHMDK6nL"
      },
      "source": [
        "\n",
        "The training data contains a row per comment, with an id, the text of the comment, and 6 different labels that we'll try to predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "oAtBnY9CFcbb",
        "scrolled": true,
        "outputId": "b58864f2-dc66-4b16-e32f-424d83829df6"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>中国人民解放军陆军领导机构、中国人民解放军火箭军、中国人民解放军战略支援部队成立大会2015...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>经中央军委主席习近平批准，中央军委近日印发了《关于深化国防和军队改革的意见》。\\n《意见》强...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>由中共中央纪律检查委员会、中共中央文献研究室编辑的《习近平关于严明党的纪律和规矩论述摘编》一...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>广大党员干部正在积极学习习近平总书记在中央政治局专题民主生活会上的重要讲话。大家纷纷表示要把...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>刚刚过去的2015年，是全面深化改革的关键之年。改革集中发力在制约经济社会发展的深层次矛盾，...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                       comment_text  ...  class2  class3\n",
              "0   1  中国人民解放军陆军领导机构、中国人民解放军火箭军、中国人民解放军战略支援部队成立大会2015...  ...       0       0\n",
              "1   2  经中央军委主席习近平批准，中央军委近日印发了《关于深化国防和军队改革的意见》。\\n《意见》强...  ...       0       0\n",
              "2   3  由中共中央纪律检查委员会、中共中央文献研究室编辑的《习近平关于严明党的纪律和规矩论述摘编》一...  ...       0       0\n",
              "3   4  广大党员干部正在积极学习习近平总书记在中央政治局专题民主生活会上的重要讲话。大家纷纷表示要把...  ...       0       0\n",
              "4   5  刚刚过去的2015年，是全面深化改革的关键之年。改革集中发力在制约经济社会发展的深层次矛盾，...  ...       0       0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "W0yVHHBIhJLz",
        "outputId": "2ec7ee53-bb5c-4d67-d702-ccc3caf2f25b"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>中共中央政治局1月12日召开会议，研究修改宪法部分内容的建议。中共中央总书记习近平主持会议。...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>当地时间11日上午，柬埔寨首相洪森在金边和平大厦举行仪式，欢迎国务院总理李克强对柬埔寨进行正...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>欢迎仪式后，双方在金边和平大厦举行会谈。\\n李克强表示，中柬是近邻，传统友谊深厚。中方愿以两...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>当天中午，李克强在金边王宫会见柬埔寨国王西哈莫尼。\\n李克强首先转达习近平主席对西哈莫尼国王...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>国务院总理李克强出席在柬埔寨金边举行的澜沧江-湄公河合作第二次领导人会议，并结束对柬埔寨的正...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                       comment_text\n",
              "0   1  中共中央政治局1月12日召开会议，研究修改宪法部分内容的建议。中共中央总书记习近平主持会议。...\n",
              "1   2  当地时间11日上午，柬埔寨首相洪森在金边和平大厦举行仪式，欢迎国务院总理李克强对柬埔寨进行正...\n",
              "2   3  欢迎仪式后，双方在金边和平大厦举行会谈。\\n李克强表示，中柬是近邻，传统友谊深厚。中方愿以两...\n",
              "3   4  当天中午，李克强在金边王宫会见柬埔寨国王西哈莫尼。\\n李克强首先转达习近平主席对西哈莫尼国王...\n",
              "4   5  国务院总理李克强出席在柬埔寨金边举行的澜沧江-湄公河合作第二次领导人会议，并结束对柬埔寨的正..."
            ]
          },
          "metadata": {},
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjnBWnzVhJao",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e1e37b49-af37-4328-8c9f-fec7c160d3c5"
      },
      "source": [
        "sample.head()"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  class1  class2  class3\n",
              "0   1     0.5     0.5     0.5\n",
              "1   2     0.5     0.5     0.5\n",
              "2   3     0.5     0.5     0.5\n",
              "3   4     0.5     0.5     0.5\n",
              "4   5     0.5     0.5     0.5"
            ]
          },
          "metadata": {},
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "g3nbXgKyhJ-Q",
        "outputId": "0da6f009-2ab5-4131-faba-6189287db211"
      },
      "source": [
        "test_label.head()"
      ],
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  class1  class2  class3\n",
              "0   1       1       0       0\n",
              "1   2       0       1       0\n",
              "2   3       0       0       1\n",
              "3   4       1       0       0\n",
              "4   5       0       1       0"
            ]
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mReOku_TtXsA"
      },
      "source": [
        "There are roughly 160k training examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNORNxYvBTzv",
        "outputId": "17f97b8c-0169-4c07-e4bb-f681a8cc45d3"
      },
      "source": [
        "print('There are {:,} training examples.'.format(len(train)))"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 14,903 training examples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bwX6vFJLjem"
      },
      "source": [
        "Display some of the comments labeled as containing an attack. Be prepared to see some terrible human behavior... (I've removed the output for this cell!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "AjfJnK6qLjen",
        "outputId": "3a0a66a3-c4b2-4fd8-8bc8-5c2ee1ede696"
      },
      "source": [
        "import textwrap\n",
        "import random\n",
        "\n",
        "'''\n",
        "# Wrap text to 80 characters.\n",
        "wrapper = textwrap.TextWrapper(width=80) \n",
        "\n",
        "# Filter to just the \"insult\" comments.\n",
        "insults = train.loc[train.insult == 1]['comment_text']\n",
        "comments = train.loc[train.insult == 1]['comment_text']\n",
        "\n",
        "# Randomly choose some examples.\n",
        "for i in range(5):\n",
        "    j = random.choice(insults.index)\n",
        "    \n",
        "    print('')\n",
        "    print(wrapper.fill(insults[j]))\n",
        "    print('')\n",
        "'''"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Wrap text to 80 characters.\\nwrapper = textwrap.TextWrapper(width=80) \\n\\n# Filter to just the \"insult\" comments.\\ninsults = train.loc[train.insult == 1][\\'comment_text\\']\\ncomments = train.loc[train.insult == 1][\\'comment_text\\']\\n\\n# Randomly choose some examples.\\nfor i in range(5):\\n    j = random.choice(insults.index)\\n    \\n    print(\\'\\')\\n    print(wrapper.fill(insults[j]))\\n    print(\\'\\')\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPc3BM4-tOlZ"
      },
      "source": [
        "### 2.3. Class Distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phUj1ZYwpse6"
      },
      "source": [
        "To analyze the distribution of the labels, let's first explicitly flag the comments which are not toxic (have no labels set to 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5O4Oe-mosdC"
      },
      "source": [
        "# These are the six possible labels.\n",
        "### Three\n",
        "label_cols = ['class1', 'class2', 'class3']\n",
        "\n",
        "# Select just the labels (not the text), and for every row, check whether any\n",
        "# of the labels are \"1\".\n",
        "has_labels = train[label_cols].any(axis=1)\n",
        "\n",
        "# Add a new column indicating which samples have no toxic labels.\n",
        "train['none'] = 1 - has_labels\n",
        "\n",
        "# Add the 'none' column to our list of label names.\n",
        "label_cols.append('none')"
      ],
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AefD40jnrZQR"
      },
      "source": [
        "Total the number of samples with each label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSVtWB-Op3mW",
        "outputId": "7739f84c-948c-4616-ed8c-2b9cd3eaa735"
      },
      "source": [
        "# Tally up each label separately.\n",
        "label_counts = train[label_cols].sum(axis=0)\n",
        "\n",
        "print(label_counts)"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class1    8125\n",
            "class2    4564\n",
            "class3    2214\n",
            "none         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7GiyO1LrHm4"
      },
      "source": [
        "So what percentage are toxic in some way?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtDry4sbr1lR"
      },
      "source": [
        "#print('{:.1%} of the comments are safe.'.format(label_counts['none'] / len(train)))"
      ],
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtIKdNA6nnfr"
      },
      "source": [
        "How many samples are there of each type?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "NRqXl9XQnnfs",
        "outputId": "72b239c4-be8a-4336-93b5-4acbe852a0cf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
        "\n",
        "# Plot the number of tokens of each length.\n",
        "sns.barplot(x=label_cols, y=label_counts)\n",
        "plt.title('Class Distribution')\n",
        "plt.xlabel('Category')\n",
        "plt.ylabel('# of Training Samples')\n"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, '# of Training Samples')"
            ]
          },
          "metadata": {},
          "execution_count": 278
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So0AAUbgsqkB"
      },
      "source": [
        "Based on the above, if we just predicted \"not toxic\" for *every single training sample*, we would get ~90% accuracy on the training set! So we'll have to be careful in how we interpret our accuracy on this task to make sure we're actually doing better than this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXbBB1NNv3wj"
      },
      "source": [
        "## S3. Tokenization & Truncation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHFUYGTnv3wk"
      },
      "source": [
        "We'll need to tokenize all of the text in our dataset, using BERT's own tokenizer, in order to feed the text into BERT for training. \n",
        "\n",
        "Before we do that, we have an important decision to make about the maximum \"sequence length\" (the number of tokens in an input sentence/passage). BERT is limited to a maximum input length of 512 tokens. Beyond that, long input sequences mean long training times and potential GPU memory issues. \n",
        "\n",
        "For these reasons, we'll be truncating some of the text samples to a shorter length. To decide on this length, we'll start by exploring the lengths of the text samples in our dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMHzhnmuGrpb"
      },
      "source": [
        "### 3.1. Load BertTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT0b0-5NGq0y"
      },
      "source": [
        "\n",
        "In order to see the distribution of comment lengths *in terms of BERT tokens*, we'll need to first apply the BertTokenizer to the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZiRfpUEv3wl",
        "outputId": "2d517d62-fb2b-4b72-967a-48dc33d284bf"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) #Original\n",
        "\n",
        "#tokenizer = BertTokenizer.from_pretrained('BERT-Base, Multilingual Cased', do_lower_case=True)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
        "\n"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFB46zTrv3wo"
      },
      "source": [
        "### 3.2. Comment Length Distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWKdJWEyv3wo"
      },
      "source": [
        "To decide on a truncation strategy for this dataset, let's first look at the distribution of comment lenghts.\n",
        "\n",
        "> **NOTE:** To save time, you can skip running the cells in section 3.2. (But still read through it, of course!) \n",
        "\n",
        "To do this, our first step is to tokenize all of the comments in the training set using the `tokenizer.encode` function.\n",
        "\n",
        "The `tokenizer.encode` function combines multiple steps for us:\n",
        "1. Split the sentence into tokens.\n",
        "2. Add the special `[CLS]` and `[SEP]` tokens.\n",
        "3. Map the tokens to their IDs.\n",
        "\n",
        "Later, we will use the `tokenizer.encode_plus` function, which will perform truncation and padding for us! Here, though, we just want to see the *unmodified* sequence lengths.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRgc9BE0v3wp",
        "outputId": "9cc78c4a-4ba0-474b-97c5-01b2fbcc1108"
      },
      "source": [
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "# By default, the tokenizer will spit out a warning whenever we tokenize a \n",
        "# sample which ends up being more than 512 tokens. We don't care about that for\n",
        "# now, though, and this cell will produce a lot of those warnings! So we'll \n",
        "# adjust the logging settings to suppress those warnings and keep the output\n",
        "# cell cleaner.\n",
        "logging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)\n",
        "\n",
        "# Record the length of each sequence (in terms of BERT tokens).\n",
        "lengths = []\n",
        "\n",
        "print('Tokenizing comments...')\n",
        "\n",
        "# For every sentence...\n",
        "for index, row in train.iterrows():\n",
        "    \n",
        "    # Report progress.\n",
        "    if ((len(lengths) % 20000) == 0):\n",
        "        print('  Tokenized {:,} comments.'.format(len(lengths)))\n",
        "    \n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        row['comment_text'],     # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    # Record the non-truncated length.\n",
        "    lengths.append(len(encoded_sent))\n",
        "\n",
        "print('DONE.')"
      ],
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing comments...\n",
            "  Tokenized 0 comments.\n",
            "DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSwwRWmSv3wr"
      },
      "source": [
        "Let's grab some quick statistics--what are the min, max and median comment lengths?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pt5-ukhv3wr",
        "outputId": "fcd44578-49e6-426e-e674-db91c1dc9a48"
      },
      "source": [
        "print('   Min length: {:,} tokens'.format(min(lengths)))\n",
        "print('   Max length: {:,} tokens'.format(max(lengths)))\n",
        "print('Median length: {:,} tokens'.format(int(np.median(lengths))))"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Min length: 18 tokens\n",
            "   Max length: 6,276 tokens\n",
            "Median length: 204 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1u3zyPwv3ww"
      },
      "source": [
        "To further analyze it, let's plot the distribution. To keep the scale of the x-axis reasonable, *we'll clip the lengths to 512.*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "ZJpqBsE_v3ww",
        "outputId": "66fb7c4c-73c2-4673-a45f-038e17ff7d62"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
        "\n",
        "# Truncate any comment lengths greater than 512.\n",
        "trunc_lengths = [min(l, 512) for l in lengths]\n",
        "\n",
        "# Plot the distribution of comment lengths.\n",
        "sns.distplot(trunc_lengths, kde=False, rug=False)\n",
        "\n",
        "# Alternatively, you might try using a log scale on the x-axis, but this is \n",
        "# tricky. See here for one approach:\n",
        "# https://stackoverflow.com/questions/47850202/plotting-a-histogram-on-a-log-scale-with-matplotlib?rq=1\n",
        "#plt.xscale('log')\n",
        "\n",
        "plt.title('Comment Lengths')\n",
        "plt.xlabel('Comment Length')\n",
        "plt.ylabel('# of Comments')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPqD2JpMBGvL"
      },
      "source": [
        "Clearly the majority of the comments are relatively short. Let's count up how many comments would be truncated based on different choices of `max_len`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yjyl5YAZArgB",
        "outputId": "1ccb0f34-71d5-449f-a200-97d56564e3e9"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Cast the list to a numpy array so we can use some numpy features.\n",
        "lengths = np.asarray(lengths)\n",
        "\n",
        "# Get the total number of comments.\n",
        "num_comments = len(lengths)\n",
        "\n",
        "# Check the following lengths:\n",
        "max_lens = [128, 256, 300, 400, 512]\n",
        "\n",
        "print('How many comments will be truncated?\\n')\n",
        "\n",
        "# For each choice...\n",
        "for max_len in max_lens:\n",
        "\n",
        "    # Calculate how many comments will be truncacted.\n",
        "    num_over = np.sum(lengths > max_len)\n",
        "\n",
        "    # And as a percentage.\n",
        "    prcnt_over = float(num_over) / float(num_comments)\n",
        "\n",
        "    print('max_len = {:}  -->  {:>7,} of {:>7,}  ({:>5.1%})  ' \\\n",
        "          'will be truncated '.format(\n",
        "              max_len, num_over, num_comments, prcnt_over\n",
        "          ))"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How many comments will be truncated?\n",
            "\n",
            "max_len = 128  -->   10,289 of  14,903  (69.0%)  will be truncated \n",
            "max_len = 256  -->    6,617 of  14,903  (44.4%)  will be truncated \n",
            "max_len = 300  -->    5,907 of  14,903  (39.6%)  will be truncated \n",
            "max_len = 400  -->    4,217 of  14,903  (28.3%)  will be truncated \n",
            "max_len = 512  -->    2,897 of  14,903  (19.4%)  will be truncated \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asqwSCR0zbMc"
      },
      "source": [
        "### 3.3. Choose max_len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff-eSxYL6hZC"
      },
      "source": [
        "There are several factors that impact our choice of the maximum sequence length `max_len`:\n",
        "1. **Training Time** - Training time is quadratic with `max_len`. `max_len = 512` will take 4x  longer to train than `max_len = 256`, and 16x longer than `max_len = 128`!\n",
        "2. **Accuracy** - Truncating the samples to a shorter length will presumably hurt accuracy, due to the loss of information. How much it hurts depends on the dataset, though--in a previous Notebook ([Document Classification](https://colab.research.google.com/drive/1iWrcYR_kG_6yGbCZJ0qqgaOigYlW9qc8#scrollTo=Qxi0mOhbmRLi)) which worked with the two-class version of this Wikipedia comments dataset, we found that truncation had little impact on our score.\n",
        "3. **GPU Memory** - The combination of `max_len` and `batch_size` need to fit within the memory limits of our GPU. We explored this limit in a previous Notebook ([Multiclass Classification](https://colab.research.google.com/drive/1iWrcYR_kG_6yGbCZJ0qqgaOigYlW9qc8#scrollTo=Qxi0mOhbmRLi)). For a Tesla K80 (which has 12GB of RAM!), with `batch_size = 16`, the maximum length we can use (without running of memory) is about `max_len = 400`.\n",
        "\n",
        "For this notebook, we'll use **`max_len = 128`** to speed up training times, and we'll see that BERT still delivers high accuracy on this benchmark, despite the truncation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5E9pERUEKL5"
      },
      "source": [
        "# Set our sequence length to pad or truncate all of our samples to.\n",
        "max_len = 128"
      ],
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRp4O7D295d_"
      },
      "source": [
        "### 3.4. Tokenize Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIWAoWL2RK1p"
      },
      "source": [
        "Now we're ready to perform the real tokenization.\n",
        "\n",
        "The `tokenizer.encode_plus` function combines multiple steps for us:\n",
        "\n",
        "1. Split the sentence into tokens.\n",
        "2. Add the special `[CLS]` and `[SEP]` tokens.\n",
        "3. Map the tokens to their IDs.\n",
        "4. Pad or truncate all sentences to the same length.\n",
        "5. Create the attention masks which explicitly differentiate real tokens from `[PAD]` tokens.\n",
        "6. Cast everything to pytorch tensors.\n",
        "\n",
        "The first four features are in `tokenizer.encode`, but I'm using `tokenizer.encode_plus` to get the fifth item (attention masks). Documentation is [here](https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jsHTrZEAV6-"
      },
      "source": [
        "# Optional - You can select a subsample of the dataset to run through the \n",
        "#            Notebook quicker.\n",
        "if False:\n",
        "    # Take just the first 4,000 training samples.\n",
        "    train = train[:40000]"
      ],
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca1rne6DTvLA",
        "outputId": "284cdea1-a3ab-46a4-dd57-333a3dfc517b"
      },
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "input_ids = []\n",
        "attn_masks = []\n",
        "labels = []\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# ======== Encoding ========\n",
        "\n",
        "print('Encoding {:,} training examples...'.format(len(train)))\n",
        "\n",
        "# For every training example...\n",
        "for (index, row) in train.iterrows():\n",
        "\n",
        "    # Report progress.\n",
        "    if ((len(input_ids) % 15000) == 0):\n",
        "        print('  Encoded {:,} comments.'.format(len(input_ids)))\n",
        "\n",
        "    # Convert sentence pairs to input IDs, with attention masks.\n",
        "    encoded_dict = tokenizer.encode_plus(row['comment_text'],  # The text to encode.\n",
        "                                        max_length=max_len,    # Pad or truncate to this lenght.\n",
        "                                        pad_to_max_length=True,\n",
        "                                        truncation=True, \n",
        "                                        return_tensors='pt')   # Return objects as PyTorch tensors.\n",
        "\n",
        "    # Add this example to our lists.\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attn_masks.append(encoded_dict['attention_mask'])\n",
        "    \n",
        "print('\\nDONE. {:,} examples.'.format(len(input_ids)))\n",
        "\n",
        "# ======== List of Examples --> Tensor ========\n",
        "\n",
        "# Convert each Python list of Tensors into a 2D Tensor matrix.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attn_masks = torch.cat(attn_masks, dim=0)\n",
        "\n",
        "# ======== Prepare Labels ========\n",
        "\n",
        "# Select the label columns for all examples.\n",
        "labels = train[['class1', 'class2', 'class3']]\n",
        "\n",
        "# The labels are either 0 or 1. Despite this, we need to cast the values to\n",
        "# floats--otherwise our loss function will throw an error.\n",
        "# https://discuss.pytorch.org/t/nn-bcewithlogitsloss-cant-accept-one-hot-target/59980\n",
        "labels = labels.to_numpy().astype(float)\n",
        "\n",
        "# Cast the labels list to a 2D Tensor.\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# ======== Summary ========\n",
        "\n",
        "print('\\nData structure shapes:')\n",
        "print('   input_ids:  {:}'.format(str(input_ids.shape)))\n",
        "print('  attn_masks:  {:}'.format(str(attn_masks.shape)))\n",
        "print('      labels:  {:}'.format(str(labels.shape)))\n",
        "\n",
        "print('\\nEncoding took {:.0f} seconds'.format(time.time() - t0))"
      ],
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding 14,903 training examples...\n",
            "  Encoded 0 comments.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DONE. 14,903 examples.\n",
            "\n",
            "Data structure shapes:\n",
            "   input_ids:  torch.Size([14903, 128])\n",
            "  attn_masks:  torch.Size([14903, 128])\n",
            "      labels:  torch.Size([14903, 3])\n",
            "\n",
            "Encoding took 39 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voHe1wQsQ96F"
      },
      "source": [
        "### 3.5. Split-Off a Validation Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjzJmFghC8h8"
      },
      "source": [
        "This dataset already has separate training and test sets, but we're going to further divide up our training set to use 90% for training and 10% for *validation*. This validation set will help us detect over-fitting during the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9_K_nOGUzhD"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attn_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split. Calculate the number of samples to \n",
        "# include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
      ],
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bwa6Rts-02-"
      },
      "source": [
        "## S4. Train Our Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xYQ3iLO08SX"
      },
      "source": [
        "Now that our input data is properly formatted, it's time to fine tune the BERT model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSU7yERLP_66"
      },
      "source": [
        "### 4.1. Using Colab GPU for Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI0iOY8zvZzL"
      },
      "source": [
        "\n",
        "Google Colab offers free GPUs and TPUs! Since we'll be training a large neural network it's best to take advantage of this (in this case we'll attach a GPU), otherwise training will take a very long time.\n",
        "\n",
        "A GPU can be added by going to the menu and selecting:\n",
        "\n",
        "`Edit 🡒 Notebook Settings 🡒 Hardware accelerator 🡒 (GPU)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqG7FzRVFEIv"
      },
      "source": [
        "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYsV4H8fCpZ-",
        "outputId": "f02683b5-cd33-4c03-dc4c-372bd48474c8"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBehPTA9Nvjf"
      },
      "source": [
        "### 4.1. Initialize Model with Pre-Trained Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFsCTp_mporB",
        "outputId": "58b48966-b070-4017-d7c5-ab82a5c01de9"
      },
      "source": [
        "from transformers import AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForMultiLabelSequenceClassification.from_pretrained(\n",
        "###    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    \"bert-base-chinese\", # Use the 12-layer BERT model, with an uncased vocab.    \n",
        "######\n",
        "######\n",
        "######\n",
        "\n",
        "    num_labels = 3,   \n",
        " \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "desc = model.cuda()\n",
        "\n",
        "print (\"Model loaded.\")"
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EuV5XkeRENS"
      },
      "source": [
        "### 4.4. Batch Size & DataLoaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD9i6Z2pG-sN"
      },
      "source": [
        "We'll also create a PyTorch DataLoader for our dataset. \n",
        "\n",
        "The DataLoader simply handles the creation of training batches for us. \n",
        "\n",
        "**Choice of Batch Size**\n",
        "\n",
        "Training on a small batch of training samples at once (rather than one sample at a time) makes more efficient use of our GPU's parallel processing capabilities, and seems to even improve the model's accuracy.\n",
        "\n",
        "The BERT authors recommend trying a batch size of either 16 or 32. For this Notebook, we'll be using a **batch size of 16**.\n",
        "\n",
        "**Randomization**\n",
        "\n",
        "The DataLoader for our training set will construct batches for us by randomly selecting different samples to put in each batch (each training sample will only appear in one batch, though!). \n",
        "\n",
        "Randomizing the training samples is considered good practice. Moreover, I believe the randomization is re-done for each training epoch (each pass through our training set), and that this can improve model accuracy.\n",
        "\n",
        "For validation, it doesn't matter what order we execute in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBFuDdywU2DB"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Specify our batch size.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmgT0TDKULHr"
      },
      "source": [
        "### 4.5. Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-VEBobKwHk"
      },
      "source": [
        "Our `model` object handles the execution of a forward pass, and the calculation of gradients during training. \n",
        "\n",
        "The actual updates to the model's weights, however, are performed by an Optimizer object. Here, we create that object and give it a reference to our model's parameters, as well as set some of our training hyperparameters.\n",
        "\n",
        "For the purposes of fine-tuning, the authors recommend the following choices of learning rates: 5e-5, 3e-5, 2e-5  (We'll use 2e-5).\n",
        "\n",
        "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
        "\n",
        "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5,\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iaG0A5quuqz"
      },
      "source": [
        "### 4.6. Epochs & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGeSUdv_wDgF"
      },
      "source": [
        "The learning rate scheduler is responsible for updating the learning rate over the course of the training. Generally speaking, you want the learning rate to gradually get smaller and smaller so that training makes gradually finer adjustments to the weights. \n",
        "\n",
        "This decay needs to happen *across all of the training epochs*, so this is where we need to specify the number of epochs we want to train for. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoSUMnW1U4Mu"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (BERT authors recommend between 2 and 4)\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF2REdBeVJsp"
      },
      "source": [
        "**Helper Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNhRtWPXH9C3"
      },
      "source": [
        "Helper function for formatting elapsed times.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWBru237exn4"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))  \n"
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ginim8z1VX2K"
      },
      "source": [
        "Helper function to automatically pick a reasonable interval for printing out a progress update during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do7r4TRjexrc"
      },
      "source": [
        "def good_update_interval(total_iters, num_desired_updates):\n",
        "    '''\n",
        "    This function will try to pick an intelligent progress update interval \n",
        "    based on the magnitude of the total iterations.\n",
        "\n",
        "    Parameters:\n",
        "      `total_iters` - The number of iterations in the for-loop.\n",
        "      `num_desired_updates` - How many times we want to see an update over the \n",
        "                              course of the for-loop.\n",
        "    '''\n",
        "    # Divide the total iterations by the desired number of updates. Most likely\n",
        "    # this will be some ugly number.\n",
        "    exact_interval = total_iters / num_desired_updates\n",
        "\n",
        "    # The `round` function has the ability to round down a number to, e.g., the\n",
        "    # nearest thousandth: round(exact_interval, -3)\n",
        "    #\n",
        "    # To determine the magnitude to round to, find the magnitude of the total,\n",
        "    # and then go one magnitude below that.\n",
        "\n",
        "    # Get the order of magnitude of the total.\n",
        "    order_of_mag = len(str(total_iters)) - 1\n",
        "\n",
        "    # Our update interval should be rounded to an order of magnitude smaller. \n",
        "    round_mag = order_of_mag - 1\n",
        "\n",
        "    # Round down and cast to an int.\n",
        "    update_interval = int(round(exact_interval, -round_mag))\n",
        "\n",
        "    # Don't allow the interval to be zero!\n",
        "    if update_interval == 0:\n",
        "        update_interval = 1\n",
        "\n",
        "    return update_interval"
      ],
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fFhFF9x2SPu"
      },
      "source": [
        "Submissions for the Toxic Comments Challenge are evaluated \"on the mean column-wise ROC AUC\". In other words, the score is the average of the individual AUCs of each predicted column.\n",
        "\n",
        "This is accomplished by setting `average='macro'` in our call to the `roc_auc_score` function from scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tchEi_k2UAA",
        "outputId": "3ec48d5d-1f8d-4757-a2af-0c0ab4167464"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# A quick example...\n",
        "true_labels = [0,1,0,0,1]\n",
        "pred_labels = [0,1,0,0,0]\n",
        "\n",
        "score = roc_auc_score(true_labels, pred_labels, average='macro')\n",
        "\n",
        "print('Example ROC AUC score:', score)"
      ],
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example ROC AUC score: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5-THlhKepL5"
      },
      "source": [
        "### 4.7. Training loop\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB06aBGEev3e",
        "outputId": "e7bd73ed-f6df-4abf-e9c1-b516f2af4cc4"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # Pick an interval on which to print progress updates.\n",
        "    update_interval = good_update_interval(\n",
        "                total_iters = len(train_dataloader), \n",
        "                num_desired_updates = 10\n",
        "            )\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update.\n",
        "        if (step % update_interval) == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This call returns the loss (because we provided labels) and the \n",
        "        # \"logits\"--the model outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        " \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_loss = 0\n",
        "\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():   \n",
        "   \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "\n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Store predictions and true labels\n",
        "        predictions.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "\n",
        "    # Measure validation accuracy...\n",
        "\n",
        "    # Combine the results across all batches. \n",
        "    flat_predictions = np.concatenate(predictions, axis=0)\n",
        "    flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "    # Calculate the validation accuracy.\n",
        "    val_accuracy = roc_auc_score(flat_true_labels, flat_predictions, average='macro')\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    80  of    839.    Elapsed: 0:00:17.\n",
            "  Batch   160  of    839.    Elapsed: 0:00:34.\n",
            "  Batch   240  of    839.    Elapsed: 0:00:50.\n",
            "  Batch   320  of    839.    Elapsed: 0:01:07.\n",
            "  Batch   400  of    839.    Elapsed: 0:01:24.\n",
            "  Batch   480  of    839.    Elapsed: 0:01:41.\n",
            "  Batch   560  of    839.    Elapsed: 0:01:57.\n",
            "  Batch   640  of    839.    Elapsed: 0:02:14.\n",
            "  Batch   720  of    839.    Elapsed: 0:02:31.\n",
            "  Batch   800  of    839.    Elapsed: 0:02:48.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epcoh took: 0:02:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "  Validation Loss: 0.24\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    80  of    839.    Elapsed: 0:00:17.\n",
            "  Batch   160  of    839.    Elapsed: 0:00:34.\n",
            "  Batch   240  of    839.    Elapsed: 0:00:50.\n",
            "  Batch   320  of    839.    Elapsed: 0:01:07.\n",
            "  Batch   400  of    839.    Elapsed: 0:01:24.\n",
            "  Batch   480  of    839.    Elapsed: 0:01:41.\n",
            "  Batch   560  of    839.    Elapsed: 0:01:57.\n",
            "  Batch   640  of    839.    Elapsed: 0:02:14.\n",
            "  Batch   720  of    839.    Elapsed: 0:02:31.\n",
            "  Batch   800  of    839.    Elapsed: 0:02:48.\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epcoh took: 0:02:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.20\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    80  of    839.    Elapsed: 0:00:17.\n",
            "  Batch   160  of    839.    Elapsed: 0:00:34.\n",
            "  Batch   240  of    839.    Elapsed: 0:00:50.\n",
            "  Batch   320  of    839.    Elapsed: 0:01:07.\n",
            "  Batch   400  of    839.    Elapsed: 0:01:24.\n",
            "  Batch   480  of    839.    Elapsed: 0:01:41.\n",
            "  Batch   560  of    839.    Elapsed: 0:01:57.\n",
            "  Batch   640  of    839.    Elapsed: 0:02:14.\n",
            "  Batch   720  of    839.    Elapsed: 0:02:31.\n",
            "  Batch   800  of    839.    Elapsed: 0:02:48.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Training epcoh took: 0:02:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.21\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:09:06 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNuteN1Fmju0"
      },
      "source": [
        "### 4.8. Training Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "29a6a3ba-8450-4b41-d2e7-4f8259cd658c"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.24</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0:02:56</td>\n",
              "      <td>0:00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.18</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0:02:56</td>\n",
              "      <td>0:00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.14</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0:02:56</td>\n",
              "      <td>0:00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.24         0.24           0.96       0:02:56         0:00:06\n",
              "2               0.18         0.20           0.97       0:02:56         0:00:06\n",
              "3               0.14         0.21           0.97       0:02:56         0:00:06"
            ]
          },
          "metadata": {},
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-G03mmwH3aI"
      },
      "source": [
        "We can plot the training loss and validation loss to check if our model is overfitting. \n",
        "\n",
        "> When checking for over-fitting, loss is a better indicator than accuracy. Accuracy only takes into account whether the model's output was on the correct side of the decision threshold, whereas loss also incorporates the model's *confidence*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "615f4911-1b51-47bb-9708-68a1ee7c7acf"
      },
      "source": [
        "#'''\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()\n",
        "#'''"
      ],
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvUAAAGaCAYAAACPCLyfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVyU1f7A8c8MDMOqCIIoiwsKKAKJu5KggpKau2l5tTIrLZdbv3szb3az7vW2aFlqeUutzExzX3JFFNfUUHNHC5VFERHZ92Hm94cXdASUUYYB/L5fr/u6cZ7nOc+ZiW9858w530eh0+l0CCGEEEIIIWotpakHIIQQQgghhHg0ktQLIYQQQghRy0lSL4QQQgghRC0nSb0QQgghhBC1nCT1QgghhBBC1HKS1AshhBBCCFHLSVIvhHjsJSYm4u3tzfz58x+6j7fffhtvb+8qHFXdVdH77e3tzdtvv12pPubPn4+3tzeJiYlVPr5169bh7e3NkSNHqrxvIYQwFnNTD0AIIe5lSHIcGRmJm5ubEUdT++Tm5vLf//6XrVu3cuPGDRwcHGjfvj2vvfYanp6elepjypQp7Nixgw0bNtC6detyz9HpdPTu3ZvMzEwOHDiApaVlVb4Mozpy5AhHjx7l+eefp169eqYeThmJiYn07t2b0aNH889//tPUwxFC1AKS1AshapxPPvlE7+djx47x888/M3LkSNq3b693zMHB4ZHv5+rqyqlTpzAzM3voPv71r3/x/vvvP/JYqsKMGTPYsmULAwYMoFOnTqSkpLB7925OnjxZ6aR++PDh7Nixg7Vr1zJjxoxyzzl8+DBXr15l5MiRVZLQnzp1CqWyer5APnr0KAsWLGDIkCFlkvpBgwbRv39/VCpVtYxFCCGqgiT1QogaZ9CgQXo/FxcX8/PPP/PEE0+UOXav7OxsbG1tDbqfQqFArVYbPM671ZQEMC8vj+3btxMUFMSnn35a2j5p0iQKCwsr3U9QUBCNGzdm8+bNvPXWW1hYWJQ5Z926dcDtDwBV4VH/HVQVMzOzR/qAJ4QQpiBr6oUQtVavXr0YM2YM586d46WXXqJ9+/YMHDgQuJ3cz507lxEjRtC5c2fatm1LWFgYc+bMIS8vT6+f8tZ43922Z88ehg0bhp+fH0FBQXz88cdoNBq9PspbU1/SlpWVxXvvvUfXrl3x8/Nj1KhRnDx5sszrSUtLY/r06XTu3Jl27doxduxYzp07x5gxY+jVq1el3hOFQoFCoSj3Q0Z5iXlFlEolQ4YMIT09nd27d5c5np2dzc6dO/Hy8sLf39+g97si5a2p12q1fP311/Tq1Qs/Pz8GDBjApk2byr0+NjaWmTNn0r9/f9q1a0dAQABDhw5l9erVeue9/fbbLFiwAIDevXvj7e2t9++/ojX1t27d4v333yc4OJi2bdsSHBzM+++/T1pamt55Jdf/+uuvLFmyhNDQUNq2bUvfvn1Zv359pd4LQ8TExPD666/TuXNn/Pz86NevH4sWLaK4uFjvvKSkJKZPn07Pnj1p27YtXbt2ZdSoUXpj0mq1fP/99zz99NO0a9eOwMBA+vbtyz/+8Q+KioqqfOxCiKojM/VCiFrt2rVrPP/884SHh9OnTx9yc3MBSE5OZs2aNfTp04cBAwZgbm7O0aNHWbx4MefPn2fJkiWV6n/v3r389NNPjBo1imHDhhEZGcm3335L/fr1mTBhQqX6eOmll3BwcOD1118nPT2d7777jldeeYXIyMjSbxUKCwt58cUXOX/+PEOHDsXPz48LFy7w4osvUr9+/Uq/H5aWlgwePJi1a9fyyy+/MGDAgEpfe6+hQ4eycOFC1q1bR3h4uN6xLVu2kJ+fz7Bhw4Cqe7/v9eGHH/LDDz/QsWNHXnjhBVJTU/nggw9wd3cvc+7Ro0eJjo4mJCQENze30m8tZsyYwa1bt3j11VcBGDlyJNnZ2URERDB9+nQaNGgA3H8vR1ZWFs8++yxxcXEMGzaMNm3acP78eVasWMHhw4dZvXp1mW+I5s6dS35+PiNHjsTCwoIVK1bw9ttv4+HhUWYZ2cM6ffo0Y8aMwdzcnNGjR9OwYUP27NnDnDlziImJKf22RqPR8OKLL5KcnMxzzz1Hs2bNyM7O5sKFC0RHRzNkyBAAFi5cyLx58+jZsyejRo3CzMyMxMREdu/eTWFhYY35RkoIUQ6dEELUcGvXrtV5eXnp1q5dq9fes2dPnZeXl27VqlVlrikoKNAVFhaWaZ87d67Oy8tLd/LkydK2hIQEnZeXl27evHll2gICAnQJCQml7VqtVte/f39d9+7d9fqdNm2azsvLq9y29957T69969atOi8vL92KFStK23788Uedl5eX7quvvtI7t6S9Z8+eZV5LebKysnQvv/yyrm3btro2bdrotmzZUqnrKjJ27Fhd69atdcnJyXrtzzzzjM7X11eXmpqq0+ke/f3W6XQ6Ly8v3bRp00p/jo2N1Xl7e+vGjh2r02g0pe1nzpzReXt767y8vPT+3eTk5JS5f3Fxse4vf/mLLjAwUG988+bNK3N9iZLft8OHD5e2ffbZZzovLy/djz/+qHduyb+fuXPnlrl+0KBBuoKCgtL269ev63x9fXVvvPFGmXveq+Q9ev/99+973siRI3WtW7fWnT9/vrRNq9XqpkyZovPy8tIdOnRIp9PpdOfPn9d5eXnpvvnmm/v2N3jwYN1TTz31wPEJIWoeWX4jhKjV7O3tGTp0aJl2CwuL0llFjUZDRkYGt27dolu3bgDlLn8pT+/evfWq6ygUCjp37kxKSgo5OTmV6uOFF17Q+7lLly4AxMXFlbbt2bMHMzMzxo4dq3fuiBEjsLOzq9R9tFotU6dOJSYmhm3bttGjRw/+9re/sXnzZr3z3n33XXx9fSu1xn748OEUFxezYcOG0rbY2Fh+//13evXqVbpRuare77tFRkai0+l48cUX9da4+/r60r179zLnW1tbl/5zQUEBaWlppKen0717d7Kzs7l06ZLBYygRERGBg4MDI0eO1GsfOXIkDg4O7Nq1q8w1zz33nN6Sp0aNGtG8eXOuXLny0OO4W2pqKidOnKBXr174+PiUtisUCiZOnFg6bqD0d+jIkSOkpqZW2KetrS3JyclER0dXyRiFENVHlt8IIWo1d3f3Cjc1Ll++nJUrV/Lnn3+i1Wr1jmVkZFS6/3vZ29sDkJ6ejo2NjcF9lCz3SE9PL21LTEzE2dm5TH8WFha4ubmRmZn5wPtERkZy4MABZs+ejZubG1988QWTJk3irbfeQqPRlC6xuHDhAn5+fpVaY9+nTx/q1avHunXreOWVVwBYu3YtQOnSmxJV8X7fLSEhAYAWLVqUOebp6cmBAwf02nJycliwYAHbtm0jKSmpzDWVeQ8rkpiYSNu2bTE31/+zaW5uTrNmzTh37lyZayr63bl69epDj+PeMQG0bNmyzLEWLVqgVCpL30NXV1cmTJjAN998Q1BQEK1bt6ZLly6Eh4fj7+9fet2bb77J66+/zujRo3F2dqZTp06EhITQt29fg/ZkCCGqnyT1QohazcrKqtz27777jo8++oigoCDGjh2Ls7MzKpWK5ORk3n77bXQ6XaX6v18VlEfto7LXV1bJxs6OHTsCtz8QLFiwgIkTJzJ9+nQ0Gg0+Pj6cPHmSWbNmVapPtVrNgAED+Omnnzh+/DgBAQFs2rQJFxcXnnzyydLzqur9fhT/93//R1RUFM888wwdO3bE3t4eMzMz9u7dy/fff1/mg4axVVd5zsp64403GD58OFFRUURHR7NmzRqWLFnC+PHj+fvf/w5Au3btiIiI4MCBAxw5coQjR47wyy+/sHDhQn766afSD7RCiJpHknohRJ20ceNGXF1dWbRokV5ytW/fPhOOqmKurq78+uuv5OTk6M3WFxUVkZiYWKkHJJW8zqtXr9K4cWPgdmL/1VdfMWHCBN59911cXV3x8vJi8ODBlR7b8OHD+emnn1i3bh0ZGRmkpKQwYcIEvffVGO93yUz3pUuX8PDw0DsWGxur93NmZiZRUVEMGjSIDz74QO/YoUOHyvStUCgMHsvly5fRaDR6s/UajYYrV66UOytvbCXLwv78888yxy5duoRWqy0zLnd3d8aMGcOYMWMoKCjgpZdeYvHixYwbNw5HR0cAbGxs6Nu3L3379gVufwPzwQcfsGbNGsaPH2/kVyWEeFg1axpBCCGqiFKpRKFQ6M0QazQaFi1aZMJRVaxXr14UFxfzww8/6LWvWrWKrKysSvURHBwM3K66cvd6ebVazWeffUa9evVITEykb9++ZZaR3I+vry+tW7dm69atLF++HIVCUaY2vTHe7169eqFQKPjuu+/0yjOePXu2TKJe8kHi3m8Ebty4UaakJdxZf1/ZZUGhoaHcunWrTF+rVq3i1q1bhIaGVqqfquTo6Ei7du3Ys2cPFy9eLG3X6XR88803AISFhQG3q/fcW5JSrVaXLm0qeR9u3bpV5j6+vr565wghaiaZqRdC1Enh4eF8+umnvPzyy4SFhZGdnc0vv/xiUDJbnUaMGMHKlSv5/PPPiY+PLy1puX37dpo2bVqmLn55unfvzvDhw1mzZg39+/dn0KBBuLi4kJCQwMaNG4HbCdqXX36Jp6cnTz31VKXHN3z4cP71r3+xf/9+OnXqVGYG2Bjvt6enJ6NHj+bHH3/k+eefp0+fPqSmprJ8+XJ8fHz01rHb2trSvXt3Nm3ahKWlJX5+fly9epWff/4ZNzc3vf0LAAEBAQDMmTOHp59+GrVaTatWrfDy8ip3LOPHj2f79u188MEHnDt3jtatW3P+/HnWrFlD8+bNjTaDfebMGb766qsy7ebm5rzyyiu88847jBkzhtGjR/Pcc8/h5OTEnj17OHDgAAMGDKBr167A7aVZ7777Ln369KF58+bY2Nhw5swZ1qxZQ0BAQGly369fP5544gn8/f1xdnYmJSWFVatWoVKp6N+/v1FeoxCiatTMv25CCPGIXnrpJXQ6HWvWrGHWrFk4OTnx1FNPMWzYMPr162fq4ZVhYWHB0qVL+eSTT4iMjGTbtm34+/vz/fff884775Cfn1+pfmbNmkWnTp1YuXIlS5YsoaioCFdXV8LDwxk3bhwWFhaMHDmSv//979jZ2REUFFSpfp9++mk++eQTCgoKymyQBeO93++88w4NGzZk1apVfPLJJzRr1ox//vOfxMXFldmcOnv2bD799FN2797N+vXradasGW+88Qbm5uZMnz5d79z27dvzt7/9jZUrV/Luu++i0WiYNGlShUm9nZ0dK1asYN68eezevZt169bh6OjIqFGjmDx5ssFPMa6skydPlls5yMLCgldeeQU/Pz9WrlzJvHnzWLFiBbm5ubi7u/O3v/2NcePGlZ7v7e1NWFgYR48eZfPmzWi1Who3bsyrr76qd964cePYu3cvy5YtIysrC0dHRwICAnj11Vf1KuwIIWoeha46di8JIYR4KMXFxXTp0gV/f/+HfoCTEEKIuk/W1AshRA1R3mz8ypUryczMLLcuuxBCCFFClt8IIUQNMWPGDAoLC2nXrh0WFhacOHGCX375haZNm/LMM8+YenhCCCFqMFl+I4QQNcSGDRtYvnw5V65cITc3F0dHR4KDg5k6dSoNGzY09fCEEELUYJLUCyGEEEIIUcvJmnohhBBCCCFqOUnqhRBCCCGEqOVko6yB0tJy0GqrdsWSo6MtqanZVdqnEOI2iS8hjEfiSwjjUCoVNGhgY9A1ktQbSKvVVXlSX9KvEMI4JL6EMB6JLyFqBll+I4QQQgghRC0nSb0QQgghhBC1nCT1QgghhBBC1HKS1AshhBBCCFHLSVIvhBBCCCFELSfVb4QQQgghqkBeXg7Z2RkUFxeZeiiiBjMzU2FrWx8rK8NKVj6IJPVCCCGEEI+oqKiQrKw07O0bolKpUSgUph6SqIF0Oh1FRQWkp9/E3FyFSmVRZX2bdPlNYWEhs2fPJigoCH9/f5555hl+/fXXB163c+dO/vrXv9KrVy8CAgIIDw/n448/Jisr677XnTx5Eh8fH7y9vcnMzKyqlyGEEEKIx1xWVjq2tvWxsLCUhF5USKFQYGFhiY1NfbKz06u0b5Mm9W+//TZLly5l4MCBvPPOOyiVSl5++WVOnDhx3+veffddYmNjGTRoEDNmzCAoKIhly5bx7LPPUlBQUO41Op2Of//731hZWRnjpQghhBDiMabRFKJWS44hKsfS0oqiosIq7dNky29OnTrFli1bmD59Oi+88AIAgwcPZsCAAcyZM4fly5dXeO28efPo3LmzXlvbtm2ZNm0aW7ZsYejQoWWuWb9+PfHx8QwbNoxly5ZV6Wt5WL+evc66vbHcyizAoZ6aocGedPV1MfWwhBBCCGEgrbYYpdLM1MMQtYRSaYZWW1y1fVZpbwbYvn07KpWKESNGlLap1WqGDx/OsWPHuHHjRoXX3pvQA4SGhgIQGxtb5lh2djafffYZkyZNon79+lUw+kf369nrLN0WQ2pmATogNbOApdti+PXsdVMPTQghhBAPQZbdiMoyxu+KyZL68+fP07x5c2xs9Hf++vv7o9PpOH/+vEH93bx5E4AGDRqUOfbVV19ha2vLs88++/ADrmLr9sZSqNHqtRVqtKzbW/ZDiRBCCCGEEPdjsuU3KSkpNGrUqEy7k5MTwH1n6suzaNEizMzM6NOnj177lStX+OGHH5g/fz7m5o/+ch0dbR+5D4BbmeWv/b+VWYCTk12V3EMIcZvElBDGI/F1240bSszN5fE/D2PixJcBWLhwUbVea2pKpbJK48dkSX1+fj4qlapMu1qtBqhww2t5Nm/ezJo1a3j11Vfx8PDQO/bhhx/SsWNHevbs+WgD/p/U1Gy0Wt0j9+NQT026+WXM3S+isMhHV2iJJsEL24JmpKTcv4qPEKLynJzsJKaEMBKJrzu0Wi2ae76Br+2CgjpU6rzVqzfRuHGTh76PTnc7r3qY9+9RrjU1rVZbYfwolQqDJ5JNltRbWlpSVFT24QwlyXxJcv8g0dHRvPPOO4SEhDB16lS9Y/v27WP//v2sX7/+0Qdcxdp1KuRA2hkUZrd/CRXqfFTNz5BzBQ6fbUkX2TArhBBCCBN6990P9H5etWoFyclJTJ78pl67vX3Zpc+GmDv3S5NcW9eYLKl3cnIqd4lNSkoKAM7Ozg/sIyYmhokTJ+Lt7c3cuXMxM9PfdT579mx69eqFjY0NiYmJAKX16a9du0Z+fn6l7mMM5wp+LU3oSyjMtFg2/ZNvNjchMSWHocEtUMqmGyGEEEKYQN++/fR+joqKJCMjvUz7vfLz87G0tKz0fcpbuVEd19Y1JkvqfXx8WLZsGTk5OXqbZU+ePFl6/H7i4+MZP348Dg4OfP3111hbW5c5JykpiYsXLxIREVHm2KBBgwgICGDVqlWP+EoeTlpB+Q8cKDbPpUM7c7YejuPazRxefroNVmp58K8QQgghap5Jk14hOzubt976B/Pnz+XChRhGjx7LSy+9yv79UWzatJ6LFy+QmZmBk5Mz/fo9zZgxL+pNxE6a9AoACxZ8A8Dx49FMmTKBWbM+4fLlS2zYsJbMzAz8/AL4+9//gZube5VcC7B27SpWrlxOaupNPD09mTTpDRYtWqjXZ21hsmwxPDycb7/9ltWrV5fWqS8sLGTdunUEBgaWbqK9du0aeXl5eHp6ll6bkpLCuHHjUCgULFmyBAcHh3LvMWfOHDQajV7bli1b2Lp1K7Nnz6Zx48bGeXGV0EBtX25ir0DBWdUvuHd15cx5F/69LJepw/xxblD2Q4sQQggh6q6S59mkZhbgWIOfZ5OensZbb71Bnz7hhIf3p1Gj22PcuvUXrKysGTlyNNbWVhw7Fs3ixf8lJyeH11+f+oBeYenSJSiVZjz33FiysjJZsWIZ778/g0WLllbJtevXr2Hu3E944olARo58lqSkJKZP/xt2dnY4OZlmJcejMFlSHxAQQHh4OHPmzCElJQUPDw/Wr1/PtWvX+PDDD0vPmzZtGkePHuXChQulbePHjychIYHx48dz7Ngxjh07VnrMw8ODdu3aARASElLmviWlMkNCQqhXr56RXt2DDfQM56eYtRRp7+wrUClVjGg1iILifCIT9qPyOkZ63kU+2HiJCcFhtG3uZLLxCiGEEKL6lDzPpqT8dcnzbIAal9jfvJnC22+/y4ABg/TaZ878N2r1nWU4gwcPZ/bs/7B+/WpefnkiFhYW9+1Xo9Hw7bdLS6sX1qtXny++mMOlS3/SokXLR7q2qKiIxYsX4uvrx+eff1V6XsuWrZg1a6Yk9Yb65JNP+Pzzz9m4cSMZGRl4e3vzzTff0L59+/teFxNz+5d68eLFZY4NGTKkNKmvyTq5BAKwKXY76QXp2KvtGegZXtoe7Nad6OTf2XZ5NylWv/NVTAxPXO/E2I5hWJpXbhOxEEIIIUzr4OkkDpxKMvi62GsZaIr1q+0VarR8t/U8+36/ZnB/Qf6N6e5nnBUKlpaWhIf3L9N+d0Kfm5tDYWERAQHt2LhxHXFxV2jVyuu+/fbvP1CvHHlAwBMAXLt29YFJ/YOujYk5R0ZGBq+9NkTvvLCwcObN++y+fddUJk3q1Wo106ZNY9q0aRWes2zZsjJtd8/aG2ry5MlMnjz5oa+vSp1cAunkElhuSTAzpRmdG7eno0s7Tlw/x4pT2ziZt49pe4/Qu1kQvdyDsLWwqaBnIYQQQtRm9yb0D2o3JScn53KfBXTpUiyLFi3k+PHfyMnJ0TuWk5P9wH5LlvGUsLO7vcIiK+vBZVQfdO3167c/aN27xt7c3Nyky7MfhezArOGUCiXtG7elXSNfvt93iKOpv7IjLpLdCfvo1qQjvd174GhV/p4CIYQQQphWd7+HmyH/+1cHSS3nQZWO9dRMGx1YFUOrMnfPyJfIyspi8uRXsLa25aWXJuDq6oaFhQUXL8awcOF8tNoH15VXKs3KbS+pTW+sa2srSeprCaVSwbiQ7rQ568l3e6Ixd73Cft1h9l89TKCzP2EeIbjZPfyDH4QQQghRcwwN9tRbUw9gYa5kaLDnfa6qOU6cOEZGRgazZs3miSfufAhJSjJ86ZAxuLjc/qCVmJhAQMCdZdsajYakpCQ8Pe+/vKcmkqS+luni60Ijhx7MX2tPYUJL/LtkcvrmKaKTf6e1gxd9mobQyt4ThdS3F0IIIWqtks2wtaH6TXmUSiWgPzNeVFTE+vWrTTUkPT4+bahfvz6bNq2nb99+pcuHIiK2k5WVaeLRPRxJ6muh5o3r8e7zHVmw7jS/7bZgQNBfsPa4SlTiQb448Q1N7dwJaxpCgJMvSoXS1MMVQgghxEPo6utSa5L4e/n5+WNnV49Zs2YyfPhIFAoFO3ZspaasflGpVIwb9wpz587mr399jZ49e5OUlMS2bZtxdXWrlZOjkvHVUg3s1Lw9uh1dfRvxy4FrXD7ZiHc6vsUo7yHkaHJZfGYZ/zo8h4NXj1BUXPTgDoUQQgghqkj9+vZ88slcHB0bsmjRQlas+JEOHTrz2mtTTD20UsOGjeSvf/0b168n8eWXX3Dy5Ak++ugzbG3tsLCofZUGFbq6vGPACFJTs9Fqq/YtK6/6TWXpdDq2H41nzZ5YPBrZMXmYH/Z2FvyecoaIuD3EZ12lnoUdPd2DeNK1C1bmVlU6diFqukeJLyHE/Ul83XH9ehwuLk1NPQzxiLRaLQMGhBEc3JNp02YY9V73+51RKhU4Otoa1J8sv6nlFAoFT3VuimtDG77edJYPlkYzaagfga7+tHPy40Lan0TERbExdhs7ruwmyLULPd2DsFfXN/XQhRBCCCFMpqCgALVaf0Z++/YtZGZm0K7d/Z+ZVBPJTL2BatpM/d2u3cxh3tpT3MrMZ2xfH4L875TQis9KZFfcXo7fOIWZQkknl0BCPYJpZFP7npgmhCFkJlEI45H4ukNm6muf3347wsKF8wkJ6UW9evW5eDGGLVs20bRpM5Ys+RGVSmXU+1f1TL3ZzJkzZ1bBuB4beXmFVb7Jw8ZGTW5u4SP3Y2dtQRdfFy4nZbLztwTyCjS0btYApUJBfXU92jn708klEI1Ww5Hrx4hKPEhidhIOlg1oYCkz96Juqqr4EkKUJfF1R3Z2Bra29qYehjDQ6dMn2bcvir17d5OcnEzPnr15990PsLExLKF+GPf7nVEoFFhbWxjUn8zUG6gmz9SXKNZqWRn5J5HHEmnb3IEJg3yxttT/tJlVmE1U4kH2JR4iV5NHK/sWhHoE4+voUyt3fAtREZlJFMJ4JL7ukJl6YSiZqTexmjxTX0KpUODv6Yi9rQW7j18l+kIKvs0aYHfXJz61mQXeDVrSw7UbdiobzqTGcODaYX5POYOluRoXa2cphynqBJlJFMJ4JL7ukJl6YSiZqTex2jBTf7eLCel8uf40mmIdEwf50raFY7nnabQajiWfJCI+iqScZBqo7ent0YNuTTqhNjPsl0qImkRmEoUwHomvO2SmXhhKZupNrDbM1N/Nsb4lHX2cOR17i53RCVhZmNGiSb0yS2yUCiVudk0Icu1C03puJOVc5+C1Ixy4epiC4kKa2LhgIcm9qIVkJlEI45H4ukNm6oWhqnqmXpJ6A9W2pB7A2lJF17aNuJ6aS0R0IqmZ+fi1cMRMWXbtvEKhoJG1E12bdKS1QytuFaRz8NoR9iYeIrMwCxdrZ6xVUute1B6SdAhhPBJfd0hSLwxV1Um91Kl/TFhamDNxSFs2HbjMpoNXuH4rl0lD/KhvW/ET01rUb8YE/xe4npNMRPxeDlw9wv6rhwl09ifMIwQ3uybV+AqEEEIIIURFZE29gWrbmvryRMfcYPGWc9hYqpgyzJ+mLnaVui4tP509CQc4cO32kpzWDl70aRpCK3tPqZgjaixZ8yuE8Uh83SFr6oWhqnpNvST1BqoLST1AfHIW89aeIju3iHH9W9OpdaNKX5tblMu+q4eJSjhAVlE2Te3cCWsaQoCTr1TMETWOJB1CGI/E1x2S1AtDVXVSLxnYY8qjkR3vPt8RDxc7/rvxLOv3XUJbyc931iprwpv14oNu0xnlPYQcTS6LzyzjX0fmcPDqEYqKi4w8eiGEEELUNlu3bkAHGqEAACAASURBVCYoqANJSddK24YPf5pZs2Y+1LWP6vjxaIKCOnD8eHSV9WlKktQ/xurbWPD3Ue0I8m/M5kNX+Gr9GfILNZW+3sJMxZOuXXmvy995qe1fsDRT89OFtfzz14/YGbeHPE2eEUcvhBBCCGN66603CA0NIi+v4r/nb745ib59gykoKKjGkRlm164drFr1k6mHYXSyUfYxpzJX8uJTPrg727Iy8g/+syyXKcP8aWhf+Qo3SoWSQGd/2jn5cSHtTyLiotgYu40dV3YT5NqFnu5B2KvrG/FVCCGEEKKqhYX15dCh/Rw4sJewsPAyx9PSbnHs2G/06fMUanXFhTfu56ef1qJUGneOOTJyJ3/8cZFnnnlOr/2JJwKJjDyISqUy6v2ri8zUCxQKBWEd3HnzmSe4lVnAB0ujuRCf9lD9+Di0YnK7l5nWcQq+jj5Exu/jvUMfsfz8apJzbhhh9EIIIYQwhiefDMHKyppdu3aUe3z37l0UFxfTp0/ZhL+yLCwsMDc3zRyzUqlErVYb/UNFdZGZelHKt7kDM57vwLw1p5iz8ndG9/Ei5AnXh+rLw86NcW1H83RuOJEJ+zic9Bu/JkXj7+RLmEcIzet7VPHohRBCCFGVLC0tefLJYPbs2UVmZib16tXTO75r1w4cHR1xd2/KnDkfcezYUZKTk7G0tCQwsAOvvz6Vxo3vX/56+PCnadeuPe+8M7O07dKlWD7/fDZnzpymfv36DBo0lIYNncpcu39/FJs2refixQtkZmbg5ORMv35PM2bMi5iZmQEwadIr/P77cQCCgjoA4OLSmDVrNnP8eDRTpkxg3rz/EhjYobTfyMid/Pjj98TFXcHa2obu3Z9k4sQp2NvfqSk/adIrZGdn889/fsBnn33C+fNnsbOrx4gRoxg9+nnD3ugqIkm90OPiYM2MsR34etNZfth+gcQb2Yzq3Qpzs4f7FOtk7cgo7yH0bx5GVOJB9iUe4mTKGVrZtyDUIxhfRx8phymEEEKU4+j142yK3U5aQToN1PYM9Aynk0tgtY4hLCycnTu3ERUVycCBQ0rbr19P4syZUwwfPorz589y5swpQkP74uTkTFLSNTZsWMvkya/y44+rsbS0rPT9UlNvMmXKBLRaLX/5y/NYWlqxadP6cpf3bN36C1ZW1owcORprayuOHYtm8eL/kpOTw+uvTwXg+efHkZeXR3JyEpMnvwmAlZV1hfffunUz//nP+/j6+jFx4hRu3Ehm7dqfOX/+LIsW/aA3jszMDP7v/6bQs2dvevfuw549u1i4cD4tWrSka9fulX7NVUWSelGGtaU5U4f7syYqlu1H40lKzWXi4LbYWj38mjM7C1uebtGXMI8QDl07QmTCfhae+o4mNi6ENQ2hvXMAZkqzKnwVQgghRO119PpxfopZS5H2dkW5tIJ0fopZC1CtiX3Hjp2xt2/Arl079JL6Xbt2oNPpCAvri6dnS3r2DNW7rnv3HkyY8CJRUZGEh/ev9P2WL19KRkY6ixcvw9vbB4CnnhrAs88OKXPuzJn/Rq2+84Fh8ODhzJ79H9avX83LL0/EwsKCjh27sG7dajIy0unbt999763RaFi4cD4tW3oxf/7XWFjcfqKrt7cPM2e+w+bN6xk+fFTp+TduJPPee/8u3W8wYMAghg8fwJYtGyWpFzWHUqngmV4tcXWyYen2GP69NJrJw/xwdTKsZuq9LM3V9PLoQQ+3bhxLPklEfBRLz61kU+x2env0oFuTTqjNDHssshBCCFFTHUk6xq9Jvxl83eWMeDQ6/Yp0Rdoilp9fw6FrRw3ur2vjjnRu3N7g68zNzenVK5QNG9Zy8+ZNGjZsCMCuXTtxc3OnTZu2eudrNBpycrJxc3PH1taOixdjDErqf/31IH5+AaUJPUCDBg0IC3uK9etX6517d0Kfm5tDYWERAQHt2LhxHXFxV2jVysug1xoTc460tFulHwhK9OoVxpdffsGhQwf1knpbW1tCQ/uW/qxSqWjd2pdr164adN+qIkm9uK/ufo1xcbBmwbrTzFp2jFcG+vJEy4aP3K+50pzOjdvT0aUdZ1NjiIiLYs0fm9h2eRc93LoR4tYdWwubKngFQgghRO1zb0L/oHZjCgsLZ9261ezevZNnnnmOK1cu8+efF3nxxZcBKCjIZ9my79m6dTMpKTe4+7mm2dnZBt0rOfk6fn4BZdo9PMo+pOnSpVgWLVrI8eO/kZOTo3csJ8ew+8LtJUXl3UupVOLm5k5ycpJeu7NzozJLiO3s6hEb+6fB964KktSLB/J0rc+7z3dg/rrTzF9zimEhnjzV2aNK1sIrFUr8GrbBr2EbLmVcYWdcFNuu7GJX/F66NelIb/ceOFo5VMGrEEIIIapf58btH2qGfMbB/5BWkF6mvYHanr8GTqiKoVWan18AjRu7EhGxnWeeeY6IiO0ApctO5s6dzdatmxkx4lnatvXD1tYWUDBz5j/0EvyqlJWVxeTJr2BtbctLL03A1dUNCwsLLl6MYeHC+Wi1WqPc927KCpYNG+s1P4gk9aJSHOpZ8vboQL7bep41UbEk3sjmhad8sFBV3Tr4FvWbMcH/BZJyktkVv5cDV4+w/+phAp39CfMIwc3u/jvohRBCiLpioGe43pp6AJVSxUDPhy8f+ShCQ/uwbNl3JCYmEBm5E2/v1qUz2iXr5idPfqP0/IKCAoNn6QEaNXIhMTGhTHt8fJzezydOHCMjI4NZs2bzxBN39hiU/8TZyk1Curg0Lr3X3X3qdDoSExNo3tyzUv2YSt0ozCmqhVplxqsDfRnaowWHzyXz8U/HScuq+ifINbZpxJjWz/B+12n0dAvi9M1zfPjb5yz4fTEX0/402SdgIYQQorp0cgnkOZ9hNFDfLqPYQG3Pcz7Dqr36TYk+fZ4CYMGCuSQmJujVpi9vxnrt2p8pLi42+D5du3bn9OmTXLgQU9qWlpZGRMQ2vfNKasvfnRMUFRWVWXcPYGVlVakPGD4+bWjQwIENG9ZQVHTnw9SePZGkpNygW7fq3/xqCJmpFwZRKBQM6NYM14Y2fPPLOT5Y+huTh/rTokm9B19soAaW9gxtNYDwZr3Yd/UwUQkH+OLENzS1cyesaQgBTr4oFfK5VAghRN3UySXQZEn8vZo3b0HLll4cOLAPpVJJ7953Noh26xbEjh1bsbGxpVmz5pw9e5ro6KPUr2/40+Sfe+55duzYyptvvs7w4aNQqy3ZtGk9jRo1Jjv7j9Lz/Pz8sbOrx6xZMxk+fCQKhYIdO7ZS3ryft7cPO3duY/78z/DxaYOVlTVBQT3KnGdubs7EiZP5z3/eZ/LkVwkN7cONG8msWfMzLVp48vTTZSvw1CSSEYmH0s7LiXfGtEdlpuSj5cf59cx1o93LWmVNeLNefNBtOqO8h5CjyWXxmWX868gcDl49QlFx0YM7EUIIIcQjKZmdb9eufWkVHICpU/9G3779iIjYxoIFn3Pz5k0+//zL+9aDr0jDhg2ZN+9rmjf3ZNmy71m9egXh4f0YMWKU3nn169vzySdzcXRsyKJFC1mx4kc6dOjMa69NKdPnoEHD6Nv3KbZu/YX335/B55/PrvD+/fo9zcyZsygoyOfLL79g69bNhIWF88UX/y23Vn5NotDJWgaDpKZmo9VW7Vvm5GRHSkpWlfZZXbJyC1m44Qwx8ek81dmDYcGeKJXGfZiUVqfl95QzRMTtIT7rKvUs7OjpHsSTrl2wMrcy6r1F7VOb40uImk7i647r1+NwcSlboUWIitzvd0apVODoaFgZcbOZM2fOrIJxPTby8grL/WrnUdjYqMnNLazaTquJWmVG5zaNyM4rIiI6kSvXswho2RCVufG+BFIoFDS2aUT3Jp3xtG9OSu5NDl47wr7EX8nV5NHYphGW5pV/ep2o22pzfAlR00l83ZGdnYGtrb2phyFqkfv9zigUCqytDXtuj6ypF4/M3EzJmL7euDnZ8NOuP/j3D9FMGe5PowaGf+1mCIVCgY9DK3wcWhGflciuuL1Exu8jKuEAnVwCCfUIppGNs1HHIIQQQghRE8jyGwPJ8pv7Ox+XxsINZ9DpdEwc3JY2zaq3xnxKbiqRCfs4nPQbGm0x/k6+hHmE0Ly+R7WOQ9QcdSm+hKhpJL7ukOU3wlCy/MbEZPnN/TnZW9Hex5lTsalE/JaItaU5zRvXq5IHVVWGjcqatg1b071JZ8yV5py4cYq9Vw/xR1ostiobnKwaVttYRM1Ql+JLiJpG4usOWX4jDFXVy28kqTeQJPUPZmOpoquvC1dTcoiITiQ9u5C2LRyMvoH2bmozC7wbtKSHazfsVDacSY3hwLXD/J5yBktzNS7WzlIO8zFR1+JLiJpE4usOSeqFoSSpNzFJ6itHZa6kY2tntDodEdGJXIhPw79lQ9RV+ATayjBXmtO8flOC3brhZOVIbMYVDl47wuGkYygUCprYumBewWOeRd1QF+NLiJpC4usOSeqFoao6qZc19QaSNfWGO3IumW+3nqeetQWTh/nh0cjOZGPR6rScTY0hIi6K2Iwr2KisCXbtRrBbd2wtbEw2LmE8dT2+hDAlia87ZE29MFRVr6mXpN5AktQ/nMtJmSxYd5qc/CJeHtCG9t6mr0pzKeMKO+OiOH3zHCqlim5NOtLbvQeOVtW7uVcY1+MQX0KYisTXHdevx9GokYfs2xKVotPpSE6Ol42ypiTLbx5OAzs1nds0IiY+nZ2/JaAAWrnbm/Q/fg0s7enQ6AkCnf3J1+RzOCmaqMSDJOfewMnKkXpq032jIKrO4xBfQpiKxNcdeXk5qFRqzMykWrh4sKKiQgoL87GxqVfucVl+Uw1kpv7RFGmKWbr9AofOXKeDtxMv9W+D2qJmrGlPy09nT8IBDlw7TEFxIa0dvOjTNIRW9p4y81KLPU7xJUR1k/i6Iy8vh6ysNOztnVCpLOTvhiiXTqejqKiQ9PQU7OwaYGVV/tJfWX5TDSSpf3Q6nY4dRxNYHfUn7k62TB7mj2P9mvME2NyiXPZdPUxUwgGyirJpaudOWNMQApx8pWJOLfS4xZcQ1UniS19eXg7Z2ekUF2tMPRRRg5mZmWNra19hQg+1MKkvLCzkiy++YOPGjWRmZuLj48Mbb7xB165d73vdzp072bp1K6dOnSI1NZXGjRvTs2dPXnvtNezs7iyZSEpKYs2aNezdu5e4uDiUSiVeXl689tprD7xHRSSprzqnYlP5etMZVGZKXh/qRyu3mlU1oLC4iCPXo9kVv4+beak4Wzck1D2YTi6BqMxUph6eqKTHNb6EqA4SX0IYR61L6t9880127tzJ2LFjadq0KevXr+fMmTMsW7aMdu3aVXhd586dcXZ2JjQ0lCZNmnDhwgVWrlxJs2bNWLt2LWq1GoAff/yR2bNnExoaSmBgIBqNho0bN3L27Fk+/vhjBg8ebPCYJamvWkmpOcxbc4qbGfmM7evNkwFNTD2kMrQ6Lb+nnCEibg/xWVepZ2FHT/cgnnTtgpW5lamHJx7gcY4vIYxN4ksI46hVSf2pU6cYMWIE06dP54UXXgCgoKCAAQMG4OzszPLlyyu89siRI3Tu3FmvbcOGDUybNo0PP/yQoUOHAvDHH3/g6OiIg8OdaiaFhYUMGjSIgoICdu/ebfC4Jamvejn5Rfx3wxnOXkkjrIM7z/TyxExZ85a56HQ6LqT9SURcFDFpf2BppibItQs93YOwV9c39fBEBR73+BLCmCS+hDCOh0nqTZY5bd++HZVKxYgRI0rb1Go1w4cP59ixY9y4caPCa+9N6AFCQ0MBiI2NLW1r1aqVXkIPYGFhQXBwMFevXiU/P/9RX4aoAjaWKv76TABhHdyJiE7g81UnyckvMvWwylAoFPg4tGJyu5eZ1nEKvo4+RMbv471DH7H8/GqScyr+nRVCCCGEMCaTJfXnz5+nefPm2NjobxLw9/dHp9Nx/vx5g/q7efMmAA0aNHjguSkpKVhbW5cu0xGmZ6ZU8mxoK158yoeY+HT+vTSapNQcUw+rQh52boxrO5r3urxF1yad+C35BP868infnP6Byxnxph6eEEIIIR4zJiummpKSQqNGjcq0Ozk5Adx3pr48ixYtwszMjD59+tz3vLi4OCIiIujfv7+Um6qBngxogoujNV+uO82/fzjGqwN98fd0NPWwKuRk7cgo7yH0bx5GVOJB9iUe4mTKGVrZtyDUIxhfRx/5PRNCCCGE0Zksqc/Pz0elKltBpGT2vKCgoNJ9bd68mTVr1vDqq6/i4eFR4Xl5eXlMnToVKysr3njjDcMHDQavb6osJyd50FEJJyc7WjZzZNa3R5m35iQvDPBlcHDNrhXvhB0tXIfzbOAAIi8dZMuFSBae+g6P+q4M9Amjm0cHzJU1ox7/40jiSwjjkfgSomYwWVJvaWlJUVHZddMlyXxll8ZER0fzzjvvEBISwtSpUys8r7i4mDfeeIPY2FiWLFmCs7PzQ41bNspWDwXw91FPsGTLOb7dfJYLl1MZG+6NyrzmJ8adHTrRvnMg0cm/ExG/lwVHvmf57xvo7dGDbk06oTYz7Alx4tFIfAlhPBJfQhjHw2yUNVlS7+TkVO4Sm5SUFIBKJd0xMTFMnDgRb29v5s6di5lZxQnfjBkz2Lt3L59++imdOnV6+IGLaqO2MGPC4Lb8cvAKGw5c5vqtXF4f6oe9bc3fC2GuNKdL4w50cgnkbGoMO+OiWPPHJrZd2UWwazeC3bpja1HxQyeEEEIIIQxhso2yPj4+XL58mZwc/c2QJ0+eLD1+P/Hx8YwfPx4HBwe+/vprrK2tKzz3448/Zt26dfzjH/+gX79+jz54UW2UCgUDg5rz2uC2JKRk86+l0VxOyjT1sCpNqVDi17AN/9f+Nd4MfI0W9Zux9couZhz6D6subiA175aphyiEEEKIOsBkSX14eDhFRUWsXr26tK2wsJB169YRGBhYuon22rVremUq4fZs/rhx41AoFCxZsqRM2cq7LV68mG+//ZYJEyYwZswY47wYYXQdfJz5x1/ao1TAR8uPc+RcsqmHZDBP+2ZM8H+BGZ3/j/bOARy4eoSZhz/hu7M/kZh1zdTDE0IIIUQtZtInyk6dOpXIyEief/55PDw8Sp8ou3TpUtq3bw/AmDFjOHr0KBcuXCi9btCgQcTExDB+/Hi8vLz0+vTw8Ch9Gm1ERASTJk2iWbNmvPbaa2XuHxYWdt8Z/vLImnrTyswp5Kv1p7mYmEH/rk0Z0qMFyhq8gfZ+0vLT2ZNwgAPXDlNQXEhrBy/6NA2hlX3N3hRc20h8CWE8El9CGEeteqIs3N4U+/nnn7N582YyMjLw9vbmzTffpFu3bqXnlJfUe3t7V9jnkCFD+OijjwCYP38+CxYsqPDcyMhI3NzcDBqzJPWmpynW8uPOC+w7mUS7Vg0ZP6ANVmqTbQ95ZLlFuey7epiohANkFWXT1M6dsKYhBDj5olTUvCfr1jYSX0IYj8SXEMZR65L62kiS+ppBp9MReSyRlZF/0rihNVOG+eNkb2XqYT2SwuIijlyPZlf8Pm7mpeJs3ZBQ92A6uQSiMitb/lVUjsSXEMYj8SWEcUhSXw0kqa9Zzl65xX83nEGhUPDa4Lb4NH3wE4VrOq1Oy4kbp4mIjyIh6yr1LOzo6R7Ek65dsDKv3R9cTEHiSwjjkfgSwjgkqa8GktTXPMm3cpm39hQ30vJ4LrQVPQMNW1JVU+l0Oi6k/UlEXBQxaX9gaaYmyLULPd2DsFfXN/Xwag2JLyGMR+JLCOOQpL4aSFJfM+Xma/hm81lOxabSs50rz4a2wtys7qxHj89KZFfcXo7fOIWZQkknl0BCPYJpZPNwD1F7nEh8CWE8El9CGIck9dVAkvqaS6vVsXZvLNuOxOPjYc/EwW2xs65bT29NyU0lMmEfh5N+Q6Mtxt/JlzCPEJrX9zD10GosiS8hjEfiSwjjkKS+GkhSX/P9euY6322Lwd7WginD/XFzMiwoaoOswmyiEg+yL/EQuZo8Wtm3INQjGF9HHymHeQ+JLyGMR+JLCOOQpL4aSFJfO8Rey2DButPkFxbzytNtaNfKydRDMop8TT6Hrh0lMmE/6QUZNLFxIaxpCO2dAzBTmpl6eDWCxJcQxiPxJYRxSFJfDSSprz3SsgqYv/YUcdezGNKjBf27Nq2zs9garYbo5N+JiN/L9ZxkGqjt6e3Rg25NOqE2q1tLkAwl8SWE8Uh8CWEcktRXA0nqa5fComK+3xbD4XPJdGrtzIv9WqNW1d0ZbK1Oy9nUGHbGRXEp4wo2KmuCXbsR7NYdWwsbUw/PJCS+hDAeiS8hjEOS+mogSX3to9Pp2HYknrVRsXi42DF5qB8O9SxNPSyji02/QkR8FKdvnkOlVNGtSUd6u/fA0crB1EOrVhJfQhiPxJcQxiFJfTWQpL72+v2Pm3y9+SyWKjMmDfXD0/XxqPWelJPMrri9/JZ8Ah06Ap39CfMIwc2uiamHVi0kvoQwHokvIYxDkvpqIEl97XY1JZt5a0+RllXI8+HedPdrbOohVZu0/HR2J+zn4LUjFBQX0sbBm7CmIbSyb1Fn9xqAxJcQxiTxJYRxSFJfDSSpr/2y84r4av1pYuLTCe/kwfAQT5TKupvU3iu3KJd9Vw8TlXCArKJsmtq5E9Y0hAAnX5SKuvPArhISX0IYj8SXEMYhSX01kKS+btAUa1kZ+Qe7j1/Fr4Ujrw70xdrS3NTDqlaFxUUcuR7Nrvh93MxLxdm6IaHuwXRyCURlpjL18KqMxJcQxiPxJYRxSFJfDSSpr1uiTlxlecRFnOytmDrcn0YO1qYeUrXT6rScuHGaiPgoErKuUs/Cjp7uQTzp2gUrcytTD++RSXwJYTwSX0IYhyT11UCS+rrnQnwaX64/g1arY+Lgtvg2f7yqw5TQ6XRcSPuTiLgoYtL+wNJMTZBrF3q6B2Gvrr2biiW+hDAeiS8hjEOS+mogSX3dlJKex/y1p7h6M4dRvVoR2sGtTm8efZD4rER2xe3l+I1TmCmUdHIJJNQjmEY2zqYemsEkvoQwHokvIYxDkvpqIEl93ZVfqGHR5nOc+OMmT/o35i99vFGZ172No4ZIyU0lMmEfh5N+Q6Mtxt/JlzCPEJrX9zD10CpN4ksI45H4EsI4JKmvBpLU121anY4N+y/zy6ErtHSrz6QhftSzsTD1sEwuqzCbqMSD7Es8RK4mj1b2LQj1CMbX0afGf6Mh8SWE8Uh8CWEcktRXA0nqHw9Hzyfz7Zbz2FqrmDLMH49GdqYeUo2Qr8nn0LWjRCbsJ70ggyY2LoQ1DaG9cwBmSjNTD69cEl9CVL2j14+zKXY76QXp2KvtGegZTieXQFMPS4g6Q5L6aiBJ/eMj7noW89aeIie/iPH929DBp/atJzcWjVZDdPLvRMTv5XpOMg3U9vT26EG3Jp1Qm9WsbzYkvoSoWkevH+enmLUUaYtK21RKFc/5DJPEXogqIkl9NZCk/vGSkV3AgvWnib2aycDuzRgY1BxlDV9uUp20Oi1nU2PYGRfFpYwr2KisCXbtRrBbd2wtbEw9PEDiS4iHodPpyC/OJ7swl+yiHHKKcsj+3/+2Xd5FfnFBmWsaqO35d/d/mGC0QtQ9ktRXA0nqHz9FGi0/7Ijh4OnrtPd2Ynz/NqgtauZSE1OKTb9CRHwUp2+eQ6VU0a1JR3q798DRyrQlQiW+xONOp9NRUFxATlHu/xLz3NIkPacwp0zb7SQ+F61Oa/C9vuz1iRFegRCPH0nqq4Ek9Y8nnU5HxG8J/LznT9ycbJk8zI+G9Wv/g5mMISknmV1xe/kt+QQ6dAQ6+xPmEYKbXROTjEfiS9Q1hcWFpYn3ncT83hn1/yXphbfbNLricvtSoMBWZYONyhoblQ22FjbYlvzz//5no7L+X7sNNiobZh35jLSC9DJ9yUy9EFVHkvpqIEn94+3MpVQWbjyLuZmC14f44eVub+oh1Vhp+ensTtjPwWtHKCgupI2DN2FNQ2hl36JaK+ZIfImarEiruSv5vn9iXpK4372W/W4KFFirrPST9LsT8/8l7bfbb/9saW6JUmFY6V5ZUy+E8UlSXw0kqRdJqTnMW3uam+l5jOnrTY8A08xA1xa5Rbnsu/orexIOkF2UQ1M7d8KahhDg5GtwMvEwJL5EdSnWFusvbbk3SS+8+9jt/y8oLqywPytzq9Lku0ySbmFdOnNe0matsqqWmAKpfiOEsUlSXw0kqRcAOflFfL3xLGcu36J3ezdG9W6JmfLxflDVgxQWF3HkejS74vdxMy8VZ+uGhLoH08klEJWZymj3lfgSD0Or05JTmqDfWeZyZ126/ux5TlEOeZr8CvuzNFOXJuA2FtbYmNtgWyYxv7MExsbcusaWib2bxJcQxiFJfTWQpF6UKNZqWb0nlp2/JdCmWQMmDGqLrZXxktO6QqvTcuLGaSLio0jIuko9Czt6ugfxpGsXrMyrfp+CxJfQ6rTkafLvJOKFd5a2lE3Sc8gpzCVXk4eO8v9bb6FU3bX+/O5Z9HuSdIs7x1RK82p+1dVD4ksI45CkvhpIUi/utf/UNZbtuIBDPUumDPOnScOaUcqxptPpdFxI+5OIuChi0v7A0kxNkGsXeroHYa+uX2X3kfiqW+5XalFvZr0wR28ZTEUJurnCDFsL2ztrzv+XlN/52RobC/216RY17FkMpiTxJYRxSFJfDSSpF+X5MzGDBetPU1hUzIRBvvh7NjT1kGqV+KxEdsXt5fiNU5gplHRyCSTUI5hGNo/+wC+Jr5rrdqnFwrIbQ0squmhyS0su3j2jXlGpRaVCWWZjqI3FPT/fM6OuNrOo1o3bdY3ElxDGIUl9NZCkXlTkVmY+89aeIiE5m+E9PQnv5CHJgoFSclOJTNjH4aTf0GiL8XfyJcwjhOb1PR66T4mv6lNYXKQ/c35PqUX9pS63/1mj1ZTblwKFfiJ+T6lFmzJLXayxNLOUmKtmCga+iAAAIABJREFUEl9CGIck9dVAknpxPwVFxXy75Ty/xdygq68LLzzljcq85m92q2myCrOJSjjA3qu/kqfJo5V9C8KahtDGwdvgpE3i6+GUlFrM+d9SlgpLLWruLHUprKDUIoCNuXW5FVts7qrucqfcog1WD1FqUVQ/iS8hjEOS+mogSb14EJ1Oxy+HrrB+/2WaN67HpKF+NLBTm3pYtVK+Jp9D144SmbCf9IIMmti4ENY0hPbOAZWuDCLxdbvU4t3Jd5kHFRXql2HMKcohv7igwv6szC3LVmwpt9Ti7WPW5la1opKLMJzElxDGIUl9NZCkXlTWsQspLP7lHFZqMyYP86d543qmHlKtpdFqiE7+nYj4vVzPSaaB2p7eHj3o1qQT6gdsWqxr8aXVacktyiu3Ykv5pRZzydPkVdif2sxCb/bcRlVxqcWSRF0SdFGirsWXEDWFJPXVQJJ6YYiEG9nMW3OKzNxCXnzKhy6+LqYeUq2m1Wk5mxrDzrgoLmVcwUZlTbBrN4LdumNrUX7VoZocX1qdlvz/lVq8e0nLvRtDK1tqUaU0x1Zlq1/v/H6lFs2tjfqMAFH31eT4EqI2k6S+GkhSLwyVmVvIV+vPcDEhnX5dmjI0uAVK2cz3yGLTrxARH8Xpm+dQKVV0a9KR3u49cLRy0DuvuuKrpNRiaTJe0YOKDCi1eN/EXEotihpA/n4JYRyS1FcDSerFw9AUa/kp4iJRv1/jiZYNefnpNlip6+bDaKpbUk4yu+L2cjT5OACBzv6EeYRwLef6Qz/G/u5Si+VVbLlT2aXypRbvrYNuW6bkopRaFLWP/P0Swjgkqa8GktSLh6XT6dh9/Cordv1BY0drJg/zw7mBtamHVWek5aezO2E/B68doaC4EAUKvVlwldKc8Ka9aVbfo0zJxXsfYFSZUotlZs8tbMpJ3KXUoqjb5O+XEMYhSX01kKRePKrzV27x1YYzALw2uC2tmzk84AphiNyiXP7560fkafIrdX5JqUUb89sJuH65xf8l7lJqUYhyyd8vIYzjYZJ6+f5fiGrWupkD7z7fgXlrT/Ppzyd5LqwVPdu5ykxuFbFWWd83oX8jcKKUWhRCCFHnyHSTECbg3MCad8a0x6+FAz/uvMiyHRfQFJe/HlsYroHavsL2lvbNcbFphJ2FrST0Qggh6gxJ6oUwESu1OZOH+dOvS1Oifr/Gpyt/Jyu30NTDqhMGeoajUuqXalQpVQz0DDfRiIQQQgjjkqReCBNSKhUMD/Hk5afbEHstk38tjSbhRraph1XrdXIJ5DmfYTRQ26Pg9gz9cz7DKl39RgghhKhtZKOsgWSjrDCWy0mZzF97iryCYl5+ug2BXk6mHlKd8P/t3XdYVGf6PvB7BgaQJgJDkV4MKB0rdtEYYhdF126KMWWTaMo3PddumokxicbEjS2JuqYIokRjjAXsBgVRRBClKIwoTQGlDjC/P/zJLgsqAzNzOMP9uS7/mHdOeSZXHubm5T3nsL+ItIf9RaQd7blQVtCZ+rq6Onz++ecYOnQoAgMDMWPGDJw8efKh++3btw9LlixBeHg4goKCEBERgc8++wy3b7f+gyU6OhqPP/44AgIC8Nhjj2Hr1q2a/ihEHebhaIn3FvRHT1szfBN7HruO54K/cxMREVFbGPzjH//4h1Anf/311xEbG4sZM2Zg4sSJyMzMxMaNGxEWFgZHR8f77jd79mzU1dVh3LhxGD9+PMzMzPDTTz/h4MGDmDZtGgwN/3NTn19++QXvv/8+Bg4ciLlz56KxsRHr1q2DmZkZQkJC1K65uroOms5ZZmbGqOJaasLddfZhfvYorajB/iQFrpdWIdDLBoYGXCnXXuwvIu1hfxFph0Qigampek8JF2z5TWpqKqKiovDWW29h4cKFAIDa2lpMmDABdnZ2D5xNT0xMxMCBA5uN7dy5E2+88QaWLVuGyMhIAEBNTQ1GjBiBvn37Ys2aNU3bvvbaa4iPj8fhw4dhYWGhVt1cfkO6oFKpsDcxDzGHsuFqb4EXpwXA2tJE6LJEif1FpD3sLyLtENXym71790ImkyEqKqppzNjYGNOnT0dycjKKioruu+//BnoAGDNmDAAgOzu7aSwxMRFlZWWYPXt2s23nzJmDyspKHDlypKMfg0grJBIJHh/khpemB6LwVhU+2JSErGvlQpdFREREnZRgoT4jIwMeHh4wMzNrNh4YGAiVSoWMjAy1jldSUgIA6NGjR9NYeno6AMDf37/Ztn5+fpBKpU3vE3VWQd62eHd+P5jIDLD8pzM4lnpd6JKIiIioExIs1BcXF8POzq7FuFx+944fD5qpb8369ethYGCAsWPHNjuHkZERrKyaP4jm3pi65yASQk9bM7y7oB96OVvh+z0Z+OXgZTQ08kFVRERE9B+GD99EO2pqaiCTyVqMGxsbA7i7vr6tdu3ahZiYGCxevBiurq4PPce986hzjnvUXd/UVnK5emv7qWuRA/jkhaHY+Fsadh/LRUlFLV6f1w/m3Vr//5uaY38RaQ/7i6hzECzUm5iYQKlUthi/F7TvhfuHSUpKwjvvvIORI0fi5ZdfbnGOurrWr8qvra1t8zn+Gy+UJSFFDvWAjbkR/r3vEpZ8eQgvTQuAo43Zw3fswthfRNrD/iLSDlFdKCuXy1td/lJcXAwArS7N+V8XL17Ec889Bx8fH3z11VcwMDBocQ6lUomysrJm43V1dSgrK2vTOYg6mxHBTnh9Vggqq5X4aHMy0nJKhS6JiIiIBCZYqPf19UVubi4qKyubjZ87d67p/QfJy8vD008/DWtra6xduxampqYttunduzcAIC0trdl4WloaGhsbm94nEptHXKzw/sJ+sLE0wVfR57DvVB4fVEVERNSFCRbqIyIioFQqER0d3TRWV1eH2NhYhIaGwt7eHgBQUFDQ7DaVwN3Z/CeffBISiQQbN26EtbV1q+cYNGgQrKys8NNPPzUb//nnn2Fqaorhw4dr+FMR6Y5t9254e14oQnrJ8Ut8Fr7fkwFlPS+gJSIi6ooEe6Ksg4MDsrKysHXrVlRWVkKhUGDZsmXIzs7G559/jp49ewIAnn/+eSxfvhwvvvhi076zZ89GTk4OZs2ahbq6OmRmZjb9q66ubnoaraGhIUxNTfHjjz8iKysLd+7cwebNmxEXF4eXX34ZgwcPVrtuPlGWOhNDAyn6+d5dRnYgSYGLV28h0NsWJkYGD9mz62B/EWkP+4tIO9rzRFnBLpQFgOXLl2PlypWIi4tDeXk5fHx8sG7dOvTt2/eB+128eBEAsGHDhhbvTZ06FSEhIU2v58yZA5lMhu+//x4HDx6Eo6Mj3nnnHcyfP1+zH4ZIIFKJBFOGecJJbo6Nu9PxwY+n8dK0QLg58I4UREREXYVExYW4auHdb6gzu3rjNlbHpuJOlRJPju+NAb3thS5JcOwvIu1hfxFph6jufkNEmufmYIH3FvSHq70Fvou7gB1HctDI39uJiIj0HkM9kZ7pbmaE12eFYGigI3aduII1O9JQU1cvdFlERESkRQz1RHpIZijFE4/7YtboXki5XIxPtiSjpKxa6LKIiIhISxjqifSURCLBo/1dsHRGEG5W1OKDTUnIzLsldFlERESkBQz1RHrO38MG7y7oB/NuMqz45SwOnb0mdElERESkYQz1RF2Ag7Up3p3fD73de2Dz3kxs3XcJ9Q18UBUREZG+YKgn6iJMTQyxZHoQIga44uAZBb7adg53qpVCl0VEREQawFBP1IVIpRLMCPfGU+N747KiDB9tSsK14jtCl0VEREQdxFBP1AUNCXDEG7NDUaNswMdbknE2q0TokoiIiKgDNBLq6+vr8eeff2Lbtm0oLi7WxCGJSMu8nLrj/QX9YG9titUxqdjz11XwAdNERETiZKjuDsuXL0diYiK2b98OAFCpVHjiiSeQlJQElUoFKysrbNu2Da6urhovlog0y9rSBG/OCcUPezIQcygbiqI7WPi4L4xkBkKXRkRERGpQe6b+6NGj6NevX9Pr+Ph4nD59Gk899RS++OILAMC6des0VyERaZWxzACLJ/khcrgn/kovxGc/ncGt27VCl0VERERqUHum/saNG3Bzc2t6nZCQAGdnZ7z22msAgMuXL2PXrl2aq5CItE4ikWDCYHc42Zph3e50fLDpNF6MDIRnT0uhSyMiIqI2UHumXqlUwtDwP78LJCYmYvDgwU2vXVxcuK6eSKRCHpHjnbl9ITOQ4tOtZ3Ay7YbQJREREVEbqB3qHRwckJKSAuDurHx+fj769+/f9H5paSlMTU01VyER6ZSznTneW9AP3k6WWL87HdEJWWhs5AW0REREnZnay2/Gjx+PNWvW4ObNm7h8+TLMzc0xYsSIpvczMjJ4kSyRyFmYGuGVmcH46cBl/JGYh2sllVg8yQ/djNX+kUFEREQ6oPZM/eLFizF16lScPXsWEokEn332GSwt7667vX37NuLj4xEWFqbxQolItwwNpJj/mA/mjX0EF3Jv4qPNSSi8VSV0WURERNQKiUqDN6ZubGxEZWUlTExMIJPJNHXYTqW09I7GlyLI5RYoLr6t0WMSaVLG1VtYs+M8AOC5Kf7o424tcEVtx/4i0h72F5F2SKUS2NiYq7ePJguor6+HhYWF3gZ6oq6qt1sPvLewP6wsjPHlr+dwICmfD6oiIiLqRNQO9YcPH8bq1aubjW3duhWhoaEIDg7Gq6++CqVSqbECiahzsLPqhrfn9kWglw1+OnAZm/Zmor6hUeiyiIiICO0I9Rs3bkROTk7T6+zsbHzyySews7PD4MGDsWfPHmzdulWjRRJR59DN2BB/nxaA8WFuOHKuACt+TkFFVZ3QZREREXV5aof6nJwc+Pv7N73es2cPjI2NERMTgw0bNmDcuHHYuXOnRoskos5DKpFg2ggvPDOpD3Jv3MaHPyYhr5BraomIiISkdqgvLy9Hjx49ml6fOHECgwYNgrn53cX8AwYMgEKh0FyFRNQpDerjgDfnhKJRpcKyf59BcmaR0CURERF1WWqH+h49eqCgoAAAcOfOHZw/fx79+vVrer++vh4NDQ2aq5CIOi0PR0u8t6AfnORm+HZHGn47lssLaImIiASg9pNkgoOD8csvv8Db2xtHjhxBQ0MDhg8f3vT+1atXYWdnp9EiiajzsjI3xhuzQ7BpbyZ2HsuFoqQST43rDWMjA6FLIyIi6jLUnql/6aWX0NjYiCVLliA2NhZTpkyBt7c3AEClUuHAgQMIDQ3VeKFE1HnJDA3w1PjemDHKG8mZRVj272SUltcIXRYREVGX0a6HT5WVleHMmTOwsLBA//79m8bLy8uxc+dODBw4EL6+vhottLPgw6eIHiw1uxRrf0uDzECKFyID0MvZStB62F9E2sP+ItKO9jx8SqNPlO0KGOqJHq6gpBJfb09FaXkN5j/mg2FBPQWrhf1FpD3sLyLtaE+oV3tN/T15eXk4ePAg8vPzAQAuLi4YPXo0XF1d23tIItITPW3N8N6CfvhuZxp++OMiFMWVmBHuBQOpRh9iTURERP9fu2bqV65cifXr17e4y41UKsXixYvx8ssva6zAzoYz9URt19DYiF/js3AgSQE/D2s8O9kPZiYyndbA/iLSHvYXkXboZKY+JiYG3333HUJCQvD000+jV69eAIDLly9j48aN+O677+Di4oLIyEh1D01EesZAKsXsMY/AWW6OLX9m4qNNSXhpeiAcbcyELo2IiEivqD1THxkZCZlMhq1bt8LQsPnvBPX19ZgzZw6USiViY2M1WmhnwZl6ova5lF+Gb3ecR32DCosn+SHQy0Yn52V/EWkP+4tIO9ozU6/2Atfs7GyMGzeuRaAHAENDQ4wbNw7Z2dnqHpaI9NwjLlZ4f0F/2HY3waqYc9ibmMcHVREREWmI2qFeJpOhqqrqvu9XVlZCJtPtmlkiEgeb7iZ4e25fhD4ix7aELHz/ewaU9XwCNRERUUepHeoDAgLw66+/oqSkpMV7paWl2LZtG4KCgjRSHBHpH2MjAzw3xR+Th3rgeNoNLP8pBWV3aoUui4iISNTUXlN/+vRpLFy4EGZmZpg2bVrT02SzsrIQGxuLyspK/Pjjj+jXr59WChYa19QTaU7SxSJs+D0dZiYyvDgtAO4Olho/B/uLSHvYX0TaobOHT8XHx+PDDz/E9evXm4337NkT77//PkaOHKnuIUWDoZ5Is/IKb2P19lRUVCnx5LjeGNjHXqPHZ38RaQ/7i0g7dPpE2cbGRqSlpUGhUAC4+/ApPz8/bNu2DZs3b8aePXvac9hOj6GeSPMqKuvw7Y7zuKwox/gwN0wd7gmpRKKRY7O/iLSH/UWkHTp9oqxUKkVgYCACAwObjd+6dQu5ubntPSwRdUGWZkZ4fVYI/r0vE7+fvIqCkko8PaEPuhm3+0cUERFRl8JnthNRp2BoIMWCCF/MHtML57JK8cm/k1FcVi10WURERKLAUE9EnYZEIsGYfi5YOjMIZbdr8eGmJFy8ekvosoiIiDo9hnoi6nT83K3x7vx+sDCV4YtfzyIh5ZrQJREREXVqDPVE1CnZW5vinXn94OdhjS1/ZmLLn5mob2gUuiwiIqJOqU1Xof3www9tPuCZM2favG1dXR1WrVqFuLg4VFRUwNfXF0uXLkVYWNgD90tNTUVsbCxSU1Nx6dIlKJVKZGZmtrptUVERvv76a5w4cQKlpaWwt7fH2LFj8cwzz8DSUvP3xCYizTE1McRL0wKx/XA2/kjMw/XSSjw3xR8WpkZCl0ZERNSptOmWlr6+vuodVCJBRkbGQ7d75ZVXsG/fPsyfPx9ubm7YsWMH0tLSsGXLFoSEhNx3v9WrV+O7776Dj48PqqurkZOT02qor6qqwoQJE1BVVYU5c+bAwcEB6enpTU+9/emnn9T6XABvaUkklBNp1/HjH5mwMjfCS9MD4Sxv262+2F9E2sP+ItIOrd3ScvPmze0q6EFSU1Px+++/46233sLChQsBAFOmTMGECROwYsUKbN269b77zpo1C4sWLYKJiQk+/vhj5OTktLrdoUOHcO3aNaxdu7bZA7FMTEzw/fffIz8/Hy4uLpr8WESkJYP9HWFvbYpvYs/j4y3JeGZiH4T0kgtdFhERUafQplA/YMAAjZ947969kMlkiIqKahozNjbG9OnT8dVXX6GoqAh2dnat7mtra9umc9y5cwcAYGNj0+r+JiYm7SmdiATi1bM73l/QH6u3p+Kb7ecxdbgnxoe5QaKhB1URERGJlWAXymZkZMDDwwNmZmbNxgMDA6FSqdq0fOdh+vbtC6lUio8//hhnz57FjRs3EB8fjx9++AGRkZGQyznLRyQ2PSyM8eacUAzsY4/YIzlYtysddcoGocsiIiISlGCPaywuLoa9vX2L8XtBu6ioqMPn8PLywgcffIDly5dj5syZTeMzZ87EP/7xjw4fn4iEYSQzwKKJfeAkN0Ps4RzcuFmFFyMDYG3Jv74REVHXJFior6mpgUwmazFubGwMAKitrdXIeRwcHBAUFIThw4ejZ8+eSEpKwpYtW9C9e3e8+uqrah9P3YsW2kout9DKcYn02cJJAejjJceKrUn4eEsy3n5iAHzdrFtsx/4i0h72F1HnIFioNzExgVKpbDF+L8zfC/cdkZycjGeffRYxMTHo3bs3AGDMmDEwNzfHN998g6lTp8LT01OtY/LuN0Sdi4edGd6e2xdfb0/FW98ex4IIHwwJcGx6n/1FpD3sLyLtaM/dbwRbUy+Xy1tdYlNcXAwA971IVh2//vor7OzsmgL9PeHh4VCpVDh79myHz0FEwnOSm+O9Bf3h7WSJjb9nYFt8lsZ/+SYiIurMBJup9/X1xZYtW1BZWdnsYtlz5841vd9RpaWlaGhoeQFdfX09ALT6HhGJk3k3GV6ZGYxfDl7G3lN5SMstRWVNPcpu18La0hiRI7wQ5ucgdJlERERaIdhMfUREBJRKJaKjo5vG6urqEBsbi9DQ0KaLaAsKCpCdnd2uc7i7u6OwsBBJSUnNxnfv3g0ALWbwiUjcDA2kmDvWB0MDHKAorsSt27VQASitqMWmPy7i5IUbQpdIRESkFYLN1AcFBSEiIgIrVqxAcXExXF1dsWPHDhQUFGDZsmVN273xxhs4depUsyfGXrt2DXFxcQCA8+fPAwDWrFkD4O4Mf3h4OABgzpw5iI2NxeLFizF37lw4Ojri9OnT2L17N4YNGwZ/f39dfVwi0qGMq7dajNXVNyL2cDZn64mISC8JFuoBYPny5Vi5ciXi4uJQXl4OHx8frFu3Dn379n3gfgqFAqtWrWo2du/11KlTm0K9p6cntm/f3nSOkpIS2NnZ4emnn8aLL76onQ9FRIIrrWj97lmlFbWob2iEoYFgf6QkIiLSColKpeLVZGrg3W+IOr/X1xy/b7C3s+qGaSO90M9HzifREnUQv7+ItENUd78hItKWyBFeMDJs/uPNyFCKiAEukMmk+NfONHyyJRmXFWUCVUhERKRZgi6/ISLShnvr5mMPZ+NmRfO730xvVOHY+evYcTQHy/59BqGPyDF9pBccrE0FrpqIiKj9uPxGTVx+QyQu9+uv2roG7Dudhz2Jeaivb8SI4J6YNNQDlqZGAlRJJE78/iLSjvYsv+FMPRF1ScZGBpg4xAPDg50QdywXh1IKcCLtBsYNcsOj/V1gLDMQukQiIqI240y9mjhTTyQube2v66WViE7IxtmsEvSwMMbUYZ4Y7O8AqZQX0xLdD7+/iLSjPTP1DPVqYqgnEhd1+ysz7xa2JWQh9/ptOMvNMSPcC/4eNlqskEi8+P1FpB0M9TrAUE8kLu3pr0aVCqczirD9cDZKymvg52GNqJFecLW30FKVROLE7y8i7WCo1wGGeiJx6Uh/KesbkXBGgV0nrqCqph6D/R0wdbgnrC1NNFwlkTjx+4tIO3ihLBGRBskMpRg7wBVDAh3x+4mrOJCcj1MXizC2vwvGDXJDN2P+CCUios6BM/Vq4kw9kbhosr9KyqoReyQHf6UXwsJUhklDPDAiuCcMDfgcP+qa+P1FpB1cfqMDDPVE4qKN/sq9XoHohCxczCuDvbUppo/wQugjtpBIeKcc6lr4/UWkHQz1OsBQTyQu2uovlUqFc9mliE7IwvXSKng7d8fMUd7wcuqu8XMRdVb8/iLSDq6pJyLSEYlEgmBvWwR4WuNo6nXsPJqLj7cko5+PHNNGesG+h6nQJRIRURfCUE9E1AEGUilGBjthUB977E3Mw95TeUi5XIJRIU6YOMQdFqZGQpdIRERdAEM9EZEGmBgZYsowT4wMccLOo7k4eEaB42k3MD7MDWP6OsNIZiB0iUREpMe4pl5NXFNPJC5C9de14juIPpSN1OxSWFsaY9pwLwz0s4eUF9OSHuH3F5F28EJZHWCoJxIXofsr4+otbIvPwtXC23Czt8CMUV7o7W4tWD1EmiR0fxHpK4Z6HWCoJxKXztBfjSoVEtMLEXs4G6UVtQjwtEHUKC84y9X7gU3U2XSG/iLSRwz1OsBQTyQunam/lPUNOJCswO4TV1FTV4+hAY6YMswTPSyMhS6NqF06U38R6RPe0pKIqBOTGRrg8YFuGBbYE7uOX0H8GQUSMwrxWH9XRAx0RTdj/kgmIqL24Uy9mjhTTyQunbm/im5VYfvhHJy+WARLMyNMHuqB4UGOMJBKhS6NqE06c38RiRmX3+gAQz2RuIihv7ILyrEtPguXFeVwtDHF9JFeCPa2hYR3yqFOTgz9RSRGDPU6wFBPJC5i6S+VSoWUyyWIPpSNwptVeMTFCjPDveHhaCl0aUT3JZb+IhIbhnodYKgnEhex9Vd9QyOOnCtA3LFc3K5SYkBvO0wb4QW5VTehSyNqQWz9RSQWvFCWiEjkDA2kCA91RpifA/5IvIp9p/Jx5lIxwkOdMWGwO8y7yYQukYiIOiGGeiKiTqibsSEih3thVIgzdhzNwf7T+Th+/jrGh7ljdF9nyAx5MS0REf0Hl9+oictviMRFX/orv+gOohOykJZ7E7bdTRA5whMDettDyotpSUD60l9EnQ3X1OsAQz2RuOhbf13IvYltCVnIL7oDdwcLzAz3ho9rD6HLoi5K3/qLqLNgqNcBhnoicdHH/mpsVOHkhRuIPZKDW7drEexti+kjvdDT1kzo0qiL0cf+IuoMGOp1gKGeSFz0ub/qlA3Yn5SP309eRZ2yEcODHDF5qAe6mxsLXRp1EfrcX0RC4t1viIi6ECOZAcaHuWNYUE/sOn4Fh1Ku4eSFQjw+0BWPDXCFsZGB0CUSEZGOcKZeTZypJxKXrtRfhTerEHM4G8mZxehuboSpwzwxNMARUikvpiXt6Er9RaRLXH6jAwz1ROLSFfsrS1GOXxMuI/taBZxszRA1ygsBnjaQ8E45pGFdsb+IdIGhXgcY6onEpav2l0qlQnJmMWIOZ6PoVjV6u/XAjFHecHOwELo00iNdtb+ItI2hXgcY6onEpav3V31DIxJSrmHX8Su4U61EmJ89pg73hG33bkKXRnqgq/cXkbbwQlkiImrG0ECKR/u5YIi/I/b8dRX7k/Jx+mIxxvRzxoQwN5iayIQukYiINIAz9WriTD2RuLC/mistr8GOozk4mXYDpiaGmDjEA+GhTjA0kApdGokQ+4tIO7j8RgcY6onEhf3Vuqs3biP6UBbSr9yC3MoE00Z4ob+vHS+mJbWwv4i0g6FeBxjqicSF/XV/KpUKabk3sS0hC9eKK+HZ0xIzRnnjERcroUsjkWB/EWkH19QTEVGbSSQSBHjawM/dGsfPX8eOozn4dOsZhPSyRdQobzhYmwpdIhERtRFn6tXEmXoicWF/tV1tXQP2nc7DnsQ8KJWNGBHSE5OHeMDSzEjo0qiTYn8RaQdn6omIqN2MjQwwcYgHhgc74bdjuTicUoCTaTfw+CA3jO3vAmOZgdAlEhHRfXCmXk2cqScSF/ZX+10vrUTMoWxK1q8JAAAcsklEQVSkXC5BDwtjTBnmgSH+jpBKeTEt3cX+ItIOUV4oW1dXh1WrViEuLg4VFRXw9fXF0qVLERYW9sD9UlNTERsbi9TUVFy6dAlKpRKZmZn33T43NxerVq3CX3/9haqqKjg5OSEyMhKLFi1Sq16GeiJxYX91XGbeLWxLyEbu9Qo4y80xY5QX/D1thC6LOgH2F5F2tCfUC35j4jfffBObNm3CpEmT8M4770AqlWLRokVISUl54H6HDx9GdHQ0AMDFxeWB2164cAHTp0/HtWvXsHjxYrz77rsYM2YMbty4obHPQUSkr3xce+Dd+X3x7GQ/1NTV48tt5/DFLynIK2SYIyLqLASdqU9NTUVUVBTeeustLFy4EABQW1uLCRMmwM7ODlu3br3vviUlJTA3N4eJiQk+/vhjbN68udWZ+oaGBkyaNAkeHh74+uuvIZV27PcYztQTiQv7S7OU9Y1IOKPArhNXUFVTj8H+Dpg63BPWliZCl0YCYH8RaYfoZur37t0LmUyGqKiopjFjY2NMnz4dycnJKCoquu++tra2MDF5+JfIsWPHkJWVhaVLl0IqlaKyshKNjY0aqZ+IqKuRGUoxdoArPn02DI8NcEViRiHeWvcXth/ORlVNvdDlERF1WYKG+oyMDHh4eMDMzKzZeGBgIFQqFTIyMjp8jpMnT8Lc3ByFhYV47LHHEBoaitDQULz77ruorq7u8PGJiLoiMxMZZoR745NFg9D3ETl+P3kVb649iYPJCtQ3cOKEiEjXBA31xcXFsLOzazEul8sB4IEz9W119epVNDQ04Pnnn8fQoUOxevVqzJo1CzExMXj11Vc7fHwioq7M1qobnpnkh/cW9IOz3Axb91/CexsSkZxZBN5cjYhIdwS9T31NTQ1kMlmLcWNjYwB319d3VFVVFaqrq/G3v/0N7733HgBg7NixkEgk2LhxIy5evAhfX982H0/d9U1tJZdbaOW4RMT+0gW53AL9A3oiKaMQP+y+gG93pKG3uzWenOgHX3drocsjLWJ/EXUOgoZ6ExMTKJXKFuP3wvy9cN/RcwDAhAkTmo1PmjQJGzduRHJyslqhnhfKEokL+0u33OVmeH9BPxxNvY6dR3Px+uqj6Ocjx7SRXrDvYSp0eaRh7C8i7RDdE2XlcnmrS2yKi4sBoNWlOe05BwDY2DS/p/K91xUVFR0+BxER/YeBVIqRwU4Y1MceexPzsPdUHlIul2BUiBMmDnGHhamR0CUSEekdQdfU+/r6Ijc3F5WVlc3Gz5071/R+R/n5+QEACgsLm43fu0e9tTX/LExEpA0mRoaYMswTny4Ow5AARxw8o8Cba09iz19XUadsELo8IiK9Imioj4iIgFKpbHqIFHD3CbOxsbEIDQ2Fvb09AKCgoADZ2dntOkd4eDhkMhliYmKajUdHR0MikWDQoEHt/wBERPRQVubGWPi4Lz54cgAecbZCzKFsvL3+L5xIu45GXkxLRKQRgi6/CQoKQkREBFasWIHi4mK4urpix44dKCgowLJly5q2e+ONN3Dq1KlmD5e6du0a4uLiAADnz58HAKxZswbA3Rn+8PBwAIC9vT2eeeYZfPvtt1AqlRg0aBBSUlLw22+/Yfbs2XBzc9PVxyUi6tKc5OZ4OSoIGVdvYVtCFjbszsC+U/mICveGHy+mJSLqEEGfKAvcvSh25cqV2LVrF8rLy+Hj44NXXnkFgwcPbtpm3rx5LUJ9YmIi5s+f3+oxp06dik8//bTptUqlwqZNm/DTTz+hoKAAdnZ2iIqKwuLFi9V+wiwvlCUSF/ZX59SoUuFUeiG2H85BaUUNAjxtEDXKC85y7dxhjLSD/UWkHe25UFbwUC82DPVE4sL+6tyU9Q04mHwNu09cQXVdPYYGOGLKME/0sOj43c9I+9hfRNohurvfEBFR1yYzNEDEQFcMDXTE7hNXcDBZgcSMQjzW3xURA13RzZhfU0REbcGZejVxpp5IXNhf4lJUVo3Yw9k4lVEES1MZJg/zxPAgRxiouVSSdIP9RaQdXH6jAwz1ROLC/hKn7IJyRMdn4ZKiHA7Wpoga6YXgXraQSCRCl0b/hf1FpB0M9TrAUE8kLuwv8VKpVDh7uQTRh7Jx42YVHnGxwoxR3vDsaSl0afT/sb+ItINr6omISG9IJBKEPCJHgJcNjp4rQNyxXHy0OQkDetshcoQX7Ky6CV0iEVGnwVBPRESdmqGBFKNCnTHIzwF/JOZh36k8JGcWY3RfZ0wY7A7zbjKhSyQiEhxDPRERiUI3Y0NEDvfEqBAn7Diag/2n83Es9TomDHbH6L5OkBkaCF0iEZFguKZeTVxTTyQu7C/9pSi6g22HspCWcxO23U0QOdwTA/rYQ8qLaXWG/UWkHbxQVgcY6onEhf2l/y5cuYno+CzkFd2Bu4MFZozyhq9bD6HL6hLYX0TawVCvAwz1ROLC/uoaGlUqnEy7gdgjObh1uxZBXjaYPsobTrZmQpem19hfRNrBUK8DDPVE4sL+6lrqlA3Yn5SPPX9dRU1dA4YH9cSUoR7obm4sdGl6if1FpB28pSUREXVpRjIDjA9zx7Cgnth1/AoOpVzDXxcKETHQFY8NcIGJEb/2iEg/caZeTZypJxIX9lfXVnizCjGHs5GcWYzuZkaYMswDQwMdYSCVCl2aXmB/EWkHl9/oAEM9kbiwvwgAshTl+DXhMrKvVaCnrRmiRnoh0MsGEt4pp0PYX0TawVCvAwz1ROLC/qJ7VCoVkjOLEXM4G0W3quHraoWZ4b3g5mAhdGmixf4i0g6Geh1gqCcSF/YX/a/6hkYcSrmG345fwZ1qJQb52SNyuCdsu3cTujTRYX8RaQcvlCUiInoIQwMpxvRzwWB/R+z56yr2J+Uj6WIxxvRzxoQwN5iayIQukYhIbZypVxNn6onEhf1FD3OzogaxR3JwMu0GTE0MMXGIB8JDnWBowItpH4b9RaQdXH6jAwz1ROLC/qK2yiu8jW0JWUi/cgtyKxNMG+GF/r52vJj2AdhfRNrBUK8DDPVE4sL+InWoVCqk5d5EdEIWFMWV8OxpiRmjvPGIi5XQpXVK7C8i7eCaeiIiog6QSCQI8LSBn7s1jqddx44jOfh06xmE9LLF9JFecLQxE7pEIqJWcaZeTZypJxIX9hd1RK2yAftO52PPX1ehVDZiRHBPTB7qAUszI6FL6xTYX0TawZl6IiIiDTKWGWDiYHeMCOqJuOO5OJxSgBMXbmDcIDeM7e8CY5mB0CUSEQHgTL3aOFNPJC7sL9Kk66WViDmUjZTLJehhYYwpwzwwxN8RUmnXvJiW/UWkHbxQVgcY6onEhf1F2nApvwy/xmch93oFnOVmmDHKG/6eNkKXpXPsLyLtYKjXAYZ6InFhf5G2qFQqnL5YhO2Hs1FcVgM/9x6IGuUNV3sLoUvTGfYXkXYw1OsAQz2RuLC/SNuU9Y1ISLmGXcdzUVVTjzB/B0QO94S1pYnQpWkd+4tIO3ihLBERkY7JDKUY298FQwIc8PvJqziQpMDpi0V4tJ8Lxg1yg6kJv2qJSPs4U68mztQTiQv7i3StpLwasUdy8NeFQph3k2HSEHeMDHGCoYFU6NI0jv1FpB1cfqMDDPVE4sL+IqFcuVGBbfFZuJhXBrse3TB9hBf6+sghkejPnXLYX0TawVCvAwz1ROLC/iIhqVQqpGaXIvpQNgpKKuHt1B0zwr3h7dRd6NI0gv1FpB1cU09ERNSJSCQSBHnbwt/TGsdSr2Pn0Vx8siUZfX3kmD7SC/Y9TIUukYj0BEM9ERGRlhlIpRgR7ISBfezx56l87E3Mw9nLJRgZ4oRJQ9xhYWokdIlEJHIM9URERDpiYmSIyUM9MCK4J+KO5SL+jAIn0q5j3CA3PNrPBUYyA6FLJCKR4pp6NXFNPZG4sL+oM7tWUomYhCycyy6FtaUxpg7zRJi/A6QiuZiW/UWkHbxQVgcY6onEhf1FYnDx6i38mpCFqzduw9XOHFHh3vBztxa6rIdifxFpB0O9DjDUE4kL+4vEolGlwqn0Qmw/nIPSihr4e1pjxkhvONup98WuS+wvIu1gqNcBhnoicWF/kdgo6xtwMPkadp+4guq6egwJcMTUYZ7oYWEsdGktsL+ItIO3tCQiIhI5maEBIga6YmigI3afuIKDyQqcSi/E2AGueHygK7oZ86ubiFriTL2aOFNPJC7sLxK7orJqxB7OxqmMIliayjB5qAeGBfWEoYFU6NLYX0RawuU3OsBQTyQu7C/SFzkFFdgWfxmXFOVwsDZF1EgvBPeyhUTAO+Wwv4i0g6FeBxjqicSF/UX6RKVS4ezlEkQfysaNm1V4xLk7ZoT3gmdPS0HqYX8RaQfX1BMREekxiUSCkEfkCPCywdFzBYg7louPNidhQG87RI7wgp1VN6FLJCKBCBrq6+rqsGrVKsTFxaGiogK+vr5YunQpwsLCHrhfamoqYmNjkZqaikuXLkGpVCIzM/Oh59uzZw+WLl0KCwsLJCUlaepjEBER6ZShgRSjQp0xyM8BexPz8OepPCRnFmN0X2dMGOwO824yoUskIh0T9CqbN998E5s2bcKkSZPwzjvvQCqVYtGiRUhJSXngfocPH0Z0dDQAwMXFpU3nqqmpweeffw5TU9MO101ERNQZdDM2xNThnli2OAyD/R2wPykfb353En8kXoWyvkHo8ohIhwQL9ampqfj999/x2muv4f/+7/8wc+ZMbNq0CY6OjlixYsUD9501axaSk5MRGxuLoUOHtul869evh5GREcLDwzVRPhERUafRw8IYT4zrjX8+MQBeTt0RnZCNt9cl4q8LN9DIS+eIugTBQv3evXshk8kQFRXVNGZsbIzp06cjOTkZRUVF993X1tYWJiYmbT5XQUEBNmzYgDfeeAMyGf8kSURE+snZzhxLZwThtb8Fw8zEEOt2pePDTUm4ePWW0KURkZYJFuozMjLg4eEBMzOzZuOBgYFQqVTIyMjQ2Lk+++wzhISEcJaeiIi6hD7u1nj/if54anxv3K6qw/KfU7Aq+hyulVQKXRoRaYlgF8oWFxfD3t6+xbhcLgeAB87Uq+PUqVPYv38/YmNjNXI8IiIiMZBKJBgS4Ij+vnY4kKzA7yev4P2NiRge1BOTh3rAytxY6BKJSIMEC/U1NTWtLoUxNr77Q6a2trbD52hoaMBHH32EyMhI+Pr6dvh4ANS+Z2hbyeUWWjkuEbG/iBb0tMKUUb3w64FL2HM8F4nphZg60htTR3qjm3HHogD7i6hzECzUm5iYQKlUthi/F+bvhfuO+PXXX6FQKPD99993+Fj38OFTROLC/iL6j6lD3DG4jx22H8rGz/sysed4LiYP88CwQEcYSNVfkcv+ItIOUT18Si6Xt7rEpri4GABgZ2fXoePX1dXh66+/RmRkJGpqaqBQKAAAVVVVaGxshEKhgKmpKaytrTt0HiIiIjGx72GK56cGIOtaObbFZ2Hz3kwcSFJg+kgvBHnZQCKRCF0iEbWDYKHe19cXW7ZsQWVlZbOLZc+dO9f0fkfU1NTg1q1b2LJlC7Zs2dLi/dGjR2PcuHH46quvOnQeIiIiMfJ26o635obizKVixBzKxtcxqfB1tcKMcG+4O1gKXR4RqUmwUB8REYHvv/8e0dHRWLhwIYC7s+uxsbEIDQ1tuoi2oKAA1dXV8PLyUuv43bp1w7fffttifPPmzUhNTcWKFStavVCXiIioq5BIJOjrY4cgb1scPluAuGO5+ODHJAzqY4/I4Z6wteomdIlE1EaChfqgoCBERERgxYoVKC4uhqurK3bs2IGCggIsW7asabs33ngDp06dQmZmZtPYtWvXEBcXBwA4f/48AGDNmjUA7s7wh4eHQyaTYcyYMS3Oe+DAAaSnp7f6HhERUVdkaCDF6L7OCPNzwB+JV7HvdD6SMoswpq8Lxg92g5kJn/FC1NkJFuoBYPny5Vi5ciXi4uJQXl4OHx8frFu3Dn379n3gfgqFAqtWrWo2du/11KlTeT96IiKidjA1McS0EV4YFeKEHUdy8OepPBxNLcDEwe4YFeoMmaFgj7chooeQqFR8frQ6ePcbInFhfxG1X17hbUQnZOHClVuw7W6C6SO90N/XDn+lFyL2cDZuVtTC2tIYkSO8EObnIHS5RHqjPXe/YahXE0M9kbiwv4g6Li2nFNsSsqAoroRtdxOU3alFfcN/vguNDKVY8Lgvgz2RhrQn1PPvaERERPRA/p42+McTA/DEOF+UVtQ0C/QAUFffiNjD2QJVR0QAQz0RERG1gVQqwbDAnrjf3/dLKzr+JHgiaj+GeiIiImozG8vWn/h+v3Ei0g2GeiIiImqzyBFeMPqfu+AYGUoROUK958kQkWYJektLIiIiEpd7F8Py7jdEnQtDPREREaklzM8BYX4OvLsUUSfC5TdERERERCLHUE9EREREJHIM9UREREREIsdQT0REREQkcgz1REREREQix1BPRERERCRyDPVERERERCLHUE9EREREJHIM9UREREREIscnyqpJKpWI6rhExP4i0ib2F5HmtaevJCqVSqWFWoiIiIiISEe4/IaIiIiISOQY6omIiIiIRI6hnoiIiIhI5BjqiYiIiIhEjqGeiIiIiEjkGOqJiIiIiESOoZ6IiIiISOQY6omIiIiIRI6hnoiIiIhI5BjqiYiIiIhEzlDoArqqoqIibN68GefOnUNaWhqqqqqwefNmDBw4UOjSiEQtNTUVO3bsQGJiIgoKCmBlZYWQkBAsWbIEbm5uQpdHJGrnz5/Hd999h/T0dJSWlsLCwgK+vr544YUXEBoaKnR5RHpn/fr1WLFiBXx9fREXF/fAbRnqBZKbm4v169fDzc0NPj4+SElJEbokIr2wYcMGnDlzBhEREfDx8UFxcTG2bt2KKVOmICYmBl5eXkKXSCRa+fn5aGhoQFRUFORyOW7fvo1du3Zh7ty5WL9+PYYMGSJ0iUR6o7i4GP/6179gamrapu0lKpVKpeWaqBV37tyBUqlEjx49cODAAbzwwgucqSfSgDNnzsDf3x9GRkZNY1euXMHEiRMxfvx4fPrppwJWR6R/qqurMWbMGPj7+2Pt2rVCl0OkN958800UFBRApVKhoqLioTP1XFMvEHNzc/To0UPoMoj0TmhoaLNADwDu7u7o1asXsrOzBaqKSH9169YN1tbWqKioELoUIr2RmpqK3377DW+99Vab92GoJyK9p1KpUFJSwl+kiTTkzp07uHnzJnJycvDll1/i0qVLCAsLE7osIr2gUqnw4YcfYsqUKejdu3eb9+OaeiLSe7/99hsKCwuxdOlSoUsh0gtvv/02/vzzTwCATCbD3/72Nzz77LMCV0WkH3bu3ImsrCx8++23au3HUE9Eei07OxsffPAB+vbti8mTJwtdDpFeeOGFFzBz5kzcuHEDcXFxqKurg1KpbLH0jYjUc+fOHXzxxRd45plnYGdnp9a+XH5DRHqruLgYixcvRvfu3bFq1SpIpfyRR6QJPj4+GDJkCKZNm4aNGzfiwoULaq39JaLW/etf/4JMJsMTTzyh9r78hiMivXT79m0sWrQIt2/fxoYNGyCXy4UuiUgvyWQyjB49Gvv27UNNTY3Q5RCJVlFRETZt2oTZs2ejpKQECoUCCoUCtbW1UCqVUCgUKC8vv+/+XH5DRHqntrYWzz77LK5cuYIff/wRnp6eQpdEpNdqamqgUqlQWVkJExMTocshEqXS0lIolUqsWLECK1asaPH+6NGjsWjRIrz22mut7s9QT0R6paGhAUuWLMHZs2exZs0aBAcHC10Skd64efMmrK2tm43duXMHf/75JxwdHWFjYyNQZUTi5+zs3OrFsStXrkRVVRXefvttuLu733d/hnoBrVmzBgCa7p0dFxeH5ORkWFpaYu7cuUKWRiRan376KeLj4zFq1CiUlZU1e1iHmZkZxowZI2B1ROK2ZMkSGBsbIyQkBHK5HNevX0dsbCxu3LiBL7/8UujyiETNwsKi1e+oTZs2wcDA4KHfX3yirIB8fHxaHXdyckJ8fLyOqyHSD/PmzcOpU6dafY+9RdQxMTExiIuLQ1ZWFioqKmBhYYHg4GA8+eSTGDBggNDlEemlefPmtemJsgz1REREREQix7vfEBERERGJHEM9EREREZHIMdQTEREREYkcQz0RERERkcgx1BMRERERiRxDPRERERGRyDHUExERERGJHEM9ERF1evPmzUN4eLjQZRARdVqGQhdARETCSExMxPz58+/7voGBAdLT03VYERERtRdDPRFRFzdhwgQMHz68xbhUyj/mEhGJBUM9EVEX16dPH0yePFnoMoiIqAM4DUNERA+kUCjg4+OD1atXY/fu3Zg4cSICAgIwcuRIrF69GvX19S32uXjxIl544QUMHDgQAQEBGDduHNavX4+GhoYW2xYXF+Ojjz7C6NGj4e/vj7CwMDzxxBM4fvx4i20LCwvxyiuvoH///ggKCsJTTz2F3NxcrXxuIiIx4Uw9EVEXV11djZs3b7YYNzIygrm5edPr+Ph45OfnY86cObC1tUV8fDy++eYbFBQUYNmyZU3bnT9/HvPmzYOhoWHTtgkJCVixYgUuXryIL774omlbhUKBWbNmobS0FJMnT4a/vz+qq6tx7tw5nDhxAkOGDGnatqqqCnPnzkVQUBCWLl0KhUKBzZs34/nnn8fu3bthYGCgpf9CRESdH0M9EVEXt3r1aqxevbrF+MiRI7F27dqm1xcvXkRMTAz8/PwAAHPnzsXf//53xMbGYubMmQgODgYAfPzxx6irq8Mvv/wCX1/fpm2XLFmC3bt3Y/r06QgLCwMA/POf/0RRURE2bNiAYcOGNTt/Y2Njs9e3bt3CU089hUWLFjWNWVtb4/PPP8eJEyda7E9E1JUw1BMRdXEzZ85EREREi3Fra+tmrwcPHtwU6AFAIpHg6aefxoEDB7B//34EBwejtLQUKSkpePTRR5sC/b1tn3vuOezduxf79+9HWFgYysrKcPToUQwbNqzVQP6/F+pKpdIWd+sZNGgQAODq1asM9UTUpTHUExF1cW5ubhg8ePBDt/Py8mox5u3tDQDIz88HcHc5zX+P/zdPT09IpdKmbfPy8qBSqdCnT5821WlnZwdjY+NmY1ZWVgCAsrKyNh2DiEhf8UJZIiIShQetmVepVDqshIio82GoJyKiNsnOzm4xlpWVBQBwcXEBADg7Ozcb/285OTlobGxs2tbV1RUSiQQZGRnaKpmIqMtgqCciojY5ceIELly40PRapVJhw4YNAIAxY8YAAGxsbBASEoKEhARcunSp2bbr1q0DADz66KMA7i6dGT58OI4cOYITJ060OB9n34mI2o5r6omIurj09HTExcW1+t69sA4Avr6+WLBgAebMmQO5XI6DBw/ixIkTmDx5MkJCQpq2e+eddzBv3jzMmTMHs2fPhlwuR0JCAo4dO4YJEyY03fkGAN577z2kp6dj0aJFmDJlCvz8/FBbW4tz587ByckJr7/+uvY+OBGRHmGoJyLq4nbv3o3du3e3+t6+ffua1rKHh4fDw8MDa9euRW5uLmxsbPD888/j+eefb7ZPQEAAfvnlF3z99df4+eefUVVVBRcXF7z22mt48sknm23r4uKC7du349tvv8WRI0cQFxcHS0tL+Pr6YubMmdr5wEREekii4t83iYjoARQKBUaPHo2///3vePHFF4Uuh4iIWsE19UREREREIsdQT0REREQkcgz1REREREQixzX1REREREQix5l6IiIiIiKRY6gnIiIiIhI5hnoiIiIiIpFjqCciIiIiEjmGeiIiIiIikWOoJyIiIiISuf8HmXcwSr2yw+cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5KnK6dOn5p_"
      },
      "source": [
        "Looks like we're over-fitting a bit on the third epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-M5ABsu6KX6"
      },
      "source": [
        "## S5. Performance On Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-AbUAJd6KX7"
      },
      "source": [
        "Now we'll load the holdout dataset and prepare inputs just as we did with the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiIjg4LEpPfe"
      },
      "source": [
        "### 5.1. Prepare Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXpaLPjkuAt8"
      },
      "source": [
        "The test set contains 153,164 samples, but only includes labels for 63,978 of them. In the challenge description, they explain that this was done to \"discourage hand-labeling\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSRCJtKPAz3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "583054d7-5759-4bca-ec84-b9c685718214"
      },
      "source": [
        "# Load the test set files.\n",
        "test = pd.read_csv('./data/test.csv')\n",
        "test_labels = pd.read_csv('./data/test_labels.csv')\n",
        "\n",
        "print('There are {:,} total test examples.'.format(len(test)))\n",
        "\n",
        "# The unlabeled test samples are indicated by all of the label values being\n",
        "# \"-1\" for that sample.\n",
        "\n",
        "# Select only the labeled test samples.\n",
        "### changed 1 to 2\n",
        "test = test[test_labels.class1 != - 1]\n",
        "test_labels = test_labels.loc[test_labels.class1 != -1]\n",
        "\n",
        "print('There are {:,} labeled test examples.'.format(len(test)))"
      ],
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1,000 total test examples.\n",
            "There are 1,000 labeled test examples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1lcxgaTpQRl"
      },
      "source": [
        "**Tokenize & Encode** \n",
        "\n",
        "Encode the test set, using the same code from 3.4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xzNcsKapQRo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00a95b05-4cb3-4f28-8965-067d094956d1"
      },
      "source": [
        "import torch\n",
        "\n",
        "input_ids = []\n",
        "attn_masks = []\n",
        "labels = []\n",
        "\n",
        "# ======== Encoding ========\n",
        "\n",
        "print('Encoding all {:,} test samples...'.format(len(test)))\n",
        "\n",
        "# For every test sample...\n",
        "for (index, row) in test.iterrows():\n",
        "\n",
        "    # Report progress.\n",
        "    if ((len(input_ids) % 5000) == 0):\n",
        "        print('  Tokenized {:,} comments.'.format(len(input_ids)))\n",
        "\n",
        "    # Convert sentence pairs to input IDs, with attention masks.\n",
        "    encoded_dict = tokenizer.encode_plus(row['comment_text'],  # The text to encode.\n",
        "                                        max_length=max_len,    # Pad or truncate to this lenght.\n",
        "                                        pad_to_max_length=True,\n",
        "                                        truncation=True, \n",
        "                                        return_tensors='pt')   # Return objects as PyTorch tensors.\n",
        "\n",
        "    # Add this example to our lists.\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attn_masks.append(encoded_dict['attention_mask'])\n",
        "    \n",
        "print('\\nDONE. {:,} examples.'.format(len(input_ids)))\n",
        "\n",
        "# ======== List of Examples --> Tensor ========\n",
        "\n",
        "# Convert each Python list of Tensors into a 2D Tensor matrix.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attn_masks = torch.cat(attn_masks, dim=0)\n"
      ],
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding all 1,000 test samples...\n",
            "  Tokenized 0 comments.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DONE. 1,000 examples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jow8BTudpl56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eceef3d-9af9-4038-e102-8de723e56961"
      },
      "source": [
        "\n",
        "# ======== Prepare Labels ========\n",
        "\n",
        "# Remove the 'id' column.\n",
        "#test_labels = test_labels[['class1', 'class2', 'class3']]\n",
        "del test_labels['id']\n",
        "\n",
        "# The labels are either 0 or 1. Despite this, we need to cast the values to\n",
        "# floats--otherwise our loss function will throw an error.\n",
        "# https://discuss.pytorch.org/t/nn-bcewithlogitsloss-cant-accept-one-hot-target/59980\n",
        "labels = test_labels.to_numpy().astype(float)\n",
        "\n",
        "# Cast the labels list to a 2D Tensor.\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# ======== Summary ========\n",
        "\n",
        "print('\\nData structure shapes:')\n",
        "print('   input_ids:  {:}'.format(str(input_ids.shape)))\n",
        "print('  attn_masks:  {:}'.format(str(attn_masks.shape)))\n",
        "print('      labels:  {:}'.format(str(labels.shape)))"
      ],
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data structure shapes:\n",
            "   input_ids:  torch.Size([1000, 128])\n",
            "  attn_masks:  torch.Size([1000, 128])\n",
            "      labels:  torch.Size([1000, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNrE5s6pqGVu"
      },
      "source": [
        "**DataLoader**\n",
        "\n",
        "Create a DataLoader to batch our test samples for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ndz4YWSqHyV"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "test_dataset = TensorDataset(input_ids, attn_masks, labels)\n",
        "\n",
        "# Specify our batch size.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader, which will select batches for us. For testing, the\n",
        "# order we evaluate the samples in doesn't matter, so we'll just use the \n",
        "# \"SequentialSampler\" to read them in order.\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset,  # The training samples.\n",
        "            sampler = SequentialSampler(test_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n"
      ],
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJJVmwstqzEn"
      },
      "source": [
        "### 5.2. Evaluate On Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqNzZkUx6KYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "349d0f51-8f60-4083-f4f9-5558b6bdcbf5"
      },
      "source": [
        "import time\n",
        "\n",
        "# Prediction on test set\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "print('Evaluating on {:,} test set batches...'.format(len(test_dataloader)))\n",
        "\n",
        "# Predict \n",
        "for batch in test_dataloader:\n",
        "    \n",
        "    # Report progress.\n",
        "    if ((len(predictions) % 500) == 0):\n",
        "        print('  Batch {:>5,}  of  {:>5,}.'.format(len(predictions), len(test_dataloader)))\n",
        "\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # Telling the model not to compute or store the compute graph, saving memory \n",
        "    # and speeding up prediction\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        # Forward pass, calculate logit predictions\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    # Store predictions and true labels\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')\n",
        "\n",
        "print('Evaluation took {:.0f} seconds.'.format(time.time() - t0))"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on 63 test set batches...\n",
            "  Batch     0  of     63.\n",
            "    DONE.\n",
            "Evaluation took 4 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJoh2shgrVx0"
      },
      "source": [
        "We collected the predictions in batches, so now we just need to recombine them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFcP525n6KYN"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)"
      ],
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5zp9DnVroQU"
      },
      "source": [
        "### 5.3. Score Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WcP_WxxrcRJ"
      },
      "source": [
        "Let's take a look at the model outputs for one of the test samples. \n",
        "\n",
        "Most samples don't contain anything toxic, so let's find one that actually does."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGDCd5xurlll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66384454-d744-45f0-e00e-a9fa10354527"
      },
      "source": [
        "# For every test sample...\n",
        "for test_i in range(0, len(test)):\n",
        "\n",
        "    # Break if it has at least one label set.\n",
        "    if np.any(flat_true_labels[test_i, :]):\n",
        "        break\n",
        "\n",
        "print('Test sample: {:,}\\n'.format(test_i))"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test sample: 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zlsscrsxLCd"
      },
      "source": [
        "Now we can look at the model's predictions vs. the correct labels for this test sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP4WyEvjw8OC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed471da-e02d-4a01-dd85-e01876ee0d95"
      },
      "source": [
        "# Print out model predictions vs. correct values for this test sample.\n",
        "print('           Type   Output   Truth')\n",
        "print('           ----   ------   -----')\n",
        "\n",
        "for label_i in range(0, 3):\n",
        "    print('{:>15}   {:>5.2f}      {:}'.format(\n",
        "        label_cols[label_i], # Label name\n",
        "        flat_predictions[test_i, label_i], # Model's prediction\n",
        "        int(flat_true_labels[test_i, label_i]))) # Correct label\n",
        "    "
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Type   Output   Truth\n",
            "           ----   ------   -----\n",
            "         class1    6.13      1\n",
            "         class2   -6.20      0\n",
            "         class3   -6.01      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvBEfONsxT00"
      },
      "source": [
        "Interpreting the accuracy of these predictions requires choosing a threshold confidence value. Since the labels were trained as either 0 or 1, then using a threshold of 0.5 seems like a reasonable first choice. \n",
        "\n",
        "By that threshold, our model got all of the labels correct!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfYBn8snX3kT"
      },
      "source": [
        "####\n",
        "import sys\n",
        "import numpy\n",
        "numpy.set_printoptions(threshold=sys.maxsize)"
      ],
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P8zYaDiM3qg"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYiHZJqkWccJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1badeea-0fd6-40da-a726-0ede0c0cc551"
      },
      "source": [
        "flat_predictions\n",
        "#flat_true_labels"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6.1267915 , -6.195876  , -6.0130024 ],\n",
              "       [ 6.0301943 , -6.071281  , -6.1758156 ],\n",
              "       [ 6.002379  , -6.054905  , -6.2194605 ],\n",
              "       [ 6.081835  , -6.126623  , -6.1393723 ],\n",
              "       [ 6.0970473 , -6.0639677 , -6.1655426 ],\n",
              "       [ 6.1068892 , -6.186465  , -6.030163  ],\n",
              "       [ 6.081107  , -6.2218184 , -5.954476  ],\n",
              "       [ 5.6674504 , -5.6569586 , -6.452525  ],\n",
              "       [ 6.026779  , -6.1502438 , -6.1551437 ],\n",
              "       [ 5.956227  , -6.082807  , -6.1400323 ],\n",
              "       [ 4.642043  , -4.532771  , -6.562317  ],\n",
              "       [-1.3541019 ,  1.4403633 , -5.2628465 ],\n",
              "       [-3.2400165 ,  3.4580452 , -5.342315  ],\n",
              "       [-2.963399  ,  2.975536  , -5.895939  ],\n",
              "       [-3.1879952 ,  3.2858794 , -5.6188917 ],\n",
              "       [-0.84889543,  1.0476427 , -6.41547   ],\n",
              "       [-3.3915324 ,  3.3671243 , -4.0702004 ],\n",
              "       [-1.9915397 , -0.6169409 , -0.24615146],\n",
              "       [-2.4767168 ,  0.7784619 , -1.398094  ],\n",
              "       [-2.4653077 , -3.0097373 ,  1.9149781 ],\n",
              "       [ 6.097972  , -6.2175827 , -6.0329275 ],\n",
              "       [ 5.9917417 , -6.0453944 , -6.2280817 ],\n",
              "       [ 6.124509  , -6.2652254 , -5.9685016 ],\n",
              "       [ 6.108773  , -6.1824865 , -6.040742  ],\n",
              "       [ 6.11961   , -6.2011395 , -6.0538287 ],\n",
              "       [ 5.454256  , -5.410141  , -6.4972925 ],\n",
              "       [-2.1265182 ,  2.2337167 , -5.6212463 ],\n",
              "       [-1.7668236 ,  1.8665332 , -6.073762  ],\n",
              "       [-3.13869   ,  3.1352394 , -5.6140423 ],\n",
              "       [-2.894853  ,  2.3180711 , -2.885953  ],\n",
              "       [-2.5495753 , -3.1590831 ,  2.0987988 ],\n",
              "       [-3.4627035 ,  3.3520644 , -3.6354208 ],\n",
              "       [-2.948947  ,  1.1013392 , -1.5802418 ],\n",
              "       [-3.0576744 , -3.1539505 ,  2.8702412 ],\n",
              "       [-2.2500596 , -3.5727918 ,  2.5989203 ],\n",
              "       [ 6.1096315 , -6.196874  , -6.0846634 ],\n",
              "       [ 6.136496  , -6.1893096 , -6.04029   ],\n",
              "       [ 6.1277456 , -6.236719  , -5.925928  ],\n",
              "       [ 6.100884  , -6.1913567 , -6.037535  ],\n",
              "       [ 5.7683673 , -5.920389  , -6.1845818 ],\n",
              "       [ 6.075856  , -6.1989756 , -6.0390177 ],\n",
              "       [ 6.0648665 , -6.162231  , -5.897749  ],\n",
              "       [ 6.0911746 , -6.2445316 , -5.981649  ],\n",
              "       [-3.2687073 ,  3.4140308 , -5.4665165 ],\n",
              "       [-3.2870433 ,  3.3167446 , -5.5098124 ],\n",
              "       [-3.3692586 ,  3.5225494 , -5.5803742 ],\n",
              "       [-3.355852  ,  3.407678  , -5.4634676 ],\n",
              "       [-2.2309968 , -2.4114206 ,  1.400487  ],\n",
              "       [-2.734435  ,  1.2587893 , -2.0041838 ],\n",
              "       [-3.2928243 , -3.1123312 ,  2.796433  ],\n",
              "       [-2.9776533 , -3.3697782 ,  2.6405473 ],\n",
              "       [-3.3189118 , -3.1161397 ,  2.8583536 ],\n",
              "       [-2.9791162 , -3.013339  ,  2.6340113 ],\n",
              "       [-3.1278067 , -3.44091   ,  2.9132857 ],\n",
              "       [-2.419118  , -3.2725418 ,  2.258306  ],\n",
              "       [-2.970722  , -2.8358514 ,  2.1061265 ],\n",
              "       [ 6.1117215 , -6.193998  , -6.0433073 ],\n",
              "       [ 6.1007385 , -6.203038  , -6.072049  ],\n",
              "       [ 6.133375  , -6.21918   , -6.012396  ],\n",
              "       [ 5.897004  , -5.976732  , -6.33426   ],\n",
              "       [ 5.932988  , -6.0293636 , -6.312809  ],\n",
              "       [ 6.097637  , -6.1922026 , -6.0388665 ],\n",
              "       [ 5.6725245 , -5.8302355 , -6.237667  ],\n",
              "       [ 5.9769096 , -6.1854315 , -6.0238695 ],\n",
              "       [ 6.020229  , -6.2506475 , -6.015822  ],\n",
              "       [ 5.9529896 , -6.024414  , -6.174471  ],\n",
              "       [ 6.0659676 , -6.2038155 , -6.0059905 ],\n",
              "       [-3.2664835 ,  3.222678  , -5.6832323 ],\n",
              "       [-3.1267352 ,  3.221454  , -5.7006035 ],\n",
              "       [-3.004768  ,  3.077367  , -5.9421544 ],\n",
              "       [-3.6395702 ,  3.8314872 , -5.1781073 ],\n",
              "       [-2.8366277 , -2.2396605 ,  1.9004331 ],\n",
              "       [-3.0868945 ,  2.9544613 , -3.3978395 ],\n",
              "       [-2.2023883 , -2.3588269 ,  1.2316984 ],\n",
              "       [-2.8095694 ,  2.6075554 , -3.167109  ],\n",
              "       [-1.7084306 , -3.0866582 ,  1.6175716 ],\n",
              "       [-2.7605267 ,  1.6610599 , -2.0278182 ],\n",
              "       [-3.2862875 , -2.5810177 ,  2.316481  ],\n",
              "       [ 6.0644536 , -6.103987  , -6.2013035 ],\n",
              "       [ 6.1711144 , -6.201094  , -5.954326  ],\n",
              "       [ 6.1059675 , -6.1916795 , -6.085154  ],\n",
              "       [ 6.1052675 , -6.222205  , -6.046277  ],\n",
              "       [ 6.1189146 , -6.2282057 , -6.005266  ],\n",
              "       [ 6.1172943 , -6.2547164 , -5.9852123 ],\n",
              "       [ 6.0762105 , -6.1532383 , -6.126258  ],\n",
              "       [ 5.762348  , -5.880355  , -6.266264  ],\n",
              "       [ 5.908711  , -6.0087347 , -6.2833567 ],\n",
              "       [ 5.0702076 , -5.1595893 , -6.0746903 ],\n",
              "       [-3.1702073 ,  3.286897  , -5.7107115 ],\n",
              "       [-3.2268612 ,  3.311187  , -5.514202  ],\n",
              "       [-3.1518838 ,  3.1867406 , -5.664891  ],\n",
              "       [-2.5105972 ,  2.699034  , -5.7850146 ],\n",
              "       [-3.148412  ,  3.0808928 , -5.6733103 ],\n",
              "       [-3.3938165 ,  3.4560692 , -5.550893  ],\n",
              "       [ 0.2595002 , -0.2755558 , -6.096198  ],\n",
              "       [-2.8318496 ,  2.9710925 , -5.841051  ],\n",
              "       [-2.0852594 ,  0.71886104, -1.6801815 ],\n",
              "       [-3.366663  ,  3.139704  , -3.4898305 ],\n",
              "       [-3.4391809 ,  3.1577046 , -2.984703  ],\n",
              "       [-3.0955796 , -3.3896797 ,  2.7399547 ],\n",
              "       [-2.929469  , -3.4094915 ,  2.5504122 ],\n",
              "       [-2.7588696 , -3.5222285 ,  2.5802028 ],\n",
              "       [-3.363058  , -3.2287512 ,  3.0433772 ],\n",
              "       [-2.8866506 , -3.4803126 ,  2.708313  ],\n",
              "       [-3.0563126 , -3.304019  ,  2.9017377 ],\n",
              "       [ 6.1244345 , -6.2231016 , -5.982336  ],\n",
              "       [ 6.1369753 , -6.198906  , -5.9989986 ],\n",
              "       [ 6.1170526 , -6.2142267 , -6.019291  ],\n",
              "       [ 6.093402  , -6.1224647 , -6.1210485 ],\n",
              "       [ 6.1128306 , -6.2059984 , -6.0569196 ],\n",
              "       [ 6.1152296 , -6.260418  , -5.9247117 ],\n",
              "       [ 5.6028223 , -5.6314077 , -6.3591323 ],\n",
              "       [ 5.048767  , -5.078688  , -6.599552  ],\n",
              "       [ 2.9031346 , -2.94933   , -6.090678  ],\n",
              "       [ 5.2637033 , -5.2533407 , -6.5321655 ],\n",
              "       [-3.3221292 ,  3.2575748 , -5.6867785 ],\n",
              "       [-2.836501  ,  2.9829183 , -5.8090277 ],\n",
              "       [-3.2382784 ,  3.3171227 , -5.725465  ],\n",
              "       [-2.7756925 ,  3.0633674 , -5.6756315 ],\n",
              "       [-2.8820775 ,  2.9105136 , -4.8944807 ],\n",
              "       [-3.3235874 ,  3.3783467 , -5.4512625 ],\n",
              "       [-3.116638  ,  3.2530444 , -5.8446116 ],\n",
              "       [-3.3871145 ,  3.0145442 , -3.4213428 ],\n",
              "       [-2.942069  ,  1.375483  , -1.7542026 ],\n",
              "       [-3.3506317 ,  3.436332  , -3.5270212 ],\n",
              "       [-2.8848631 , -3.3015137 ,  2.5689793 ],\n",
              "       [-3.021398  , -2.5458672 ,  1.9952675 ],\n",
              "       [-3.0870266 , -3.4343724 ,  2.9115362 ],\n",
              "       [-2.9535153 , -3.0397072 ,  2.2840157 ],\n",
              "       [ 6.0283585 , -6.1650214 , -6.105975  ],\n",
              "       [ 6.1487355 , -6.239636  , -5.9758353 ],\n",
              "       [ 6.0736213 , -6.1765413 , -6.079606  ],\n",
              "       [ 6.1236324 , -6.1301413 , -6.103471  ],\n",
              "       [ 3.5674372 , -3.4550064 , -6.0021043 ],\n",
              "       [ 6.053913  , -6.188883  , -6.0308175 ],\n",
              "       [ 5.9216094 , -6.1056814 , -6.0526266 ],\n",
              "       [ 6.0420804 , -6.282401  , -5.863597  ],\n",
              "       [-3.0953772 ,  2.9668152 , -5.634364  ],\n",
              "       [-3.0563796 ,  2.9276702 , -5.578924  ],\n",
              "       [-3.1159434 ,  3.0323484 , -5.56446   ],\n",
              "       [-3.342793  ,  3.3616986 , -5.539487  ],\n",
              "       [-3.1411872 ,  3.108037  , -5.6808434 ],\n",
              "       [-3.3734078 ,  3.3682668 , -5.6602416 ],\n",
              "       [-2.2306893 ,  2.4150276 , -5.670681  ],\n",
              "       [-2.7777243 ,  1.5396652 , -1.9771786 ],\n",
              "       [-2.5393384 , -2.04613   ,  1.4960619 ],\n",
              "       [-2.1687007 , -2.4274428 ,  1.5366887 ],\n",
              "       [-2.4824448 , -3.0674644 ,  2.051268  ],\n",
              "       [-2.687281  ,  0.2911985 , -0.61530036],\n",
              "       [-3.1398733 , -3.2224004 ,  2.5310354 ],\n",
              "       [-2.6414752 , -3.0872288 ,  2.267047  ],\n",
              "       [-2.824246  , -3.4434307 ,  2.5943084 ],\n",
              "       [-2.6202233 , -3.4190612 ,  2.3633566 ],\n",
              "       [-3.1478996 , -3.100998  ,  2.6191225 ],\n",
              "       [ 6.095985  , -6.182124  , -6.0751066 ],\n",
              "       [ 6.114791  , -6.154996  , -6.0847645 ],\n",
              "       [ 6.1181383 , -6.2183714 , -6.039844  ],\n",
              "       [ 5.457945  , -5.339258  , -6.5719905 ],\n",
              "       [-2.7877073 ,  2.4395564 , -4.2207775 ],\n",
              "       [ 5.0775785 , -5.2092466 , -6.3170075 ],\n",
              "       [ 3.6275532 , -3.832167  , -6.7494526 ],\n",
              "       [-3.1311522 ,  3.1717155 , -5.709586  ],\n",
              "       [-2.973773  ,  3.1279929 , -5.453813  ],\n",
              "       [-3.110083  ,  3.1695018 , -5.7496557 ],\n",
              "       [-3.014731  ,  3.039398  , -5.815073  ],\n",
              "       [-3.079958  ,  3.1304052 , -5.656175  ],\n",
              "       [-3.198964  , -3.1599739 ,  2.6733317 ],\n",
              "       [-2.9453847 ,  2.4901066 , -2.7827885 ],\n",
              "       [-2.1175723 , -3.383867  ,  2.0575876 ],\n",
              "       [-2.719314  , -3.302738  ,  2.6512496 ],\n",
              "       [ 6.1366735 , -6.207507  , -6.025539  ],\n",
              "       [ 6.128406  , -6.2199464 , -6.0087028 ],\n",
              "       [ 6.125751  , -6.1894026 , -6.065645  ],\n",
              "       [ 5.6234236 , -5.6651487 , -6.505648  ],\n",
              "       [ 5.9186335 , -6.00247   , -6.1923733 ],\n",
              "       [ 6.0349045 , -6.094945  , -6.1332474 ],\n",
              "       [ 6.0478873 , -6.2109385 , -5.930277  ],\n",
              "       [ 6.0647335 , -6.2254696 , -5.974545  ],\n",
              "       [ 6.04591   , -6.183858  , -5.9758005 ],\n",
              "       [ 5.6625986 , -5.83319   , -6.3476334 ],\n",
              "       [ 5.9664965 , -6.118787  , -6.098672  ],\n",
              "       [-2.8620145 ,  2.8880847 , -5.850109  ],\n",
              "       [-0.7658726 ,  0.68844277, -5.6537046 ],\n",
              "       [-1.6583124 ,  1.8097227 , -6.2850537 ],\n",
              "       [-2.0275564 , -1.7286868 ,  0.7268793 ],\n",
              "       [-3.369559  ,  2.7550504 , -2.785606  ],\n",
              "       [-2.826747  , -2.9135292 ,  2.108965  ],\n",
              "       [-2.1008503 , -3.3943863 ,  2.1339116 ],\n",
              "       [-2.8011303 , -3.2539973 ,  2.5194912 ],\n",
              "       [-2.9968224 , -1.5646163 ,  1.2972803 ],\n",
              "       [ 6.1355386 , -6.2225933 , -6.020126  ],\n",
              "       [ 6.0804105 , -6.217478  , -6.0675135 ],\n",
              "       [ 6.136709  , -6.2376394 , -5.9941998 ],\n",
              "       [ 6.109524  , -6.196018  , -6.0695767 ],\n",
              "       [ 5.918896  , -6.043434  , -6.1915045 ],\n",
              "       [ 6.084424  , -6.2639713 , -5.917258  ],\n",
              "       [ 6.021709  , -6.1748934 , -6.075721  ],\n",
              "       [ 6.0561914 , -6.194467  , -5.9310594 ],\n",
              "       [ 6.1149106 , -6.285616  , -5.923045  ],\n",
              "       [ 5.9374876 , -6.219172  , -6.054451  ],\n",
              "       [ 6.0877705 , -6.2267003 , -6.053763  ],\n",
              "       [-3.2480862 ,  3.2000015 , -5.5884953 ],\n",
              "       [-2.9001157 ,  2.9940326 , -5.8793    ],\n",
              "       [-3.5829136 ,  3.7474854 , -5.267335  ],\n",
              "       [-2.5758083 ,  2.7883437 , -5.888274  ],\n",
              "       [-2.0964196 ,  0.28204635, -0.8655876 ],\n",
              "       [-3.0376318 ,  1.9502375 , -2.0432673 ],\n",
              "       [-2.5917537 ,  1.1879607 , -1.68065   ],\n",
              "       [-1.8440757 , -1.886559  ,  0.9253449 ],\n",
              "       [-2.7770753 , -2.6153414 ,  1.822032  ],\n",
              "       [-2.5361664 , -3.2200253 ,  2.188019  ],\n",
              "       [-2.8017516 , -3.3862395 ,  2.8730986 ],\n",
              "       [ 6.1299725 , -6.1972113 , -6.04443   ],\n",
              "       [ 6.1208835 , -6.2011786 , -6.067271  ],\n",
              "       [ 6.1009655 , -6.218232  , -6.04072   ],\n",
              "       [ 6.126226  , -6.2297635 , -5.9824305 ],\n",
              "       [ 6.1190834 , -6.2256894 , -6.0186486 ],\n",
              "       [ 6.1399655 , -6.2218285 , -5.9747734 ],\n",
              "       [ 6.139589  , -6.1814375 , -6.020937  ],\n",
              "       [ 6.1133795 , -6.229679  , -6.0294876 ],\n",
              "       [ 6.1168027 , -6.195446  , -6.0465155 ],\n",
              "       [ 6.1064305 , -6.2076273 , -6.0474577 ],\n",
              "       [ 6.124333  , -6.1738787 , -6.056051  ],\n",
              "       [ 6.105537  , -6.228242  , -6.0532584 ],\n",
              "       [ 6.1233006 , -6.23584   , -6.025226  ],\n",
              "       [-3.070531  ,  3.0720098 , -5.6744823 ],\n",
              "       [-3.125577  ,  3.1231208 , -5.630619  ],\n",
              "       [-2.925505  ,  2.9818585 , -5.8186097 ],\n",
              "       [-2.573804  ,  2.7706637 , -5.9533234 ],\n",
              "       [-1.8903751 ,  2.1410103 , -5.9616737 ],\n",
              "       [-2.2393737 , -2.8385127 ,  1.7421349 ],\n",
              "       [-2.7644358 , -3.0532563 ,  2.3104925 ],\n",
              "       [-3.2663422 , -2.524354  ,  2.1641128 ],\n",
              "       [-3.4383726 , -3.088474  ,  2.8946695 ],\n",
              "       [-2.3781137 , -2.614752  ,  1.7804407 ],\n",
              "       [ 6.1289616 , -6.221588  , -6.0126076 ],\n",
              "       [ 6.067773  , -6.1637936 , -6.128872  ],\n",
              "       [ 6.1432753 , -6.182536  , -6.0345592 ],\n",
              "       [ 6.100937  , -6.128886  , -6.1512966 ],\n",
              "       [ 6.120698  , -6.2079506 , -6.033979  ],\n",
              "       [ 6.1098623 , -6.227508  , -6.042141  ],\n",
              "       [ 5.414918  , -5.355343  , -6.516359  ],\n",
              "       [ 5.4343996 , -5.530316  , -6.3649864 ],\n",
              "       [-2.8977919 ,  3.0787804 , -5.7860327 ],\n",
              "       [-2.653428  ,  2.7539485 , -5.6457124 ],\n",
              "       [ 4.38723   , -4.3916097 , -6.2915497 ],\n",
              "       [-2.989256  ,  3.257077  , -5.643325  ],\n",
              "       [-3.2659266 ,  3.3369906 , -5.5620475 ],\n",
              "       [-3.4083266 ,  3.531792  , -5.528369  ],\n",
              "       [-0.95395875,  0.9468358 , -2.0525203 ],\n",
              "       [-2.2560902 , -1.5176402 ,  0.78033763],\n",
              "       [-1.9063962 , -3.189728  ,  1.9429039 ],\n",
              "       [-2.7770174 , -2.2922246 ,  1.7270762 ],\n",
              "       [-2.7060127 , -3.1396012 ,  2.3785892 ],\n",
              "       [ 6.114689  , -6.203776  , -6.045207  ],\n",
              "       [ 6.118683  , -6.219981  , -6.044194  ],\n",
              "       [ 6.146266  , -6.181733  , -6.017538  ],\n",
              "       [ 6.1279917 , -6.1792    , -6.0428686 ],\n",
              "       [ 6.0741863 , -6.1290874 , -6.186041  ],\n",
              "       [ 6.0920444 , -6.161801  , -6.0622096 ],\n",
              "       [ 6.1040797 , -6.279806  , -5.9396048 ],\n",
              "       [ 6.076931  , -6.26758   , -5.945377  ],\n",
              "       [ 5.8381615 , -5.921836  , -6.3682547 ],\n",
              "       [ 5.1194057 , -5.035077  , -6.436564  ],\n",
              "       [ 5.9793553 , -6.1403885 , -6.1101313 ],\n",
              "       [-3.0797844 ,  3.1706893 , -5.4930305 ],\n",
              "       [-2.7340562 ,  2.909617  , -5.39312   ],\n",
              "       [-3.258547  ,  3.3139858 , -5.5392604 ],\n",
              "       [-3.369602  ,  3.3475373 , -5.6242285 ],\n",
              "       [-2.2254074 ,  2.2149293 , -5.713279  ],\n",
              "       [-2.8702364 , -3.3869584 ,  2.6386633 ],\n",
              "       [-2.4873042 , -3.1713054 ,  2.1275373 ],\n",
              "       [-2.7235532 , -3.2687905 ,  2.35919   ],\n",
              "       [-2.1369948 , -3.419572  ,  2.075243  ],\n",
              "       [-2.7117558 , -2.7803347 ,  1.9861917 ],\n",
              "       [-3.0006037 , -3.2643445 ,  2.6410246 ],\n",
              "       [-3.2213268 , -3.325547  ,  2.9392703 ],\n",
              "       [ 6.126916  , -6.202244  , -6.0422544 ],\n",
              "       [ 6.1386805 , -6.2270055 , -5.9732113 ],\n",
              "       [ 6.1334553 , -6.2053137 , -6.0518265 ],\n",
              "       [ 5.9690175 , -6.005109  , -6.31659   ],\n",
              "       [ 5.975988  , -6.048649  , -6.229925  ],\n",
              "       [ 5.9709005 , -6.0111647 , -6.226887  ],\n",
              "       [ 6.038225  , -6.175112  , -6.0888867 ],\n",
              "       [ 5.6915455 , -5.691934  , -6.390174  ],\n",
              "       [ 5.9949503 , -6.2494946 , -6.0090084 ],\n",
              "       [ 5.8038273 , -5.9790125 , -6.2337008 ],\n",
              "       [ 5.596776  , -5.597515  , -6.4171877 ],\n",
              "       [ 6.112879  , -6.13883   , -6.0986643 ],\n",
              "       [ 4.924231  , -4.9122257 , -6.626577  ],\n",
              "       [ 5.9521503 , -6.1470647 , -6.1217213 ],\n",
              "       [-2.8834295 ,  3.0603378 , -5.8194103 ],\n",
              "       [-2.9630203 ,  3.0471194 , -5.731895  ],\n",
              "       [-1.3807033 ,  1.551769  , -5.467441  ],\n",
              "       [-1.8412694 ,  1.9072069 , -6.349165  ],\n",
              "       [-3.0794668 ,  3.140314  , -5.6405272 ],\n",
              "       [-1.6980911 ,  1.7959353 , -6.4579725 ],\n",
              "       [-3.5771124 ,  3.5540416 , -5.218316  ],\n",
              "       [-0.58417493,  0.39284053, -3.5181093 ],\n",
              "       [-3.0843582 ,  2.7786856 , -3.1161313 ],\n",
              "       [-3.0152888 , -3.4471023 ,  2.7607327 ],\n",
              "       [-2.7851543 , -3.2028167 ,  2.3472714 ],\n",
              "       [-3.3497972 , -3.097229  ,  2.8942413 ],\n",
              "       [-2.9126158 , -2.7381694 ,  2.1572666 ],\n",
              "       [ 6.0487027 , -6.0882053 , -6.182861  ],\n",
              "       [ 6.1444497 , -6.1990147 , -5.979929  ],\n",
              "       [ 6.096187  , -6.231122  , -5.9576845 ],\n",
              "       [ 5.046547  , -5.0676537 , -6.5867534 ],\n",
              "       [ 6.072739  , -6.2059445 , -6.0135717 ],\n",
              "       [ 6.1091824 , -6.2631297 , -5.9598293 ],\n",
              "       [ 6.065633  , -6.143281  , -6.150233  ],\n",
              "       [ 6.114975  , -6.2273927 , -6.0233097 ],\n",
              "       [ 6.110185  , -6.249744  , -5.9370346 ],\n",
              "       [ 6.051114  , -6.2103434 , -6.01381   ],\n",
              "       [ 5.0648737 , -5.192813  , -6.34295   ],\n",
              "       [-2.7681196 ,  2.8583846 , -5.866219  ],\n",
              "       [-2.28502   ,  1.993283  , -5.4258623 ],\n",
              "       [-2.9352098 ,  3.0771239 , -5.791725  ],\n",
              "       [-2.897383  ,  3.1108985 , -5.662682  ],\n",
              "       [-3.106385  ,  3.1242206 , -5.5815196 ],\n",
              "       [-3.2609816 ,  3.4452438 , -5.3117113 ],\n",
              "       [-3.5457115 ,  3.6191356 , -5.2973566 ],\n",
              "       [-3.3830512 ,  3.2048807 , -3.546948  ],\n",
              "       [-3.445632  ,  3.4274824 , -3.494863  ],\n",
              "       [-2.109201  , -0.9029637 ,  0.53658885],\n",
              "       [-2.4101005 , -2.9291584 ,  2.06622   ],\n",
              "       [-2.9227798 , -3.1870904 ,  2.5397663 ],\n",
              "       [ 6.1085844 , -6.2070093 , -6.059058  ],\n",
              "       [ 6.0880003 , -6.275153  , -5.945408  ],\n",
              "       [ 5.131845  , -5.255698  , -6.330179  ],\n",
              "       [ 1.4509088 , -1.6620893 , -5.025152  ],\n",
              "       [ 6.0445685 , -6.248789  , -5.9797544 ],\n",
              "       [ 6.009015  , -6.1240616 , -6.17813   ],\n",
              "       [ 6.0781612 , -6.230747  , -5.9637604 ],\n",
              "       [ 5.9588175 , -6.097541  , -5.9864044 ],\n",
              "       [ 5.944834  , -6.0479765 , -6.1784306 ],\n",
              "       [-2.840496  ,  2.7360091 , -5.847411  ],\n",
              "       [-3.2649996 ,  3.158569  , -5.5615597 ],\n",
              "       [-3.5674188 ,  3.8381627 , -5.1686916 ],\n",
              "       [-3.0020537 ,  3.1681347 , -5.7831883 ],\n",
              "       [-2.909341  ,  2.9567382 , -5.0201254 ],\n",
              "       [-3.0575092 ,  2.729642  , -3.0965674 ],\n",
              "       [-3.2402377 ,  3.2819414 , -3.438013  ],\n",
              "       [-2.1385999 , -3.2311623 ,  2.0025449 ],\n",
              "       [-2.2348871 , -1.7888119 ,  1.1770873 ],\n",
              "       [-2.706009  , -2.889588  ,  2.2388754 ],\n",
              "       [-2.6826735 , -3.5361745 ,  2.6611478 ],\n",
              "       [-2.8523111 , -3.4211597 ,  2.593876  ],\n",
              "       [ 6.143303  , -6.116213  , -6.1038704 ],\n",
              "       [ 6.1217937 , -6.2031517 , -6.0662203 ],\n",
              "       [ 6.130697  , -6.1770635 , -6.0489917 ],\n",
              "       [-1.1888719 ,  1.1792085 , -6.6419077 ],\n",
              "       [ 5.7434154 , -5.7958336 , -6.308693  ],\n",
              "       [ 5.8954964 , -6.0640674 , -6.113209  ],\n",
              "       [ 6.081396  , -6.2679176 , -5.923974  ],\n",
              "       [ 6.0390635 , -6.1670084 , -5.952101  ],\n",
              "       [ 5.955943  , -6.111475  , -6.1534615 ],\n",
              "       [ 4.6765738 , -4.7196107 , -5.958721  ],\n",
              "       [ 6.086974  , -6.294467  , -5.878231  ],\n",
              "       [-3.1952326 ,  3.2452672 , -5.733135  ],\n",
              "       [-3.170121  ,  3.2459571 , -5.6908593 ],\n",
              "       [-3.3122067 ,  3.3552566 , -5.468164  ],\n",
              "       [ 5.8208513 , -5.8545475 , -6.37326   ],\n",
              "       [-2.5746229 ,  2.427044  , -5.24774   ],\n",
              "       [-2.7581449 ,  1.4421108 , -2.8753242 ],\n",
              "       [-3.0574203 ,  2.5609844 , -3.0102637 ],\n",
              "       [-2.7228737 , -2.2442944 ,  1.572246  ],\n",
              "       [-2.9297366 , -3.2530792 ,  2.4883626 ],\n",
              "       [-3.1052651 , -3.3716729 ,  2.7364829 ],\n",
              "       [-1.8733287 , -3.3569627 ,  1.7345092 ],\n",
              "       [ 6.1047516 , -6.213019  , -6.0495553 ],\n",
              "       [ 6.146172  , -6.1875176 , -6.0424404 ],\n",
              "       [ 6.115917  , -6.1770735 , -6.0622926 ],\n",
              "       [ 6.0892906 , -6.090554  , -6.191333  ],\n",
              "       [ 6.129116  , -6.20243   , -6.0376077 ],\n",
              "       [ 5.810773  , -5.9203515 , -6.3029966 ],\n",
              "       [ 5.997149  , -6.1777277 , -6.1071577 ],\n",
              "       [ 6.06501   , -6.2638474 , -5.993037  ],\n",
              "       [-2.8694844 ,  2.7672937 , -5.9997826 ],\n",
              "       [-2.93217   ,  3.03982   , -5.778328  ],\n",
              "       [-3.0367265 ,  3.0764093 , -5.766603  ],\n",
              "       [-3.4000404 ,  3.4853127 , -5.4188604 ],\n",
              "       [-3.1735969 ,  3.2637672 , -5.6927457 ],\n",
              "       [-3.4797692 ,  3.473795  , -5.525571  ],\n",
              "       [-3.6196012 ,  3.7330532 , -5.2877903 ],\n",
              "       [-2.7394943 ,  1.9484239 , -2.8627496 ],\n",
              "       [-3.288423  ,  3.2918918 , -3.3058481 ],\n",
              "       [-2.3869743 , -0.4213949 ,  0.21362069],\n",
              "       [-2.9026654 , -3.235318  ,  2.5445275 ],\n",
              "       [-2.983314  , -3.27851   ,  2.4611797 ],\n",
              "       [-2.6607733 , -1.8803405 ,  1.4107041 ],\n",
              "       [-2.9576874 , -3.3926582 ,  2.6559439 ],\n",
              "       [-3.0313    , -3.510102  ,  2.9876657 ],\n",
              "       [ 6.095338  , -6.200124  , -6.0986595 ],\n",
              "       [ 6.111083  , -6.179182  , -6.0508385 ],\n",
              "       [ 5.80559   , -5.8213124 , -6.3896713 ],\n",
              "       [ 6.113599  , -6.186407  , -6.0578775 ],\n",
              "       [ 6.041906  , -6.056631  , -6.20829   ],\n",
              "       [ 6.0775867 , -6.188259  , -6.050422  ],\n",
              "       [ 6.1149426 , -6.244239  , -6.0081024 ],\n",
              "       [ 6.076294  , -6.0910187 , -6.168954  ],\n",
              "       [ 5.8708563 , -6.053518  , -6.2354383 ],\n",
              "       [ 5.969672  , -6.0110536 , -6.1335073 ],\n",
              "       [ 5.701217  , -5.70809   , -6.4768777 ],\n",
              "       [ 5.9981046 , -6.201363  , -6.0141573 ],\n",
              "       [-3.1931052 ,  3.2027533 , -5.750833  ],\n",
              "       [-1.8722407 ,  1.7810383 , -6.3372364 ],\n",
              "       [-3.0249243 ,  3.0946798 , -5.702001  ],\n",
              "       [-2.9631548 ,  2.9159143 , -5.6485806 ],\n",
              "       [-3.040669  ,  3.012217  , -5.6933    ],\n",
              "       [-2.948864  ,  3.1682336 , -5.810954  ],\n",
              "       [-3.100213  ,  3.0226471 , -5.720221  ],\n",
              "       [-2.855061  ,  2.3578098 , -2.9026828 ],\n",
              "       [-3.2976112 ,  3.0847242 , -3.4176898 ],\n",
              "       [-2.9175773 , -1.9826231 ,  1.5201095 ],\n",
              "       [-2.4430544 , -1.4791316 ,  1.1779562 ],\n",
              "       [-1.3700309 , -2.9659219 ,  1.5607089 ],\n",
              "       [ 6.1401324 , -6.2225294 , -6.015565  ],\n",
              "       [ 6.126759  , -6.2039847 , -6.0451736 ],\n",
              "       [ 6.1049037 , -6.1561756 , -6.084864  ],\n",
              "       [ 6.084582  , -6.1164017 , -6.1442685 ],\n",
              "       [ 6.0362005 , -6.0899496 , -6.1891203 ],\n",
              "       [ 6.13651   , -6.1954737 , -6.050652  ],\n",
              "       [ 6.138098  , -6.195306  , -6.032555  ],\n",
              "       [ 6.1453714 , -6.210845  , -5.9760227 ],\n",
              "       [ 6.078     , -6.13614   , -6.100972  ],\n",
              "       [ 5.9172654 , -5.89785   , -6.3692527 ],\n",
              "       [ 5.297597  , -5.3619227 , -6.3748875 ],\n",
              "       [ 5.497238  , -5.479141  , -6.408766  ],\n",
              "       [-2.8318324 ,  2.7544003 , -5.9442806 ],\n",
              "       [-2.9198823 ,  3.003982  , -5.73983   ],\n",
              "       [-3.1074958 ,  3.106973  , -5.661983  ],\n",
              "       [-3.0017972 ,  3.079051  , -5.7893867 ],\n",
              "       [-2.862969  ,  2.881254  , -5.9403667 ],\n",
              "       [-3.1573892 ,  3.2336128 , -5.727579  ],\n",
              "       [-3.1715038 ,  3.3336232 , -5.691371  ],\n",
              "       [-2.5804975 ,  1.4233836 , -2.0149305 ],\n",
              "       [-2.268386  , -2.5451865 ,  1.7301551 ],\n",
              "       [-2.8887494 , -3.1629183 ,  2.3579617 ],\n",
              "       [-3.1518822 , -2.9258947 ,  2.6870637 ],\n",
              "       [-1.6674118 , -2.9590142 ,  1.6015583 ],\n",
              "       [ 6.061229  , -6.127047  , -6.191832  ],\n",
              "       [ 6.1105466 , -6.154013  , -6.090942  ],\n",
              "       [ 6.0820546 , -6.1113954 , -6.1937675 ],\n",
              "       [ 6.131664  , -6.1619167 , -6.1109886 ],\n",
              "       [ 6.1082478 , -6.2334    , -5.9998198 ],\n",
              "       [ 6.0766163 , -6.118755  , -6.157743  ],\n",
              "       [ 6.056673  , -6.0496483 , -6.1272087 ],\n",
              "       [ 6.0231066 , -6.1051445 , -6.163609  ],\n",
              "       [ 5.7370586 , -5.847511  , -6.2688947 ],\n",
              "       [ 5.664396  , -5.833212  , -6.3228655 ],\n",
              "       [ 6.0223274 , -6.116332  , -6.207076  ],\n",
              "       [ 6.1298575 , -6.2807264 , -5.91848   ],\n",
              "       [ 6.020993  , -6.220461  , -6.0272584 ],\n",
              "       [-2.8841486 ,  2.9320543 , -5.715164  ],\n",
              "       [-2.7317863 ,  2.9122136 , -5.8749094 ],\n",
              "       [-3.1575108 ,  3.1784368 , -5.718729  ],\n",
              "       [-3.2710114 ,  3.4740336 , -5.6666193 ],\n",
              "       [-3.3781962 ,  3.2289288 , -3.6262975 ],\n",
              "       [-2.1952367 , -0.58766973, -0.32891273],\n",
              "       [-2.8571615 , -2.7186115 ,  2.2813716 ],\n",
              "       [ 6.0565066 , -6.1729717 , -6.0907817 ],\n",
              "       [ 6.1071157 , -6.2156644 , -6.026164  ],\n",
              "       [ 6.085128  , -6.101941  , -6.1831264 ],\n",
              "       [ 6.1491065 , -6.1868925 , -6.0102415 ],\n",
              "       [ 6.097316  , -6.133093  , -6.1618776 ],\n",
              "       [ 6.1272874 , -6.20689   , -6.0435266 ],\n",
              "       [ 6.1230826 , -6.190029  , -6.060667  ],\n",
              "       [ 5.9355907 , -5.9790087 , -6.295463  ],\n",
              "       [ 5.7857375 , -5.826623  , -6.4517555 ],\n",
              "       [ 6.131632  , -6.2661843 , -5.955537  ],\n",
              "       [ 5.723593  , -5.928323  , -6.1699944 ],\n",
              "       [-3.1714106 ,  3.1940153 , -5.671113  ],\n",
              "       [-2.7993279 ,  2.77767   , -5.624423  ],\n",
              "       [ 5.4144125 , -5.480867  , -6.4587646 ],\n",
              "       [-3.1892233 ,  3.4332597 , -5.538336  ],\n",
              "       [-2.53306   ,  2.6383753 , -5.93528   ],\n",
              "       [-3.031296  ,  3.0159447 , -5.6719246 ],\n",
              "       [-3.1543622 ,  3.2740543 , -5.7068257 ],\n",
              "       [-3.4897761 ,  3.5807767 , -5.541266  ],\n",
              "       [-2.790522  ,  2.9115007 , -5.235439  ],\n",
              "       [-2.790348  , -2.85648   ,  2.191623  ],\n",
              "       [-2.8013856 , -2.9717598 ,  2.1135118 ],\n",
              "       [-3.31598   ,  3.0609565 , -3.3510408 ],\n",
              "       [-3.3390396 , -3.1961434 ,  2.999938  ],\n",
              "       [ 6.1144395 , -6.2293873 , -6.012876  ],\n",
              "       [ 6.104746  , -6.1789217 , -6.0972643 ],\n",
              "       [ 6.0843925 , -6.258485  , -5.974268  ],\n",
              "       [ 5.9795647 , -6.1310587 , -6.060003  ],\n",
              "       [ 6.056963  , -6.2420244 , -6.0540304 ],\n",
              "       [ 5.976029  , -6.1003847 , -6.1127033 ],\n",
              "       [ 6.0888734 , -6.302227  , -5.952336  ],\n",
              "       [ 5.9886913 , -6.165203  , -6.096199  ],\n",
              "       [ 5.9537    , -6.12413   , -6.109814  ],\n",
              "       [-3.1667616 ,  3.2699869 , -5.575378  ],\n",
              "       [-2.9466722 ,  3.1301868 , -5.50235   ],\n",
              "       [-3.4208224 ,  3.733206  , -5.3688593 ],\n",
              "       [-3.3722332 ,  3.410116  , -5.5551486 ],\n",
              "       [-2.6735544 , -2.5541253 ,  1.9047496 ],\n",
              "       [-3.128271  , -3.3018196 ,  2.7056074 ],\n",
              "       [-2.260579  , -2.9695652 ,  1.8725258 ],\n",
              "       [-2.3904173 , -2.4181905 ,  1.6157137 ],\n",
              "       [-3.2838585 , -3.2683344 ,  2.6841826 ],\n",
              "       [-3.1191316 , -2.8221438 ,  2.4304032 ],\n",
              "       [-2.7188804 , -3.1589148 ,  2.5520763 ],\n",
              "       [ 6.143551  , -6.226533  , -6.00492   ],\n",
              "       [ 6.1332293 , -6.231361  , -5.996934  ],\n",
              "       [ 6.128658  , -6.228045  , -5.981188  ],\n",
              "       [ 5.9852653 , -6.152483  , -6.024577  ],\n",
              "       [ 6.0763044 , -6.228349  , -6.018238  ],\n",
              "       [ 5.918655  , -6.1380463 , -6.0416174 ],\n",
              "       [ 5.852258  , -6.0047913 , -6.1822844 ],\n",
              "       [-2.8725655 , -2.6941006 ,  1.8726723 ],\n",
              "       [-2.876916  ,  3.1128342 , -5.689701  ],\n",
              "       [-2.4233577 ,  2.510048  , -6.110697  ],\n",
              "       [-3.5101588 ,  3.6864533 , -5.229324  ],\n",
              "       [-1.7564725 ,  1.8068213 , -5.768993  ],\n",
              "       [-3.4969568 ,  3.5897913 , -5.4375696 ],\n",
              "       [-2.577209  ,  2.7614233 , -5.787541  ],\n",
              "       [-3.443419  ,  3.152164  , -3.2768888 ],\n",
              "       [-3.097927  ,  2.7564378 , -3.31739   ],\n",
              "       [-2.276084  , -3.1221259 ,  1.9839193 ],\n",
              "       [-3.147148  , -3.2793782 ,  2.7335157 ],\n",
              "       [-3.2962995 , -3.3226602 ,  2.9079347 ],\n",
              "       [-2.5894914 , -3.2745678 ,  2.2852879 ],\n",
              "       [ 6.116066  , -6.23176   , -6.0195446 ],\n",
              "       [ 6.1322813 , -6.222878  , -6.0199337 ],\n",
              "       [ 6.1283026 , -6.1774426 , -6.0553865 ],\n",
              "       [ 6.124507  , -6.227829  , -5.990048  ],\n",
              "       [ 6.1238756 , -6.2130013 , -5.9833155 ],\n",
              "       [ 6.0973105 , -6.1650696 , -6.109834  ],\n",
              "       [ 6.124076  , -6.2278385 , -6.018775  ],\n",
              "       [ 6.043491  , -6.2590003 , -5.986937  ],\n",
              "       [ 6.041629  , -6.2322197 , -5.970807  ],\n",
              "       [ 5.607973  , -5.74145   , -6.3182526 ],\n",
              "       [ 5.120141  , -5.303653  , -6.1232395 ],\n",
              "       [-3.0097513 ,  3.05215   , -5.731743  ],\n",
              "       [-3.3013678 ,  3.0874531 , -5.282896  ],\n",
              "       [-2.4174101 , -3.1953328 ,  2.0724237 ],\n",
              "       [-3.1997008 ,  3.1219716 , -5.337469  ],\n",
              "       [-2.544901  , -1.3060865 ,  0.927103  ],\n",
              "       [-2.5828462 , -0.06605364, -0.11943685],\n",
              "       [-2.9175472 , -3.0586247 ,  2.2240434 ],\n",
              "       [-3.0264294 , -3.468829  ,  2.8007712 ],\n",
              "       [ 6.1280556 , -6.214532  , -6.0057297 ],\n",
              "       [ 6.0716476 , -6.1326704 , -6.175167  ],\n",
              "       [ 6.1347647 , -6.1926413 , -6.0344152 ],\n",
              "       [ 6.031474  , -6.2016573 , -6.0567083 ],\n",
              "       [ 6.10336   , -6.221448  , -6.0446186 ],\n",
              "       [ 5.490224  , -5.508159  , -6.391696  ],\n",
              "       [ 5.8891315 , -6.038912  , -6.1959686 ],\n",
              "       [ 5.9668727 , -6.0324674 , -6.284836  ],\n",
              "       [ 5.919986  , -5.7703295 , -6.356301  ],\n",
              "       [ 5.913806  , -6.0713625 , -6.186407  ],\n",
              "       [ 2.7276194 , -2.9539173 , -5.7107286 ],\n",
              "       [-3.0790675 ,  3.2564692 , -5.569846  ],\n",
              "       [-3.141656  ,  3.079564  , -5.8084416 ],\n",
              "       [-3.2532117 ,  3.3235345 , -5.7203307 ],\n",
              "       [-2.7499123 ,  2.94243   , -5.51254   ],\n",
              "       [-2.8837907 ,  2.8478906 , -5.749897  ],\n",
              "       [-3.0678792 ,  2.383169  , -2.8580003 ],\n",
              "       [-2.820601  , -2.311601  ,  1.6708276 ],\n",
              "       [-3.3759482 , -3.1256166 ,  2.6733856 ],\n",
              "       [-2.9169748 , -2.1675327 ,  1.6187738 ],\n",
              "       [ 6.05213   , -6.0722275 , -6.22448   ],\n",
              "       [ 6.063039  , -6.114073  , -6.1907053 ],\n",
              "       [ 6.0736513 , -6.1123333 , -6.1754436 ],\n",
              "       [ 6.1455297 , -6.2138157 , -5.9885283 ],\n",
              "       [ 6.1380615 , -6.1634035 , -6.049184  ],\n",
              "       [ 6.0907755 , -6.246589  , -6.002096  ],\n",
              "       [ 5.9666324 , -6.0582476 , -6.2704506 ],\n",
              "       [ 5.2698836 , -5.4628134 , -6.575886  ],\n",
              "       [ 6.074193  , -6.2672696 , -5.945986  ],\n",
              "       [ 1.6818078 , -1.5318477 , -7.25994   ],\n",
              "       [ 5.687503  , -5.8653603 , -6.2757654 ],\n",
              "       [ 5.871558  , -5.917034  , -6.1413803 ],\n",
              "       [-2.378252  ,  2.4111464 , -5.7949543 ],\n",
              "       [-2.5039825 ,  2.6663578 , -5.7635126 ],\n",
              "       [-2.8739977 ,  3.1292627 , -5.8016043 ],\n",
              "       [-2.4277484 ,  2.345777  , -6.0390444 ],\n",
              "       [ 5.992707  , -6.0217066 , -6.2232895 ],\n",
              "       [-3.1310682 , -2.9923632 ,  2.6357949 ],\n",
              "       [-3.1086204 ,  3.0995662 , -5.7409515 ],\n",
              "       [-3.442919  ,  3.574929  , -5.402631  ],\n",
              "       [ 3.9068975 , -4.199779  , -5.651512  ],\n",
              "       [-2.397986  , -2.0998049 ,  1.2905881 ],\n",
              "       [-3.0928614 ,  1.7081172 , -2.085916  ],\n",
              "       [-2.8634026 , -2.9943154 ,  2.4053574 ],\n",
              "       [-2.4525528 , -3.3864796 ,  2.3280444 ],\n",
              "       [-3.156641  , -3.4607666 ,  2.9570796 ],\n",
              "       [ 6.06584   , -6.107834  , -6.1598682 ],\n",
              "       [ 6.1337986 , -6.2200494 , -6.0353966 ],\n",
              "       [ 5.9078364 , -6.120434  , -5.957821  ],\n",
              "       [ 6.048081  , -6.2138243 , -6.0991783 ],\n",
              "       [ 5.795553  , -5.8194304 , -6.326371  ],\n",
              "       [ 6.1145725 , -6.2497177 , -5.9881344 ],\n",
              "       [ 5.784994  , -5.950225  , -6.224133  ],\n",
              "       [ 6.0021772 , -6.2180204 , -6.036876  ],\n",
              "       [ 5.449188  , -5.520802  , -6.4358997 ],\n",
              "       [ 6.037939  , -6.199775  , -5.994526  ],\n",
              "       [-3.0495462 ,  3.2634296 , -5.514863  ],\n",
              "       [ 2.8584197 , -2.8545125 , -6.02023   ],\n",
              "       [-2.9442143 ,  3.0218222 , -5.8744335 ],\n",
              "       [-2.9565992 ,  2.8933804 , -5.793929  ],\n",
              "       [-2.8947866 ,  2.8057883 , -5.6432314 ],\n",
              "       [-2.5774841 ,  2.72793   , -5.891228  ],\n",
              "       [-2.745266  ,  0.06962854, -0.17235066],\n",
              "       [-2.939062  , -2.4650638 ,  1.7788249 ],\n",
              "       [-2.4552343 , -1.8618764 ,  1.2751647 ],\n",
              "       [-2.6550386 , -2.417253  ,  1.6880677 ],\n",
              "       [-2.8396053 , -3.5166142 ,  2.755793  ],\n",
              "       [-2.8961606 , -3.4971306 ,  2.727658  ],\n",
              "       [-2.7659314 , -1.9762222 ,  1.2790645 ],\n",
              "       [ 6.10923   , -6.214061  , -6.059656  ],\n",
              "       [-1.0948527 ,  1.0272161 , -3.83535   ],\n",
              "       [ 6.1105237 , -6.1452203 , -6.068344  ],\n",
              "       [ 6.1381    , -6.193855  , -6.029275  ],\n",
              "       [ 6.0851955 , -6.2284107 , -5.9625597 ],\n",
              "       [ 6.098445  , -6.2633314 , -5.990556  ],\n",
              "       [ 6.0505085 , -6.1745005 , -6.104082  ],\n",
              "       [ 5.8715124 , -5.795114  , -6.3932066 ],\n",
              "       [ 6.064459  , -6.130542  , -6.1290894 ],\n",
              "       [ 5.8001647 , -5.7986083 , -6.3228197 ],\n",
              "       [ 6.0891685 , -6.2808557 , -5.9480844 ],\n",
              "       [-2.9600377 ,  3.0130785 , -5.663373  ],\n",
              "       [-2.9193835 ,  2.9982185 , -5.7646627 ],\n",
              "       [-2.5733943 ,  2.773674  , -5.689005  ],\n",
              "       [-3.1700706 ,  3.2281787 , -5.508318  ],\n",
              "       [-2.541778  ,  2.5688288 , -5.0861487 ],\n",
              "       [ 4.9532294 , -5.0182085 , -5.989834  ],\n",
              "       [ 3.282149  , -3.2895663 , -6.608717  ],\n",
              "       [-3.216231  ,  3.2396233 , -5.544262  ],\n",
              "       [-2.7033477 ,  2.8424742 , -5.8509207 ],\n",
              "       [-2.794742  ,  2.6912599 , -3.445285  ],\n",
              "       [-3.2200935 ,  2.8774428 , -3.2232318 ],\n",
              "       [-2.9009948 , -3.3580992 ,  2.538527  ],\n",
              "       [-2.3656802 , -3.2402642 ,  2.1344182 ],\n",
              "       [ 6.118615  , -6.2144337 , -6.0236044 ],\n",
              "       [ 6.1360307 , -6.1994195 , -6.045946  ],\n",
              "       [ 5.9352217 , -5.9863153 , -6.2942667 ],\n",
              "       [ 2.7785354 , -2.8283932 , -5.4376793 ],\n",
              "       [ 6.0310736 , -6.187522  , -6.0731983 ],\n",
              "       [ 5.992885  , -6.13043   , -5.8396177 ],\n",
              "       [ 5.768224  , -5.8574424 , -6.231784  ],\n",
              "       [ 5.396546  , -5.622958  , -6.3437166 ],\n",
              "       [ 6.0417156 , -6.084345  , -6.130582  ],\n",
              "       [-2.9165142 ,  2.9646113 , -5.7379045 ],\n",
              "       [-3.568101  ,  3.7638538 , -5.1746025 ],\n",
              "       [-3.0964575 ,  3.2250655 , -5.640441  ],\n",
              "       [-3.6783037 ,  3.6116016 , -5.156816  ],\n",
              "       [-2.6133108 ,  1.868197  , -2.3864753 ],\n",
              "       [-3.4401069 ,  3.218814  , -3.3214023 ],\n",
              "       [-2.6817155 , -2.7323067 ,  2.0902052 ],\n",
              "       [-2.8349981 , -3.3035667 ,  2.583701  ],\n",
              "       [-3.2888143 ,  2.9481041 , -3.2264943 ],\n",
              "       [-2.9972959 , -3.0362604 ,  2.146927  ],\n",
              "       [-3.0213919 ,  2.2571547 , -2.4471264 ],\n",
              "       [ 6.075795  , -6.158824  , -6.052401  ],\n",
              "       [ 6.103323  , -6.2195234 , -6.033966  ],\n",
              "       [ 6.1162915 , -6.198345  , -6.045615  ],\n",
              "       [ 6.131712  , -6.1854    , -6.022438  ],\n",
              "       [ 6.1176395 , -6.1885433 , -6.0744762 ],\n",
              "       [ 6.0880795 , -6.2693543 , -5.8728743 ],\n",
              "       [ 5.9523206 , -6.116004  , -6.051812  ],\n",
              "       [ 6.013651  , -6.207122  , -6.0282497 ],\n",
              "       [ 6.085863  , -6.157989  , -6.140142  ],\n",
              "       [ 5.798258  , -6.066476  , -6.037569  ],\n",
              "       [ 5.1351013 , -5.249914  , -6.2792783 ],\n",
              "       [-2.9129968 ,  2.9492679 , -5.8019476 ],\n",
              "       [-3.0460787 ,  3.1834333 , -5.640663  ],\n",
              "       [-3.0705152 ,  3.1737175 , -5.5573497 ],\n",
              "       [-3.109171  ,  3.0749428 , -5.774252  ],\n",
              "       [-2.9753785 ,  3.062305  , -5.9279118 ],\n",
              "       [-2.8572206 ,  3.0881267 , -5.573328  ],\n",
              "       [-3.173397  ,  2.7968323 , -3.0922399 ],\n",
              "       [-2.0821626 , -1.2795951 ,  0.6792547 ],\n",
              "       [-2.5208054 , -3.0387895 ,  2.0413542 ],\n",
              "       [-2.9537313 , -3.3500497 ,  2.6093879 ],\n",
              "       [ 6.132727  , -6.2126517 , -6.020033  ],\n",
              "       [ 6.0253277 , -6.0951805 , -6.1562314 ],\n",
              "       [ 6.10733   , -6.2009563 , -6.063502  ],\n",
              "       [ 5.9615574 , -6.102277  , -6.1235094 ],\n",
              "       [ 6.077327  , -6.0678077 , -6.189868  ],\n",
              "       [ 5.80623   , -6.0084076 , -6.048343  ],\n",
              "       [ 5.9002504 , -6.023033  , -6.23018   ],\n",
              "       [ 5.9840755 , -6.110731  , -5.8320255 ],\n",
              "       [ 6.0232863 , -6.101363  , -6.1518803 ],\n",
              "       [-3.1765769 ,  3.2397149 , -5.728717  ],\n",
              "       [-3.0332565 ,  3.0667112 , -5.8028784 ],\n",
              "       [-3.4889781 ,  3.5606344 , -5.3843126 ],\n",
              "       [-2.4687972 ,  2.4469213 , -5.605114  ],\n",
              "       [-2.8749633 ,  2.9562662 , -5.5251236 ],\n",
              "       [-3.2885742 ,  3.3834949 , -5.5206575 ],\n",
              "       [-2.4353428 ,  0.79309726, -1.7138048 ],\n",
              "       [-2.5402296 , -3.108151  ,  2.156446  ],\n",
              "       [-2.5670667 , -2.682173  ,  1.7708801 ],\n",
              "       [-2.6439013 , -2.895758  ,  2.0458767 ],\n",
              "       [ 6.109286  , -6.218073  , -6.0382376 ],\n",
              "       [ 6.120046  , -6.1529536 , -6.0508246 ],\n",
              "       [ 6.0494366 , -6.1406918 , -6.129622  ],\n",
              "       [ 6.049193  , -6.1548023 , -6.1209574 ],\n",
              "       [ 6.168402  , -6.2008724 , -5.992203  ],\n",
              "       [ 6.1315317 , -6.2037554 , -6.0233073 ],\n",
              "       [ 6.095302  , -6.237471  , -5.92419   ],\n",
              "       [ 5.3486767 , -5.616437  , -6.1203156 ],\n",
              "       [ 6.0442567 , -6.0312004 , -6.2007394 ],\n",
              "       [ 6.082342  , -6.221406  , -6.021036  ],\n",
              "       [-3.0091863 ,  3.0850298 , -5.6522045 ],\n",
              "       [-3.010173  ,  2.952776  , -5.654472  ],\n",
              "       [-2.2717927 , -1.3361051 ,  0.88744557],\n",
              "       [-2.4757414 , -3.4172566 ,  2.3075616 ],\n",
              "       [-2.4390702 , -1.5388227 ,  0.98221487],\n",
              "       [-2.786795  , -3.4522448 ,  2.6704426 ],\n",
              "       [-1.6941941 , -2.6882224 ,  1.4394226 ],\n",
              "       [ 6.135641  , -6.214588  , -5.973238  ],\n",
              "       [ 6.132779  , -6.168477  , -6.080058  ],\n",
              "       [ 6.110459  , -6.2003064 , -6.0586233 ],\n",
              "       [ 6.072196  , -6.136831  , -6.055251  ],\n",
              "       [ 5.8949013 , -6.1080885 , -6.009693  ],\n",
              "       [ 5.953783  , -6.052828  , -6.2166634 ],\n",
              "       [ 3.7302341 , -3.8055406 , -5.905054  ],\n",
              "       [ 2.1316714 , -2.4818876 , -4.3897085 ],\n",
              "       [-2.9230654 ,  3.029662  , -5.6770945 ],\n",
              "       [-3.2432652 ,  3.365294  , -5.488818  ],\n",
              "       [-2.0546331 ,  2.0568604 , -5.568038  ],\n",
              "       [-3.2686007 ,  2.2002118 , -2.286798  ],\n",
              "       [-2.2996736 , -2.1604674 ,  1.2616354 ],\n",
              "       [-2.5725193 , -2.5724633 ,  1.7085062 ],\n",
              "       [-2.7197824 , -3.274625  ,  2.353066  ],\n",
              "       [ 6.052067  , -6.146511  , -6.0812035 ],\n",
              "       [ 6.1272125 , -6.207449  , -6.017478  ],\n",
              "       [ 6.064211  , -6.185043  , -6.1438546 ],\n",
              "       [ 6.048625  , -6.1222324 , -6.076507  ],\n",
              "       [ 5.212758  , -5.3402405 , -6.258426  ],\n",
              "       [ 5.617366  , -5.67353   , -6.3205395 ],\n",
              "       [ 6.002816  , -6.209072  , -5.993946  ],\n",
              "       [ 2.1301932 , -2.3958147 , -5.2100754 ],\n",
              "       [ 5.1379776 , -5.3062267 , -6.241375  ],\n",
              "       [ 5.643879  , -5.683288  , -6.429374  ],\n",
              "       [-1.94774   ,  2.0230377 , -5.907839  ],\n",
              "       [-2.9973845 ,  3.1288502 , -5.652166  ],\n",
              "       [ 1.2009964 , -0.98995984, -5.493996  ],\n",
              "       [-2.7431862 ,  2.913286  , -4.561969  ],\n",
              "       [-2.98955   ,  1.3192528 , -2.9866085 ],\n",
              "       [-3.0386806 , -3.4057846 ,  2.7787874 ],\n",
              "       [ 6.063134  , -6.170433  , -6.0747685 ],\n",
              "       [ 6.095219  , -6.2270756 , -5.9822445 ],\n",
              "       [ 6.0639505 , -6.119142  , -6.069441  ],\n",
              "       [ 6.1081095 , -6.099555  , -6.120903  ],\n",
              "       [ 5.531839  , -5.6771297 , -6.202815  ],\n",
              "       [ 6.0576906 , -6.231574  , -5.970318  ],\n",
              "       [ 5.9206905 , -6.051443  , -6.101484  ],\n",
              "       [ 6.0225945 , -6.154832  , -6.0681963 ],\n",
              "       [ 5.9034214 , -5.9527245 , -6.322071  ],\n",
              "       [ 1.0990198 , -0.7418507 , -6.4267306 ],\n",
              "       [ 2.364984  , -2.4461348 , -4.6802325 ],\n",
              "       [-1.6425297 ,  1.5590277 , -5.4215775 ],\n",
              "       [-2.8734045 ,  2.6292167 , -3.9792967 ],\n",
              "       [-2.9400618 , -2.7412212 ,  2.277947  ],\n",
              "       [-1.9782748 , -1.115505  ,  0.25869477],\n",
              "       [ 6.1197643 , -6.2252216 , -6.013441  ],\n",
              "       [ 5.959284  , -6.1725016 , -6.0200787 ],\n",
              "       [ 6.0548687 , -6.217211  , -5.9706283 ],\n",
              "       [ 5.307949  , -5.354895  , -6.381874  ],\n",
              "       [ 3.035429  , -2.6529229 , -5.975232  ],\n",
              "       [ 5.828416  , -6.084332  , -6.0726852 ],\n",
              "       [ 6.0495377 , -6.2023935 , -6.041413  ],\n",
              "       [ 5.8428164 , -6.168445  , -6.029094  ],\n",
              "       [ 5.5674787 , -5.8594284 , -6.2480426 ],\n",
              "       [-2.9551897 ,  3.110902  , -5.6138325 ],\n",
              "       [-3.066667  ,  3.1407983 , -5.530052  ],\n",
              "       [-1.657459  ,  2.1207616 , -3.5644991 ],\n",
              "       [-2.7207696 , -1.5823231 ,  1.0844477 ],\n",
              "       [-2.0474558 ,  0.88072133, -2.059725  ],\n",
              "       [-2.9728298 ,  2.914481  , -3.2849507 ],\n",
              "       [-2.7425723 , -2.429897  ,  1.7690825 ],\n",
              "       [-2.6355119 , -1.9936966 ,  1.6330074 ],\n",
              "       [ 6.1227646 , -6.195865  , -6.0691566 ],\n",
              "       [ 5.931514  , -6.1395087 , -6.096469  ],\n",
              "       [ 5.7344236 , -5.8462687 , -6.337921  ],\n",
              "       [ 5.936693  , -6.0437474 , -6.1935377 ],\n",
              "       [ 0.8117728 , -0.9940806 , -5.195594  ],\n",
              "       [ 1.2416303 , -0.95079714, -5.7540865 ],\n",
              "       [ 5.2686844 , -5.4257975 , -6.1329827 ],\n",
              "       [-2.9061348 ,  3.100166  , -5.631048  ],\n",
              "       [-2.0373173 ,  2.156854  , -5.6882744 ],\n",
              "       [-3.1482782 ,  2.7391708 , -2.7953453 ],\n",
              "       [-2.6340985 , -3.0829208 ,  2.1115403 ],\n",
              "       [-2.6207068 , -3.0435522 ,  2.0954432 ],\n",
              "       [-3.0986707 , -2.5901108 ,  2.0566337 ],\n",
              "       [ 6.0429726 , -6.085988  , -6.164962  ],\n",
              "       [ 6.1124153 , -6.2121906 , -6.0526323 ],\n",
              "       [ 6.096409  , -6.161626  , -6.0992336 ],\n",
              "       [ 5.98629   , -6.152125  , -6.024557  ],\n",
              "       [ 5.422846  , -5.599138  , -6.340762  ],\n",
              "       [ 5.9325094 , -6.0971394 , -6.0317974 ],\n",
              "       [ 5.982814  , -6.08644   , -6.1355324 ],\n",
              "       [ 4.70074   , -4.9285116 , -5.9565153 ],\n",
              "       [-3.1198566 ,  3.1141324 , -5.875819  ],\n",
              "       [-3.2277358 ,  3.33124   , -5.6333656 ],\n",
              "       [-3.245499  ,  3.164117  , -5.5356727 ],\n",
              "       [-2.852153  ,  2.9847267 , -5.777953  ],\n",
              "       [-2.8979516 ,  2.8560603 , -5.468156  ],\n",
              "       [-3.5951934 ,  3.7080038 , -5.281181  ],\n",
              "       [ 5.4804688 , -5.7106876 , -6.14935   ],\n",
              "       [-3.30646   ,  3.0698633 , -3.3371577 ],\n",
              "       [-2.0469675 , -0.75046533,  0.24047917],\n",
              "       [-2.407771  , -2.9218247 ,  2.1729317 ],\n",
              "       [-2.1785653 , -3.280175  ,  1.9632138 ],\n",
              "       [-2.7799625 , -3.262448  ,  2.333544  ],\n",
              "       [-2.6747942 , -3.4397442 ,  2.774962  ],\n",
              "       [-3.2823453 , -2.66987   ,  2.1699662 ],\n",
              "       [ 6.1509953 , -6.231094  , -5.9757624 ],\n",
              "       [ 6.1291504 , -6.252157  , -5.980215  ],\n",
              "       [ 6.063453  , -6.2463245 , -5.9340224 ],\n",
              "       [ 6.0629563 , -6.232365  , -5.9821787 ],\n",
              "       [ 5.9189262 , -6.0481577 , -6.1511855 ],\n",
              "       [ 1.4697576 , -1.5424112 , -5.0076385 ],\n",
              "       [ 5.541818  , -5.549556  , -6.4787207 ],\n",
              "       [ 2.1935713 , -2.083698  , -6.9075785 ],\n",
              "       [ 4.5852723 , -4.803853  , -6.0763326 ],\n",
              "       [-3.1944323 ,  3.3044517 , -5.714137  ],\n",
              "       [ 4.6897116 , -4.835351  , -6.535287  ],\n",
              "       [-2.8493745 ,  3.0476298 , -5.774812  ],\n",
              "       [-3.413629  ,  3.5659728 , -5.5685654 ],\n",
              "       [ 4.9206896 , -5.204229  , -6.008314  ],\n",
              "       [-2.2388937 ,  0.8659388 , -2.200419  ],\n",
              "       [-2.8595686 , -3.557439  ,  2.6667995 ],\n",
              "       [-3.0152123 ,  2.409828  , -2.7668014 ],\n",
              "       [-2.9249465 , -3.2243338 ,  2.5702653 ],\n",
              "       [ 1.6407582 , -1.8501483 , -4.7265997 ],\n",
              "       [ 6.1253138 , -6.25186   , -6.0026875 ],\n",
              "       [ 6.1088157 , -6.230848  , -6.0169387 ],\n",
              "       [ 6.098975  , -6.142969  , -6.1408606 ],\n",
              "       [ 6.0977263 , -6.254122  , -5.9793878 ],\n",
              "       [ 5.7516513 , -5.904404  , -6.09704   ],\n",
              "       [ 6.1032124 , -6.2873325 , -5.918562  ],\n",
              "       [ 6.0038195 , -6.187253  , -6.0371704 ],\n",
              "       [ 5.9109917 , -5.9878964 , -6.2409925 ],\n",
              "       [ 6.036174  , -6.1117735 , -6.089979  ],\n",
              "       [ 4.584118  , -4.8396044 , -6.0209184 ],\n",
              "       [-3.1108546 ,  3.2788453 , -5.7895913 ],\n",
              "       [ 5.6312027 , -5.7575684 , -6.373641  ],\n",
              "       [-3.2112207 ,  3.1587312 , -5.6894894 ],\n",
              "       [-3.324431  ,  3.2823052 , -5.560805  ],\n",
              "       [-3.2924495 ,  3.4121609 , -5.5758657 ],\n",
              "       [-2.4147658 ,  2.523083  , -5.996399  ],\n",
              "       [-2.675576  ,  1.7569684 , -2.3684943 ],\n",
              "       [-3.096182  , -3.1248567 ,  2.5255842 ],\n",
              "       [-2.1692848 , -1.3718156 ,  0.61303765],\n",
              "       [ 1.795152  , -1.9410975 , -5.0258093 ],\n",
              "       [ 6.123373  , -6.2070026 , -6.0333943 ],\n",
              "       [ 6.12626   , -6.2152762 , -6.028457  ],\n",
              "       [ 6.1265616 , -6.188938  , -6.059406  ],\n",
              "       [ 6.106581  , -6.2223563 , -6.025873  ],\n",
              "       [ 5.9622016 , -6.120317  , -6.088867  ],\n",
              "       [ 5.9375644 , -5.9840126 , -6.1477365 ],\n",
              "       [ 1.8645731 , -2.0538745 , -6.063083  ],\n",
              "       [ 6.0872684 , -6.2295227 , -5.9439464 ],\n",
              "       [-3.2587414 ,  3.2991288 , -5.70947   ],\n",
              "       [-3.1938195 ,  3.2747421 , -5.7543364 ],\n",
              "       [-3.226966  ,  3.2776902 , -5.7216644 ],\n",
              "       [-3.2584052 ,  3.3523839 , -5.5301857 ],\n",
              "       [ 5.6732464 , -5.8455133 , -6.20317   ],\n",
              "       [ 2.8101795 , -2.777919  , -5.430377  ],\n",
              "       [-2.4005637 ,  0.42819285, -1.3692465 ],\n",
              "       [-3.4099333 ,  2.9773815 , -3.285781  ],\n",
              "       [-2.4537654 , -3.2029707 ,  2.253266  ],\n",
              "       [-2.6003025 , -3.2513754 ,  2.3259983 ],\n",
              "       [ 6.124318  , -6.2267046 , -6.0265446 ],\n",
              "       [ 6.093075  , -6.2064753 , -6.043643  ],\n",
              "       [ 6.1139174 , -6.2077928 , -6.037841  ],\n",
              "       [ 6.1164613 , -6.1876397 , -6.0561476 ],\n",
              "       [ 6.115038  , -6.202057  , -6.037818  ],\n",
              "       [ 5.9488153 , -6.112894  , -6.11732   ],\n",
              "       [ 5.1496425 , -5.134454  , -6.345654  ],\n",
              "       [ 5.8136244 , -6.015493  , -6.1142416 ],\n",
              "       [ 6.0186553 , -6.096282  , -6.162378  ],\n",
              "       [ 5.6709366 , -5.72663   , -6.299601  ],\n",
              "       [ 5.7746396 , -5.650875  , -6.3346996 ],\n",
              "       [-2.7118368 ,  2.9060247 , -5.8702297 ],\n",
              "       [-3.130281  ,  3.2672539 , -5.706675  ],\n",
              "       [-3.4363828 ,  3.579683  , -5.4702063 ],\n",
              "       [-3.5836506 ,  3.5781114 , -5.266009  ],\n",
              "       [-3.1761456 ,  2.9626443 , -3.2511222 ],\n",
              "       [-2.4565454 , -1.3920051 ,  1.2239803 ],\n",
              "       [-2.9209156 , -3.2124846 ,  2.5330591 ],\n",
              "       [-2.6600838 , -3.2427957 ,  2.2805545 ],\n",
              "       [-3.1754234 , -3.236042  ,  2.8471646 ],\n",
              "       [-2.7698326 , -3.6218102 ,  2.7185998 ],\n",
              "       [ 6.1197553 , -6.208252  , -5.9936867 ],\n",
              "       [ 5.9903164 , -6.0138335 , -6.194899  ],\n",
              "       [ 6.120077  , -6.1972885 , -6.04294   ],\n",
              "       [ 6.102428  , -6.2095747 , -6.042896  ],\n",
              "       [ 6.1082983 , -6.277871  , -5.9509277 ],\n",
              "       [ 5.9120045 , -6.071733  , -6.214032  ],\n",
              "       [ 5.9529138 , -6.1805186 , -6.0445876 ],\n",
              "       [ 0.35865852, -0.24413292, -4.297453  ],\n",
              "       [-2.5913846 ,  2.8438733 , -5.7062163 ],\n",
              "       [-3.2414165 ,  3.1756341 , -5.5730586 ],\n",
              "       [-3.428566  ,  3.4205635 , -5.4680834 ],\n",
              "       [-3.3386807 ,  3.4949234 , -5.571959  ],\n",
              "       [-3.233006  ,  3.1198986 , -3.6281672 ],\n",
              "       [-2.3037987 ,  0.57957435, -1.3386787 ],\n",
              "       [-2.294676  ,  1.0764301 , -1.6127685 ],\n",
              "       [-3.180891  , -3.1328955 ,  2.5461226 ],\n",
              "       [-2.3212204 , -3.4966547 ,  2.2844572 ],\n",
              "       [ 6.128695  , -6.2075653 , -6.0261045 ],\n",
              "       [ 6.1037083 , -6.1678185 , -6.088188  ],\n",
              "       [ 6.091506  , -6.2054706 , -6.058617  ],\n",
              "       [ 5.5249977 , -5.728881  , -6.1489916 ],\n",
              "       [ 6.0705633 , -6.149415  , -6.0601735 ],\n",
              "       [-2.324521  , -1.8695729 ,  1.1034359 ],\n",
              "       [ 5.749342  , -5.888275  , -6.251157  ],\n",
              "       [ 5.84651   , -5.8764305 , -6.3986497 ],\n",
              "       [ 6.0927167 , -6.201534  , -6.064581  ],\n",
              "       [ 6.0849295 , -6.185165  , -6.110832  ],\n",
              "       [ 6.0437155 , -6.1840706 , -6.0506797 ],\n",
              "       [ 6.140809  , -6.174601  , -6.009586  ],\n",
              "       [ 6.0405617 , -6.0572157 , -6.1112123 ],\n",
              "       [ 5.544214  , -5.5626926 , -6.4254627 ],\n",
              "       [ 5.9580994 , -6.040006  , -6.191311  ],\n",
              "       [ 4.9318867 , -5.035272  , -6.6293573 ],\n",
              "       [ 3.1615195 , -3.3926904 , -4.9158554 ],\n",
              "       [-2.9442139 ,  2.9487293 , -6.0095196 ],\n",
              "       [-2.9256263 ,  3.027803  , -5.5745726 ],\n",
              "       [-2.6991882 ,  2.606621  , -5.506034  ],\n",
              "       [-2.0583491 ,  2.1198874 , -6.104455  ],\n",
              "       [-2.9827263 ,  2.1244144 , -2.7648175 ],\n",
              "       [-2.3491006 ,  0.4275388 , -0.52131927],\n",
              "       [-2.8791037 , -3.4706075 ,  2.583898  ],\n",
              "       [-3.0798388 ,  1.4649427 , -1.9160697 ],\n",
              "       [-3.3648744 , -2.6012104 ,  2.4475164 ],\n",
              "       [-2.7603238 , -2.4976292 ,  1.7058824 ],\n",
              "       [-2.3482985 , -0.5567978 , -0.46819493],\n",
              "       [ 5.9919147 , -6.1615906 , -6.0307403 ],\n",
              "       [ 6.1343517 , -6.160799  , -6.03668   ],\n",
              "       [ 6.11633   , -6.2211623 , -5.9930844 ],\n",
              "       [ 6.1330547 , -6.2512236 , -5.968843  ],\n",
              "       [ 5.8806305 , -5.940629  , -6.312148  ],\n",
              "       [ 5.9544115 , -6.003286  , -6.1596813 ],\n",
              "       [ 5.8218603 , -5.85244   , -6.3699436 ],\n",
              "       [ 5.856478  , -5.9817743 , -6.226512  ],\n",
              "       [ 6.0900836 , -6.2650714 , -5.919383  ],\n",
              "       [ 6.052305  , -6.168516  , -6.0780544 ],\n",
              "       [ 4.2548532 , -4.3474116 , -5.7276278 ],\n",
              "       [-2.9618907 ,  3.034921  , -5.855297  ],\n",
              "       [-3.1752532 ,  3.2315667 , -5.7732253 ],\n",
              "       [-2.7402477 ,  2.5904703 , -5.189631  ],\n",
              "       [-3.1389732 ,  3.2221582 , -5.81193   ],\n",
              "       [-2.5222054 ,  2.6528494 , -5.8986845 ],\n",
              "       [ 3.9373474 , -4.1439824 , -6.095049  ],\n",
              "       [-2.6039886 , -3.0456536 ,  2.063828  ],\n",
              "       [-3.1673534 ,  3.0966942 , -2.900635  ],\n",
              "       [-2.790236  , -2.3103735 ,  1.6240319 ],\n",
              "       [-3.024352  , -3.1102464 ,  2.628129  ],\n",
              "       [-2.9905386 , -3.1330173 ,  2.4256048 ],\n",
              "       [ 6.0921783 , -6.1875954 , -6.0795984 ],\n",
              "       [ 6.081851  , -6.1677    , -6.0644846 ],\n",
              "       [ 6.119978  , -6.174206  , -6.067459  ],\n",
              "       [ 6.106879  , -6.1992927 , -6.065704  ],\n",
              "       [ 6.0161967 , -6.1411395 , -6.163336  ],\n",
              "       [ 6.1226296 , -6.269466  , -5.968458  ],\n",
              "       [ 5.875159  , -5.9007597 , -6.3198104 ],\n",
              "       [ 6.1186247 , -6.103067  , -6.1657667 ],\n",
              "       [ 1.6174176 , -1.5453792 , -5.991869  ],\n",
              "       [-2.7773647 ,  2.9135058 , -5.891809  ],\n",
              "       [-3.029951  ,  3.1258028 , -5.6778307 ],\n",
              "       [-2.6936102 ,  2.5657537 , -5.6987762 ],\n",
              "       [-2.5354168 ,  2.6498456 , -5.9611254 ],\n",
              "       [-1.1591455 , -2.5342646 ,  0.9242093 ],\n",
              "       [-2.4261465 , -2.7815483 ,  1.8458015 ],\n",
              "       [-2.1976128 , -3.3135567 ,  1.9715179 ],\n",
              "       [-2.6961665 , -3.4960115 ,  2.756147  ],\n",
              "       [-3.317746  , -2.8630555 ,  2.3910882 ],\n",
              "       [ 6.0990167 , -6.1635785 , -6.132276  ],\n",
              "       [ 6.1316724 , -6.202178  , -6.0248127 ],\n",
              "       [ 6.1180754 , -6.1695776 , -6.0987897 ],\n",
              "       [ 6.1163435 , -6.1895213 , -6.0674124 ],\n",
              "       [ 6.1273656 , -6.2109346 , -6.000948  ],\n",
              "       [ 6.1197023 , -6.194723  , -6.048846  ],\n",
              "       [ 6.11356   , -6.2156806 , -6.0386066 ],\n",
              "       [ 6.110469  , -6.250556  , -6.0086555 ],\n",
              "       [ 6.079773  , -6.179203  , -6.0353603 ],\n",
              "       [ 6.1219854 , -6.220354  , -6.038595  ],\n",
              "       [ 6.117816  , -6.2829113 , -5.9564276 ],\n",
              "       [-3.1878705 ,  3.2055337 , -5.7545724 ],\n",
              "       [-2.2562995 ,  2.3487794 , -6.189503  ],\n",
              "       [-2.7496028 ,  2.1602576 , -2.4032474 ],\n",
              "       [ 6.1171246 , -6.2158027 , -6.022382  ],\n",
              "       [ 6.090114  , -6.1613264 , -6.070258  ],\n",
              "       [ 6.108718  , -6.2243733 , -6.0470214 ],\n",
              "       [ 6.117793  , -6.191523  , -5.9936094 ],\n",
              "       [ 6.0702915 , -6.1724253 , -6.102895  ],\n",
              "       [ 6.1220407 , -6.2117953 , -6.0452895 ],\n",
              "       [ 6.0488844 , -6.115875  , -6.144026  ],\n",
              "       [ 6.10337   , -6.241458  , -6.0373907 ],\n",
              "       [ 6.116375  , -6.1189137 , -6.140979  ],\n",
              "       [ 6.070864  , -6.1198235 , -6.1180887 ],\n",
              "       [ 6.1410637 , -6.178595  , -6.0466194 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqziKHN0ynMO"
      },
      "source": [
        "**ROC AUC**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2UFegBhy5Ia"
      },
      "source": [
        "The accuracy metric chosen by the authors for this dataset is the \"ROC AUC\" (Receiver Operating Characteristic, Area Under the Curve) rather than straight accuracy (number right / total examples).\n",
        "\n",
        "The ROC AUC takes into account the fact that you can adjust the threshold to trade off false positives and false negatives, and yields a score which tries to capture overall accuracy independent of where you choose to put that threshold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzdDHGZU6KYV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46e3138e-2571-4a4c-a2b9-9596717dd841"
      },
      "source": [
        "# Calcualte the ROC AUC score for our model's predictions.\n",
        "score = roc_auc_score(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('ROC AUC: {:.4f}'.format(score))"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC: 0.5153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pbIUpHZC-4O"
      },
      "source": [
        "## Appendix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUmsUOIv8EUO"
      },
      "source": [
        "### A.1. Saving Our Trained Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P27hPsmepmLJ"
      },
      "source": [
        "To back up our model, we need to:\n",
        "1. Save the model to disk.\n",
        "2. Copy the model to our Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulTWaOr8QNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffbb517a-e599-428d-dfc2-5f3842f5d92b"
      },
      "source": [
        "\n",
        "import os\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model.save_pretrained(output_dir)\n"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to ./model_save/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzGKvOFAll_e"
      },
      "source": [
        "To save your model across Colab Notebook sessions, download it to your local machine, or ideally copy it to your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trr-A-POC18_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "4fec7592-1fa4-49ed-fa9b-c9e2c6cc6dc5"
      },
      "source": [
        "'''\n",
        "# Mount Google Drive to this Notebook instance.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#root_path = 'gdrive/My Drive/your_project_folder/'  #change dir to your project folder\n",
        "#https://drive.google.com/drive/u/0/folders/1t1HENNSMrTNYSV7CpUXqD4uY55Xvt61H\n",
        "root_path = 'drive/u/0/folders/1t1HENNSMrTNYSV7CpUXqD4uY55Xvt61H'\n",
        "'''"
      ],
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# Mount Google Drive to this Notebook instance.\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\\n#root_path = 'gdrive/My Drive/your_project_folder/'  #change dir to your project folder\\n#https://drive.google.com/drive/u/0/folders/1t1HENNSMrTNYSV7CpUXqD4uY55Xvt61H\\nroot_path = 'drive/u/0/folders/1t1HENNSMrTNYSV7CpUXqD4uY55Xvt61H'\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 311
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCePYYzAV73K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "00855ef6-81f1-4e64-e69d-7657032495aa"
      },
      "source": [
        "'''\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "'''"
      ],
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\\n!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\\n!apt-get update -qq 2>&1 > /dev/null\\n!apt-get -y install -qq google-drive-ocamlfuse fuse\\nfrom google.colab import auth\\nauth.authenticate_user()\\nfrom oauth2client.client import GoogleCredentials\\ncreds = GoogleCredentials.get_application_default()\\nimport getpass\\n!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\\nvcode = getpass.getpass()\\n!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohyZ_4kQV4LC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "35b5659b-0020-4486-c477-ff9b20f16d5f"
      },
      "source": [
        "'''\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "'''"
      ],
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n!mkdir -p drive\\n!google-drive-ocamlfuse drive\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ICGoQaToRPN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "888e4024-0f2f-4a26-ea53-4d371b5cb1c9"
      },
      "source": [
        "'''\n",
        "#!ls \"./drive/Shared drives/ChrisMcCormick.AI/Content/2020-08-25 - Multilabel Toxic Comments Challenge/release/\"\n",
        "#!ls \"./drive/u/0/folders/1t1HENNSMrTNYSV7CpUXqD4uY55Xvt61H\"\n",
        "!ls \"/content/drive\"\n",
        "\n",
        "\n",
        "#https://drive.google.com/drive/folders/1t1HENNSMrTNYSV7CpUXqD4uY55Xvt61H?usp=sharing\n",
        "'''"
      ],
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#!ls \"./drive/Shared drives/ChrisMcCormick.AI/Content/2020-08-25 - Multilabel Toxic Comments Challenge/release/\"\\n#!ls \"./drive/u/0/folders/1t1HENNSMrTNYSV7CpUXqD4uY55Xvt61H\"\\n!ls \"/content/drive\"\\n\\n\\n#https://drive.google.com/drive/folders/1t1HENNSMrTNYSV7CpUXqD4uY55Xvt61H?usp=sharing\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 314
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c2Fjyv8IEv3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "05f825e6-72d8-4364-a677-10a2d763cf86"
      },
      "source": [
        "'''\n",
        "gdrive_path = \"/content/drive\"\n",
        "'''"
      ],
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ngdrive_path = \"/content/drive\"\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 315
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTx3g5NPIKCM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8d7a27f9-ffc6-4c67-d705-e0f2f494be55"
      },
      "source": [
        "'''\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(gdrive_path):\n",
        "    os.makedirs(gdrive_path)\n",
        "'''"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Create output directory if needed\\nif not os.path.exists(gdrive_path):\\n    os.makedirs(gdrive_path)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 316
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUTOljfPIQCM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3b88570b-277c-4c2d-fa67-bf688ec23c74"
      },
      "source": [
        "'''\n",
        "# Copy the model files to a directory in your Google Drive.\n",
        "#!cp -r \"./model_save/\" \"./drive/Shared drives/ChrisMcCormick.AI/Content/2020-08-25 - Multilabel Toxic Comments Challenge/release/\"\n",
        "!cp -r \"./model_save/\" #\"/content/drive\"\n",
        "'''"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Copy the model files to a directory in your Google Drive.\\n#!cp -r \"./model_save/\" \"./drive/Shared drives/ChrisMcCormick.AI/Content/2020-08-25 - Multilabel Toxic Comments Challenge/release/\"\\n!cp -r \"./model_save/\" #\"/content/drive\"\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 317
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxlZsafTC-V5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "c7f05f57-e586-43a4-f736-2f524df3f298"
      },
      "source": [
        "'''\n",
        "#gdrive_path = \"./drive/Shared drives/ChrisMcCormick.AI/Content/2020-08-25 - Multilabel Toxic Comments Challenge/release/\"\n",
        "gdrive_path = \"/content/drive\"\n",
        "#https://drive.google.com/drive/folders/1VR-FAnxhc3M_oCr0b1ufWwHC43FLpMMr\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(gdrive_path):\n",
        "    os.makedirs(gdrive_path)\n",
        "\n",
        "# Copy the model files to a directory in your Google Drive.\n",
        "#!cp -r \"./model_save/\" \"./drive/Shared drives/ChrisMcCormick.AI/Content/2020-08-25 - Multilabel Toxic Comments Challenge/release/\"\n",
        "!cp -r \"./model_save/\" \"./content/drive\"\n",
        "'''"
      ],
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#gdrive_path = \"./drive/Shared drives/ChrisMcCormick.AI/Content/2020-08-25 - Multilabel Toxic Comments Challenge/release/\"\\ngdrive_path = \"/content/drive\"\\n#https://drive.google.com/drive/folders/1VR-FAnxhc3M_oCr0b1ufWwHC43FLpMMr\\n\\n# Create output directory if needed\\nif not os.path.exists(gdrive_path):\\n    os.makedirs(gdrive_path)\\n\\n# Copy the model files to a directory in your Google Drive.\\n#!cp -r \"./model_save/\" \"./drive/Shared drives/ChrisMcCormick.AI/Content/2020-08-25 - Multilabel Toxic Comments Challenge/release/\"\\n!cp -r \"./model_save/\" \"./content/drive\"\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 318
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuIDqhbOo4nq"
      },
      "source": [
        "### A.2. Baseline ROC AUC Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJep-nMizOph"
      },
      "source": [
        "A good way to sanity check a performance score is to see how well you would do using just random guessing. \n",
        "\n",
        "In this case, we know that the classes are very imbalanced, and that ~90% of the comments don't contain anything toxic. \n",
        "\n",
        "If we just predicted zero for every test sample...\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H6YWY9z0MYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74bbf4d5-f431-47ce-d986-b2f2fff06591"
      },
      "source": [
        "zero_preds = np.zeros(flat_predictions.shape)\n",
        "\n",
        "# Calcualte the ROC AUC score for predicting all 0s.\n",
        "score = roc_auc_score(flat_true_labels, zero_preds)\n",
        "\n",
        "print('Predict all zeros --> ROC AUC: {:.3f}'.format(score))"
      ],
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict all zeros --> ROC AUC: 0.500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44zqHWvA0dbH"
      },
      "source": [
        "We can do a little better by predicting labels with the same frequency that they occur in the dataset. The `random.choices` function will help us with this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WGImVpq0lOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6646eddf-65fe-447a-e860-3f2290347bd7"
      },
      "source": [
        "from random import choices\n",
        "\n",
        "# The numbers for 'choices' to pick from.\n",
        "population = [0, 1]\n",
        "\n",
        "# How many test samples are there?\n",
        "num_test = flat_true_labels.shape[0]\n",
        "\n",
        "# Store predictions based on proportions.\n",
        "prop_preds = []\n",
        "\n",
        "# For each of the 6 labels...\n",
        "for count in label_counts[0:3]:\n",
        "\n",
        "    # What percentage of the samples have this label set?\n",
        "    prcnt_1 = count / 159571\n",
        "    \n",
        "    # ...and not set?\n",
        "    prcnt_0 = 1 - prcnt_1\n",
        "\n",
        "    # Use these percentages as the probabilities for picking\n",
        "    # either 0 or 1.\n",
        "    weights = [prcnt_0, prcnt_1]\n",
        "\n",
        "    # Choices will make the \"predictions\" for us for this label.\n",
        "    prop_preds_label = choices(population, weights, k = num_test)\n",
        "\n",
        "    # Add the predictions for this label to the list.\n",
        "    prop_preds.append(prop_preds_label)\n",
        "\n",
        "# Convert to a matrix of [samples x labels]\n",
        "prop_preds = np.asarray(prop_preds).transpose()\n",
        "\n",
        "# Calcualte the ROC AUC score for predicting based on class frequencies.\n",
        "score = roc_auc_score(flat_true_labels, prop_preds)\n",
        "\n",
        "print('Predict by class frequency --> ROC AUC: {:.3f}'.format(score))"
      ],
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict by class frequency --> ROC AUC: 0.500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z-6IzN34T9z"
      },
      "source": [
        "Not much better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qxi0mOhbmRLi"
      },
      "source": [
        "### A.3. Referenced Examples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7le0kcOSny2F"
      },
      "source": [
        "\n",
        "**Multiclass Classification**\n",
        "* Demonstrates a technique for quickly determining if document length is impacting your accuracy.\n",
        "* Explores the impact of batch size and sequence length on GPU memory usage (and limits!), training speed, and model accuracy.\n",
        "* Available for purchase [here](https://bit.ly/3iTYCfm).\n",
        "* Existing owners (including BERT Collection owners) can go directly to the product [here](https://www.chrismccormick.ai/products/bert-multi-class-text-classification-tutorial-with-code).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJHwVSG4K_66"
      },
      "source": [
        "**Document Classification**\n",
        "* Free YouTube tutorial [here](https://youtu.be/_eSGWNqKeeY).\n",
        "* Notebook available for purchase [here](https://www.chrismccormick.ai/offers/uzNxadxB/checkout).\n",
        "* Existing owners (including BERT Collection owners) can go directly to the product [here](https://www.chrismccormick.ai/products/bert-document-classification-tutorial-with-code)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lVqs7Z_z3TG"
      },
      "source": [
        "### A.4. SoftMax and Sigmoid functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpjfXTyCIi0F"
      },
      "source": [
        "The below cells show the implementation of the SoftMax and sigmoid activation functions, using the same logits values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdtbNpBYwVwX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e116ae82-daed-425e-f3cd-3411119a78fa"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Some hardcoded logits, just for demonstration.\n",
        "logits = [4.05, -4.55, -3.39, -3.10, -1.96, 0.35]\n",
        "logits = np.asarray(logits)\n",
        "\n",
        "# ======== SoftMax ========\n",
        "\n",
        "# SoftMax is e^x / sum(e^x)\n",
        "out = np.exp(logits) / np.sum(np.exp(logits))\n",
        "\n",
        "print('SoftMax scores:')\n",
        "\n",
        "# Print the final scores.\n",
        "for o in out:\n",
        "    print('  {:.5f}'.format(o))\n",
        "\n",
        "# ======== sigmoid ========\n",
        "\n",
        "# sigmoid is 1 / (1 + e^x)\n",
        "out = 1 / (1 + np.exp(-logits))\n",
        "\n",
        "print('\\nsigmoid scores:')\n",
        "\n",
        "# Print the final scores\n",
        "for o in out:\n",
        "    print('  {:.5f}'.format(o))\n"
      ],
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SoftMax scores:\n",
            "  0.97207\n",
            "  0.00018\n",
            "  0.00057\n",
            "  0.00076\n",
            "  0.00239\n",
            "  0.02403\n",
            "\n",
            "sigmoid scores:\n",
            "  0.98288\n",
            "  0.01046\n",
            "  0.03261\n",
            "  0.04311\n",
            "  0.12347\n",
            "  0.58662\n"
          ]
        }
      ]
    }
  ]
}